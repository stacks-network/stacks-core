// Copyright (C) 2013-2020 Blockstack PBC, a public benefit corporation
// Copyright (C) 2020 Stacks Open Internet Foundation
//
// This program is free software: you can redistribute it and/or modify
// it under the terms of the GNU General Public License as published by
// the Free Software Foundation, either version 3 of the License, or
// (at your option) any later version.
//
// This program is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
// GNU General Public License for more details.
//
// You should have received a copy of the GNU General Public License
// along with this program.  If not, see <http://www.gnu.org/licenses/>.

use std::cmp::Ordering;
use std::collections::{HashMap, HashSet};
use std::io::{ErrorKind, Write};
use std::ops::{Deref, DerefMut};
use std::str::FromStr;
use std::{cmp, fmt, fs};

use clarity::vm::ast::ASTRules;
use clarity::vm::costs::ExecutionCost;
use clarity::vm::representations::{ClarityName, ContractName};
use clarity::vm::types::{PrincipalData, Value};
use rand;
use rand::RngCore;
use rusqlite::types::ToSql;
use rusqlite::{
    Connection, Error as sqlite_error, OpenFlags, OptionalExtension, Row, Transaction,
    TransactionBehavior, NO_PARAMS,
};
use sha2::{Digest, Sha512_256};
use stacks_common::address::AddressHashMode;
use stacks_common::types::chainstate::{
    BlockHeaderHash, BurnchainHeaderHash, PoxId, SortitionId, StacksAddress, StacksBlockId,
    TrieHash, VRFSeed,
};
use stacks_common::types::StacksPublicKeyBuffer;
use stacks_common::util::hash::{hex_bytes, to_hex, Hash160, Sha512Trunc256Sum};
use stacks_common::util::secp256k1::{MessageSignature, Secp256k1PublicKey};
use stacks_common::util::vrf::*;
use stacks_common::util::{get_epoch_time_secs, log};
use wsts::common::Signature as WSTSSignature;
use wsts::curve::point::{Compressed, Point};

use crate::burnchains::affirmation::{AffirmationMap, AffirmationMapEntry};
use crate::burnchains::bitcoin::BitcoinNetworkType;
use crate::burnchains::db::{BurnchainDB, BurnchainHeaderReader};
use crate::burnchains::{
    Address, Burnchain, BurnchainBlockHeader, BurnchainRecipient, BurnchainSigner,
    BurnchainStateTransition, BurnchainStateTransitionOps, BurnchainTransaction, BurnchainView,
    Error as BurnchainError, PoxConstants, PublicKey, Txid,
};
use crate::chainstate::burn::operations::leader_block_commit::{
    MissedBlockCommit, RewardSetInfo, OUTPUTS_PER_COMMIT,
};
use crate::chainstate::burn::operations::{
    BlockstackOperationType, DelegateStxOp, LeaderBlockCommitOp, LeaderKeyRegisterOp, PreStxOp,
    StackStxOp, TransferStxOp, VoteForAggregateKeyOp,
};
use crate::chainstate::burn::{
    BlockSnapshot, ConsensusHash, ConsensusHashExtensions, Opcodes, OpsHash, SortitionHash,
};
use crate::chainstate::coordinator::{
    Error as CoordinatorError, PoxAnchorBlockStatus, RewardCycleInfo, SortitionDBMigrator,
};
use crate::chainstate::nakamoto::NakamotoBlockHeader;
use crate::chainstate::stacks::address::{PoxAddress, StacksAddressExtensions};
use crate::chainstate::stacks::boot::PoxStartCycleInfo;
use crate::chainstate::stacks::db::{StacksChainState, StacksHeaderInfo};
use crate::chainstate::stacks::index::marf::{MARFOpenOpts, MarfConnection, MARF};
use crate::chainstate::stacks::index::storage::TrieFileStorage;
use crate::chainstate::stacks::index::{
    ClarityMarfTrieId, Error as MARFError, MARFValue, MarfTrieId,
};
use crate::chainstate::stacks::{StacksPublicKey, *};
use crate::chainstate::ChainstateDB;
use crate::core::{
    StacksEpoch, StacksEpochExtension, StacksEpochId, AST_RULES_PRECHECK_SIZE,
    FIRST_BURNCHAIN_CONSENSUS_HASH, FIRST_STACKS_BLOCK_HASH, STACKS_EPOCH_MAX,
};
use crate::net::neighbors::MAX_NEIGHBOR_BLOCK_DELAY;
use crate::net::Error as NetError;
use crate::util_lib::db::{
    db_mkdirs, get_ancestor_block_hash, opt_u64_to_sql, query_count, query_row, query_row_columns,
    query_row_panic, query_rows, sql_pragma, table_exists, tx_begin_immediate, tx_busy_handler,
    u64_to_sql, DBConn, DBTx, Error as db_error, FromColumn, FromRow, IndexDBConn, IndexDBTx,
};

const BLOCK_HEIGHT_MAX: u64 = ((1 as u64) << 63) - 1;

pub const REWARD_WINDOW_START: u64 = 144 * 15;
pub const REWARD_WINDOW_END: u64 = 144 * 90 + REWARD_WINDOW_START;

pub type BlockHeaderCache = HashMap<ConsensusHash, (Option<BlockHeaderHash>, ConsensusHash)>;

impl FromRow<SortitionId> for SortitionId {
    fn from_row<'a>(row: &'a Row) -> Result<SortitionId, db_error> {
        SortitionId::from_column(row, "sortition_id")
    }
}

impl FromRow<ConsensusHash> for ConsensusHash {
    fn from_row<'a>(row: &'a Row) -> Result<ConsensusHash, db_error> {
        ConsensusHash::from_column(row, "consensus_hash")
    }
}

impl FromRow<BurnchainHeaderHash> for BurnchainHeaderHash {
    fn from_row<'a>(row: &'a Row) -> Result<BurnchainHeaderHash, db_error> {
        BurnchainHeaderHash::from_column(row, "burn_header_hash")
    }
}

impl FromRow<MissedBlockCommit> for MissedBlockCommit {
    fn from_row<'a>(row: &'a Row) -> Result<MissedBlockCommit, db_error> {
        let intended_sortition = SortitionId::from_column(row, "intended_sortition_id")?;
        let input_json: String = row.get_unwrap("input");
        let input =
            serde_json::from_str(&input_json).map_err(|e| db_error::SerializationError(e))?;
        let txid = Txid::from_column(row, "txid")?;

        Ok(MissedBlockCommit {
            input,
            txid,
            intended_sortition,
        })
    }
}

impl FromRow<BlockSnapshot> for BlockSnapshot {
    fn from_row<'a>(row: &'a Row) -> Result<BlockSnapshot, db_error> {
        let block_height = u64::from_column(row, "block_height")?;
        let burn_header_hash = BurnchainHeaderHash::from_column(row, "burn_header_hash")?;
        let burn_header_timestamp = u64::from_column(row, "burn_header_timestamp")?;
        let parent_burn_header_hash =
            BurnchainHeaderHash::from_column(row, "parent_burn_header_hash")?;
        let consensus_hash = ConsensusHash::from_column(row, "consensus_hash")?;
        let ops_hash = OpsHash::from_column(row, "ops_hash")?;
        let total_burn_str: String = row.get_unwrap("total_burn");
        let sortition: bool = row.get_unwrap("sortition");
        let sortition_hash = SortitionHash::from_column(row, "sortition_hash")?;
        let winning_block_txid = Txid::from_column(row, "winning_block_txid")?;
        let winning_stacks_block_hash =
            BlockHeaderHash::from_column(row, "winning_stacks_block_hash")?;
        let index_root = TrieHash::from_column(row, "index_root")?;
        let num_sortitions = u64::from_column(row, "num_sortitions")?;

        // information we learn about the stacks block this snapshot committedto
        let stacks_block_accepted: bool = row.get_unwrap("stacks_block_accepted");
        let stacks_block_height = u64::from_column(row, "stacks_block_height")?;
        let arrival_index = u64::from_column(row, "arrival_index")?;

        // information about what we have determined about the stacks chain tip.
        // This is memoized to a given canonical chain tip block.
        let canonical_stacks_tip_height = u64::from_column(row, "canonical_stacks_tip_height")?;
        let canonical_stacks_tip_hash =
            BlockHeaderHash::from_column(row, "canonical_stacks_tip_hash")?;
        let canonical_stacks_tip_consensus_hash =
            ConsensusHash::from_column(row, "canonical_stacks_tip_consensus_hash")?;

        // identifiers derived from PoX forking state
        let sortition_id = SortitionId::from_column(row, "sortition_id")?;
        let parent_sortition_id = SortitionId::from_column(row, "parent_sortition_id")?;
        let pox_valid = row.get_unwrap("pox_valid");

        let accumulated_coinbase_ustx_str: String = row.get_unwrap("accumulated_coinbase_ustx");
        let accumulated_coinbase_ustx = accumulated_coinbase_ustx_str
            .parse::<u128>()
            .expect("DB CORRUPTION: failed to parse stored value");

        let total_burn = total_burn_str
            .parse::<u64>()
            .map_err(|_e| db_error::ParseError)?;

        let miner_pk_hash = row.get("miner_pk_hash")?;

        let snapshot = BlockSnapshot {
            block_height,
            burn_header_timestamp,
            burn_header_hash,
            parent_burn_header_hash,
            consensus_hash,
            ops_hash,
            total_burn,
            sortition,
            sortition_hash,
            winning_block_txid,
            winning_stacks_block_hash,
            index_root,
            num_sortitions,

            stacks_block_accepted,
            stacks_block_height,
            arrival_index,

            canonical_stacks_tip_height,
            canonical_stacks_tip_hash,
            canonical_stacks_tip_consensus_hash,

            sortition_id,
            parent_sortition_id,
            pox_valid,
            accumulated_coinbase_ustx,

            miner_pk_hash,
        };
        Ok(snapshot)
    }
}

impl FromRow<LeaderKeyRegisterOp> for LeaderKeyRegisterOp {
    fn from_row<'a>(row: &'a Row) -> Result<LeaderKeyRegisterOp, db_error> {
        let txid = Txid::from_column(row, "txid")?;
        let vtxindex: u32 = row.get_unwrap("vtxindex");
        let block_height = u64::from_column(row, "block_height")?;
        let burn_header_hash = BurnchainHeaderHash::from_column(row, "burn_header_hash")?;
        let consensus_hash = ConsensusHash::from_column(row, "consensus_hash")?;
        let public_key = VRFPublicKey::from_column(row, "public_key")?;
        let memo_hex: String = row.get_unwrap("memo");

        let memo_bytes = hex_bytes(&memo_hex).map_err(|_e| db_error::ParseError)?;

        let memo = memo_bytes.to_vec();

        let leader_key_row = LeaderKeyRegisterOp {
            txid: txid,
            vtxindex: vtxindex,
            block_height: block_height,
            burn_header_hash: burn_header_hash,

            consensus_hash: consensus_hash,
            public_key: public_key,
            memo: memo,
        };

        Ok(leader_key_row)
    }
}

impl FromRow<LeaderBlockCommitOp> for LeaderBlockCommitOp {
    fn from_row<'a>(row: &'a Row) -> Result<LeaderBlockCommitOp, db_error> {
        let txid = Txid::from_column(row, "txid")?;
        let vtxindex: u32 = row.get_unwrap("vtxindex");
        let block_height = u64::from_column(row, "block_height")?;
        let burn_header_hash = BurnchainHeaderHash::from_column(row, "burn_header_hash")?;
        let block_header_hash = BlockHeaderHash::from_column(row, "block_header_hash")?;
        let new_seed = VRFSeed::from_column(row, "new_seed")?;
        let parent_block_ptr: u32 = row.get_unwrap("parent_block_ptr");
        let parent_vtxindex: u16 = row.get_unwrap("parent_vtxindex");
        let key_block_ptr: u32 = row.get_unwrap("key_block_ptr");
        let key_vtxindex: u16 = row.get_unwrap("key_vtxindex");
        let memo_hex: String = row.get_unwrap("memo");
        let burn_fee_str: String = row.get_unwrap("burn_fee");
        let input_json: String = row.get_unwrap("input");
        let apparent_sender_json: String = row.get_unwrap("apparent_sender");
        let sunset_burn_str: String = row.get_unwrap("sunset_burn");

        let commit_outs = serde_json::from_value(row.get_unwrap("commit_outs"))
            .expect("Unparseable value stored to database");

        let memo_bytes = hex_bytes(&memo_hex).map_err(|_e| db_error::ParseError)?;

        let memo = memo_bytes.to_vec();

        let input =
            serde_json::from_str(&input_json).map_err(|e| db_error::SerializationError(e))?;

        let apparent_sender = serde_json::from_str(&apparent_sender_json)
            .map_err(|e| db_error::SerializationError(e))?;

        let burn_fee = burn_fee_str
            .parse::<u64>()
            .expect("DB Corruption: burn fee is not parseable as u64");

        let sunset_burn = sunset_burn_str
            .parse::<u64>()
            .expect("DB Corruption: Sunset burn is not parseable as u64");

        let burn_parent_modulus: u8 = row.get_unwrap("burn_parent_modulus");

        let block_commit = LeaderBlockCommitOp {
            block_header_hash,
            new_seed,
            parent_block_ptr,
            parent_vtxindex,
            key_block_ptr,
            key_vtxindex,
            memo,
            burn_parent_modulus,

            burn_fee,
            input,
            apparent_sender,
            commit_outs,
            sunset_burn,
            txid,
            vtxindex,
            block_height,
            burn_header_hash,
        };
        Ok(block_commit)
    }
}

impl FromRow<StackStxOp> for StackStxOp {
    fn from_row<'a>(row: &'a Row) -> Result<StackStxOp, db_error> {
        let txid = Txid::from_column(row, "txid")?;
        let vtxindex: u32 = row.get_unwrap("vtxindex");
        let block_height = u64::from_column(row, "block_height")?;
        let burn_header_hash = BurnchainHeaderHash::from_column(row, "burn_header_hash")?;

        let sender = StacksAddress::from_column(row, "sender_addr")?;
        let reward_addr = PoxAddress::from_column(row, "reward_addr")?;
        let stacked_ustx_str: String = row.get_unwrap("stacked_ustx");
        let stacked_ustx = u128::from_str_radix(&stacked_ustx_str, 10)
            .expect("CORRUPTION: bad u128 written to sortdb");
        let num_cycles = row.get_unwrap("num_cycles");
        let signing_key_str_opt: Option<String> = row.get("signer_key")?;
        let signer_key = match signing_key_str_opt {
            Some(key_str) => serde_json::from_str(&key_str).ok(),
            None => None,
        };
        let max_amount_str_opt: Option<String> = row.get("max_amount")?;
        let max_amount = match max_amount_str_opt {
            Some(max_amount_str) => u128::from_str_radix(&max_amount_str, 10)
                .map_err(|_| db_error::ParseError)
                .ok(),
            None => None,
        };
        let auth_id = row.get("auth_id")?;

        Ok(StackStxOp {
            txid,
            vtxindex,
            block_height,
            burn_header_hash,
            sender,
            reward_addr,
            stacked_ustx,
            num_cycles,
            signer_key,
            max_amount,
            auth_id,
        })
    }
}

impl FromRow<DelegateStxOp> for DelegateStxOp {
    fn from_row<'a>(row: &'a Row) -> Result<DelegateStxOp, db_error> {
        let txid = Txid::from_column(row, "txid")?;
        let vtxindex: u32 = row.get_unwrap("vtxindex");
        let block_height = u64::from_column(row, "block_height")?;
        let burn_header_hash = BurnchainHeaderHash::from_column(row, "burn_header_hash")?;

        let sender = StacksAddress::from_column(row, "sender_addr")?;
        let delegate_to = StacksAddress::from_column(row, "delegate_to")?;
        let reward_addr_str: String = row.get_unwrap("reward_addr");
        let reward_addr = serde_json::from_str(&reward_addr_str)
            .expect("CORRUPTION: DB stored bad transition ops");

        let delegated_ustx_str: String = row.get_unwrap("delegated_ustx");
        let delegated_ustx = u128::from_str_radix(&delegated_ustx_str, 10)
            .expect("CORRUPTION: bad u128 written to sortdb");
        let until_burn_height = u64::from_column(row, "until_burn_height")?;

        Ok(DelegateStxOp {
            txid,
            vtxindex,
            block_height,
            burn_header_hash,
            sender,
            delegate_to,
            reward_addr,
            delegated_ustx,
            until_burn_height,
        })
    }
}

impl FromRow<TransferStxOp> for TransferStxOp {
    fn from_row<'a>(row: &'a Row) -> Result<TransferStxOp, db_error> {
        let txid = Txid::from_column(row, "txid")?;
        let vtxindex: u32 = row.get_unwrap("vtxindex");
        let block_height = u64::from_column(row, "block_height")?;
        let burn_header_hash = BurnchainHeaderHash::from_column(row, "burn_header_hash")?;

        let sender = StacksAddress::from_column(row, "sender_addr")?;
        let recipient = StacksAddress::from_column(row, "recipient_addr")?;
        let transfered_ustx_str: String = row.get_unwrap("transfered_ustx");
        let transfered_ustx = u128::from_str_radix(&transfered_ustx_str, 10)
            .expect("CORRUPTION: bad u128 written to sortdb");
        let memo_hex: String = row.get_unwrap("memo");
        let memo = hex_bytes(&memo_hex).map_err(|_| db_error::Corruption)?;

        Ok(TransferStxOp {
            txid,
            vtxindex,
            block_height,
            burn_header_hash,
            sender,
            recipient,
            transfered_ustx,
            memo,
        })
    }
}

impl FromRow<VoteForAggregateKeyOp> for VoteForAggregateKeyOp {
    fn from_row<'a>(row: &'a Row) -> Result<VoteForAggregateKeyOp, db_error> {
        let txid = Txid::from_column(row, "txid")?;
        let vtxindex: u32 = row.get_unwrap("vtxindex");
        let block_height = u64::from_column(row, "block_height")?;
        let burn_header_hash = BurnchainHeaderHash::from_column(row, "burn_header_hash")?;

        let sender = StacksAddress::from_column(row, "sender_addr")?;
        let aggregate_key_str: String = row.get_unwrap("aggregate_key");
        let aggregate_key: StacksPublicKeyBuffer = serde_json::from_str(&aggregate_key_str)
            .expect("CORRUPTION: DB stored bad transition ops");
        let round: u32 = row.get_unwrap("round");
        let reward_cycle = u64::from_column(row, "reward_cycle")?;
        let signer_index: u16 = row.get_unwrap("signer_index");
        let signer_key_str: String = row.get_unwrap("signer_key");
        let signer_key: StacksPublicKeyBuffer = serde_json::from_str(&signer_key_str)
            .expect("CORRUPTION: DB stored bad transition ops");

        Ok(VoteForAggregateKeyOp {
            txid,
            vtxindex,
            block_height,
            burn_header_hash,
            sender,
            aggregate_key,
            round,
            reward_cycle,
            signer_index,
            signer_key,
        })
    }
}

impl FromColumn<ASTRules> for ASTRules {
    fn from_column<'a>(row: &'a Row, column_name: &str) -> Result<ASTRules, db_error> {
        let x: u8 = row.get_unwrap(column_name);
        let ast_rules = ASTRules::from_u8(x).ok_or(db_error::ParseError)?;
        Ok(ast_rules)
    }
}

impl FromRow<(ASTRules, u64)> for (ASTRules, u64) {
    fn from_row<'a>(row: &'a Row) -> Result<(ASTRules, u64), db_error> {
        let ast_rules = ASTRules::from_column(row, "ast_rule_id")?;
        let height = u64::from_column(row, "block_height")?;
        Ok((ast_rules, height))
    }
}

struct AcceptedStacksBlockHeader {
    pub tip_consensus_hash: ConsensusHash, // PoX tip
    pub consensus_hash: ConsensusHash,     // stacks block consensus hash
    pub block_hash: BlockHeaderHash,       // stacks block hash
    pub height: u64,                       // stacks block height
}

#[derive(Debug)]
pub struct InitialMiningBonus {
    pub total_reward: u128,
    pub per_block: u128,
}

impl FromRow<AcceptedStacksBlockHeader> for AcceptedStacksBlockHeader {
    fn from_row<'a>(row: &'a Row) -> Result<AcceptedStacksBlockHeader, db_error> {
        let tip_consensus_hash = ConsensusHash::from_column(row, "tip_consensus_hash")?;
        let consensus_hash = ConsensusHash::from_column(row, "consensus_hash")?;
        let block_hash = BlockHeaderHash::from_column(row, "stacks_block_hash")?;
        let height = u64::from_column(row, "block_height")?;

        Ok(AcceptedStacksBlockHeader {
            tip_consensus_hash,
            consensus_hash,
            block_hash,
            height,
        })
    }
}

impl FromRow<StacksEpoch> for StacksEpoch {
    fn from_row<'a>(row: &'a Row) -> Result<StacksEpoch, db_error> {
        let epoch_id_u32: u32 = row.get_unwrap("epoch_id");
        let epoch_id = StacksEpochId::try_from(epoch_id_u32).map_err(|_| db_error::ParseError)?;

        let start_height = u64::from_column(row, "start_block_height")?;
        let end_height = u64::from_column(row, "end_block_height")?;

        let network_epoch: u8 = row.get_unwrap("network_epoch");

        let block_limit = row.get_unwrap("block_limit");
        Ok(StacksEpoch {
            epoch_id,
            start_height,
            end_height,
            block_limit,
            network_epoch,
        })
    }
}

pub const SORTITION_DB_VERSION: &'static str = "8";

const SORTITION_DB_INITIAL_SCHEMA: &'static [&'static str] = &[
    r#"
    PRAGMA foreign_keys = ON;
    "#,
    r#"
    -- sortition snapshots -- snapshot of all transactions processed in a burn block
    -- organizes the set of forks in the burn chain as well.
    CREATE TABLE snapshots(
        block_height INTEGER NOT NULL,
        burn_header_hash TEXT NOT NULL,
        sortition_id TEXT UNIQUE NOT NULL,
        parent_sortition_id TEXT NOT NULL,
        burn_header_timestamp INT NOT NULL,
        parent_burn_header_hash TEXT NOT NULL,
        consensus_hash TEXT UNIQUE NOT NULL,
        ops_hash TEXT NOT NULL,
        total_burn TEXT NOT NULL,
        sortition INTEGER NOT NULL,
        sortition_hash TEXT NOT NULL,
        winning_block_txid TEXT NOT NULL,
        winning_stacks_block_hash TEXT NOT NULL,
        index_root TEXT UNIQUE NOT NULL,

        num_sortitions INTEGER NOT NULL,

        stacks_block_accepted INTEGER NOT NULL,        -- set to 1 if we fetched and processed this Stacks block
        stacks_block_height INTEGER NOT NULL,           -- set to the height of the stacks block, once it's processed
        arrival_index INTEGER NOT NULL,                 -- (global) order in which this Stacks block was processed

        canonical_stacks_tip_height INTEGER NOT NULL,   -- height of highest known Stacks fork in this burn chain fork
        canonical_stacks_tip_hash TEXT NOT NULL,        -- hash of highest known Stacks fork's tip block in this burn chain fork
        canonical_stacks_tip_consensus_hash TEXT NOT NULL,   -- burn hash of highest known Stacks fork's tip block in this burn chain fork

        pox_valid INTEGER NOT NULL,

        accumulated_coinbase_ustx TEXT NOT NULL,

        -- JSON-serialized total PoX payouts
        pox_payouts TEXT NOT NULL,

        PRIMARY KEY(sortition_id)
    );"#,
    r#"
    CREATE TABLE snapshot_transition_ops(
      sortition_id TEXT PRIMARY KEY,
      accepted_ops TEXT NOT NULL,
      consumed_keys TEXT NOT NULL
    );"#,
    r#"
    -- all leader keys registered in the blockchain.
    -- contains pointers to the burn block and fork in which they occur
    CREATE TABLE leader_keys(
        txid TEXT NOT NULL,
        vtxindex INTEGER NOT NULL,
        block_height INTEGER NOT NULL,
        burn_header_hash TEXT NOT NULL,
        sortition_id TEXT NOT NULL,
        
        consensus_hash TEXT NOT NULL,
        public_key TEXT NOT NULL,
        memo TEXT,

        PRIMARY KEY(txid,sortition_id),
        FOREIGN KEY(sortition_id) REFERENCES snapshots(sortition_id)
    );"#,
    r#"
    CREATE TABLE block_commits(
        txid TEXT NOT NULL,
        vtxindex INTEGER NOT NULL,
        block_height INTEGER NOT NULL,
        burn_header_hash TEXT NOT NULL,
        sortition_id TEXT NOT NULL,

        block_header_hash TEXT NOT NULL,
        new_seed TEXT NOT NULL,
        parent_block_ptr INTEGER NOT NULL,
        parent_vtxindex INTEGER NOT NULL,
        key_block_ptr INTEGER NOT NULL,
        key_vtxindex INTEGER NOT NULL,
        memo TEXT,
        commit_outs TEXT,
        burn_fee TEXT NOT NULL,     -- use text to encode really big numbers
        sunset_burn TEXT NOT NULL,     -- use text to encode really big numbers
        input TEXT NOT NULL,
        apparent_sender TEXT NOT NULL,
        burn_parent_modulus INTEGER NOT NULL,

        PRIMARY KEY(txid,sortition_id),
        FOREIGN KEY(sortition_id) REFERENCES snapshots(sortition_id)
    );"#,
    r#"
    CREATE TABLE stack_stx (
        txid TEXT NOT NULL,
        vtxindex INTEGER NOT NULL,
        block_height INTEGER NOT NULL,
        burn_header_hash TEXT NOT NULL,

        sender_addr TEXT NOT NULL,
        reward_addr TEXT NOT NULL,
        stacked_ustx TEXT NOT NULL,
        num_cycles INTEGER NOT NULL,

        -- The primary key here is (txid, burn_header_hash) because 
        -- this transaction will be accepted regardless of which sortition
        -- history it is in.
        PRIMARY KEY(txid,burn_header_hash)
    );"#,
    r#"
    CREATE TABLE transfer_stx (
        txid TEXT NOT NULL,
        vtxindex INTEGER NOT NULL,
        block_height INTEGER NOT NULL,
        burn_header_hash TEXT NOT NULL,

        sender_addr TEXT NOT NULL,
        recipient_addr TEXT NOT NULL,
        transfered_ustx TEXT NOT NULL,
        memo TEXT NOT NULL,

        -- The primary key here is (txid, burn_header_hash) because 
        -- this transaction will be accepted regardless of which sortition
        -- history it is in.
        PRIMARY KEY(txid,burn_header_hash)
    );"#,
    r#"
    CREATE TABLE missed_commits (
        txid TEXT NOT NULL,
        input TEXT NOT NULL,
        intended_sortition_id TEXT NOT NULL,

        PRIMARY KEY(txid, intended_sortition_id)
    );"#,
    "CREATE TABLE db_config(version TEXT PRIMARY KEY);",
];

const SORTITION_DB_SCHEMA_2: &'static [&'static str] = &[r#"
     CREATE TABLE epochs (
         start_block_height INTEGER NOT NULL,
         end_block_height INTEGER NOT NULL,
         epoch_id INTEGER NOT NULL,
         block_limit TEXT NOT NULL,
         network_epoch INTEGER NOT NULL,
         PRIMARY KEY(start_block_height,epoch_id)
     );"#];

const SORTITION_DB_SCHEMA_3: &'static [&'static str] = &[r#"
    CREATE TABLE block_commit_parents (
        block_commit_txid TEXT NOT NULL,
        block_commit_sortition_id TEXT NOT NULL,

        parent_sortition_id TEXT NOT NULL,

        PRIMARY KEY(block_commit_txid,block_commit_sortition_id),
        FOREIGN KEY(block_commit_txid,block_commit_sortition_id) REFERENCES block_commits(txid,sortition_id)
    );"#];

const SORTITION_DB_SCHEMA_4: &'static [&'static str] = &[
    r#"
    CREATE TABLE delegate_stx (
        txid TEXT NOT NULL,
        vtxindex INTEGER NOT NULL,
        block_height INTEGER NOT NULL,
        burn_header_hash TEXT NOT NULL,

        sender_addr TEXT NOT NULL,
        delegate_to TEXT NOT NULL,
        reward_addr TEXT NOT NULL,
        delegated_ustx TEXT NOT NULL,
        until_burn_height INTEGER,

        PRIMARY KEY(txid,burn_header_Hash)
    );"#,
    r#"
    CREATE TABLE ast_rule_heights (
        ast_rule_id INTEGER PRIMAR KEY NOT NULL,
        block_height INTEGER NOT NULL
    );"#,
];

/// The changes for version five *just* replace the existing epochs table
///  by deleting all the current entries and inserting the new epochs definition.
const SORTITION_DB_SCHEMA_5: &'static [&'static str] = &[r#"
     DELETE FROM epochs;"#];

const SORTITION_DB_SCHEMA_6: &'static [&'static str] = &[r#"
     DELETE FROM epochs;"#];

const SORTITION_DB_SCHEMA_7: &'static [&'static str] = &[r#"
     DELETE FROM epochs;"#];

const SORTITION_DB_SCHEMA_8: &'static [&'static str] = &[
    r#"DELETE FROM epochs;"#,
    r#"DROP INDEX IF EXISTS index_user_burn_support_txid;"#,
    r#"DROP INDEX IF EXISTS index_user_burn_support_sortition_id_vtxindex;"#,
    r#"DROP INDEX IF EXISTS index_user_burn_support_sortition_id_hash_160_key_vtxindex_key_block_ptr_vtxindex;"#,
    r#"DROP TABLE IF EXISTS user_burn_support;"#,
    r#"ALTER TABLE snapshots ADD miner_pk_hash TEXT DEFAULT NULL"#,
    r#"
    -- eagerly-processed reward sets, before they're applied to the start of the next reward cycle
    CREATE TABLE preprocessed_reward_sets (
        sortition_id TEXT PRIMARY KEY,
        reward_set TEXT NOT NULL
    );"#,
    r#"
    -- canonical chain tip at each sortition ID.
    -- This is updated in both 2.x and Nakamoto, but Nakamoto relies on this exclusively
    CREATE TABLE stacks_chain_tips (
        sortition_id TEXT PRIMARY KEY,
        consensus_hash TEXT NOT NULL,
        block_hash TEXT NOT NULL,
        block_height INTEGER NOT NULL
    );"#,
    r#"ALTER TABLE stack_stx ADD signer_key TEXT DEFAULT NULL;"#,
    r#"ALTER TABLE stack_stx ADD max_amount TEXT DEFAULT NULL;"#,
    r#"ALTER TABLE stack_stx ADD auth_id INTEGER DEFAULT NULL;"#,
    r#"
    -- table definition for `vote-for-aggregate-key` burn op
    CREATE TABLE vote_for_aggregate_key (
        txid TEXT NOT NULL,
        vtxindex INTEGER NOT NULL,
        block_height INTEGER NOT NULL,
        burn_header_hash TEXT NOT NULL,

        sender_addr TEXT NOT NULL,
        aggregate_key TEXT NOT NULL,
        round INTEGER NOT NULL,
        reward_cycle INTEGER NOT NULL,
        signer_index INTEGER NOT NULL,
        signer_key TEXT NOT NULL,

        PRIMARY KEY(txid,burn_header_hash)
    );"#,
];

const LAST_SORTITION_DB_INDEX: &'static str = "index_block_commits_by_sender";
const SORTITION_DB_INDEXES: &'static [&'static str] = &[
    "CREATE INDEX IF NOT EXISTS snapshots_block_hashes ON snapshots(block_height,index_root,winning_stacks_block_hash);",
    "CREATE INDEX IF NOT EXISTS snapshots_block_stacks_hashes ON snapshots(num_sortitions,index_root,winning_stacks_block_hash);",
    "CREATE INDEX IF NOT EXISTS snapshots_block_heights ON snapshots(burn_header_hash,block_height);",
    "CREATE INDEX IF NOT EXISTS snapshots_block_winning_hash ON snapshots(winning_stacks_block_hash);",
    "CREATE INDEX IF NOT EXISTS snapshots_canonical_chain_tip ON snapshots(pox_valid,block_height DESC,burn_header_hash ASC);",
    "CREATE INDEX IF NOT EXISTS block_arrivals ON snapshots(arrival_index,burn_header_hash);",
    "CREATE INDEX IF NOT EXISTS arrival_indexes ON snapshots(arrival_index);",
    "CREATE INDEX IF NOT EXISTS index_leader_keys_sortition_id_block_height_vtxindex ON leader_keys(sortition_id,block_height,vtxindex);",
    "CREATE INDEX IF NOT EXISTS index_block_commits_sortition_id_vtxindex ON block_commits(sortition_id,vtxindex);",
    "CREATE INDEX IF NOT EXISTS index_block_commits_sortition_id_block_height_vtxindex ON block_commits(sortition_id,block_height,vtxindex);",
    "CREATE INDEX IF NOT EXISTS index_stack_stx_burn_header_hash ON stack_stx(burn_header_hash);",
    "CREATE INDEX IF NOT EXISTS index_transfer_stx_burn_header_hash ON transfer_stx(burn_header_hash);",
    "CREATE INDEX IF NOT EXISTS index_missed_commits_intended_sortition_id ON missed_commits(intended_sortition_id);",
    "CREATE INDEX IF NOT EXISTS index_parent_sortition_id ON block_commit_parents(parent_sortition_id);",
    "CREATE INDEX IF NOT EXISTS index_burn_header_hash ON snapshots(burn_header_hash);",
    "CREATE INDEX IF NOT EXISTS index_parent_burn_header_hash ON snapshots(parent_burn_header_hash,burn_header_hash);",
    "CREATE INDEX IF NOT EXISTS index_pox_payouts ON snapshots(pox_payouts);",
    "CREATE INDEX IF NOT EXISTS index_burn_header_hash_pox_valid ON snapshots(burn_header_hash,pox_valid);",
    "CREATE INDEX IF NOT EXISTS index_delegate_stx_burn_header_hash ON delegate_stx(burn_header_hash);",
    "CREATE INDEX IF NOT EXISTS index_vote_for_aggregate_key_burn_header_hash ON vote_for_aggregate_key(burn_header_hash);",
    "CREATE INDEX IF NOT EXISTS index_block_commits_by_burn_height ON block_commits(block_height);",
    "CREATE INDEX IF NOT EXISTS index_block_commits_by_sender ON block_commits(apparent_sender);"
];

/// Handle to the sortition database, a MARF'ed sqlite DB on disk.
/// It stores information pertaining to cryptographic sortitions performed in each Bitcoin block --
/// either to select the next Stacks block (in epoch 2.5 and earlier), or to choose the next Stacks
/// miner (epoch 3.0 and later).
pub struct SortitionDB {
    /// Whether or not write operations are permitted.  Pertains to whether or not transaction
    /// objects can be created or schema migrations can happen on this SortitionDB instance.
    pub readwrite: bool,
    /// If true, then while write operations will be permitted, they will not be committed (and may
    /// even be skipped).  This is not used in production; it's used in the `stacks-inspect` tool
    /// to simulate what could happen (e.g. to replay sortitions with different anti-MEV strategies
    /// without corrupting the underlying DB).
    pub dryrun: bool,
    /// Handle to the MARF which stores an index over each burnchain and PoX fork.
    pub marf: MARF<SortitionId>,
    /// First burnchain block height at which sortitions will be considered.  All Stacks epochs
    /// besides epoch 1.0 must start at or after this height.
    pub first_block_height: u64,
    /// Hash of the first burnchain block at which sortitions will be considered.
    pub first_burn_header_hash: BurnchainHeaderHash,
    /// PoX constants that pertain to this DB, for purposes of (but not limited to) evaluating PoX
    /// reward cycles and evaluating block-commit validity within a PoX reward cycle
    pub pox_constants: PoxConstants,
    /// Path on disk from which this DB was opened (caller-given; not resolved).
    pub path: String,
}

#[derive(Clone)]
pub struct SortitionDBTxContext {
    pub first_block_height: u64,
    pub pox_constants: PoxConstants,
    pub dryrun: bool,
}

#[derive(Clone)]
pub struct SortitionHandleContext {
    pub first_block_height: u64,
    pub pox_constants: PoxConstants,
    pub chain_tip: SortitionId,
    pub dryrun: bool,
}

pub type SortitionDBConn<'a> = IndexDBConn<'a, SortitionDBTxContext, SortitionId>;
pub type SortitionDBTx<'a> = IndexDBTx<'a, SortitionDBTxContext, SortitionId>;

///
/// These structs are used to keep an open "handle" to the
///   sortition db -- this is just the db/marf connection
///   and a chain tip. This mostly just makes the job of callers
///   much simpler, because they don't have to worry about passing
///   around the open chain tip everywhere.
///
pub type SortitionHandleConn<'a> = IndexDBConn<'a, SortitionHandleContext, SortitionId>;
pub type SortitionHandleTx<'a> = IndexDBTx<'a, SortitionHandleContext, SortitionId>;

///
/// This trait is used for functions that
///  can accept either a SortitionHandleConn or a SortitionDBConn
///
pub trait SortitionContext: Clone {
    fn first_block_height(&self) -> u64;
}

impl SortitionContext for SortitionHandleContext {
    fn first_block_height(&self) -> u64 {
        self.first_block_height
    }
}

impl SortitionContext for SortitionDBTxContext {
    fn first_block_height(&self) -> u64 {
        self.first_block_height
    }
}

pub fn get_block_commit_by_txid(
    conn: &Connection,
    sort_id: &SortitionId,
    txid: &Txid,
) -> Result<Option<LeaderBlockCommitOp>, db_error> {
    let qry = "SELECT * FROM block_commits WHERE sortition_id = ?1 AND txid = ?2 LIMIT 1";
    let args: &[&dyn ToSql] = &[sort_id, txid];
    query_row(conn, qry, args)
}

pub fn get_ancestor_sort_id<C: SortitionContext>(
    ic: &IndexDBConn<'_, C, SortitionId>,
    block_height: u64,
    tip_block_hash: &SortitionId,
) -> Result<Option<SortitionId>, db_error> {
    let adjusted_height = match get_adjusted_block_height(&ic.context, block_height) {
        Some(x) => x,
        None => return Ok(None),
    };

    ic.get_ancestor_block_hash(adjusted_height, &tip_block_hash)
}

pub fn get_ancestor_sort_id_tx<C: SortitionContext>(
    ic: &mut IndexDBTx<'_, C, SortitionId>,
    block_height: u64,
    tip_block_hash: &SortitionId,
) -> Result<Option<SortitionId>, db_error> {
    let adjusted_height = match get_adjusted_block_height(&ic.context, block_height) {
        Some(x) => x,
        None => return Ok(None),
    };

    ic.get_ancestor_block_hash(adjusted_height, &tip_block_hash)
}

/// Returns the difference between `block_height` and `context.first_block_height()`, if this
/// is non-negative. Otherwise returns None.
fn get_adjusted_block_height<C: SortitionContext>(context: &C, block_height: u64) -> Option<u64> {
    let first_block_height = context.first_block_height();
    if block_height < first_block_height {
        return None;
    }

    Some(block_height - first_block_height)
}

struct db_keys;
impl db_keys {
    /// store an entry that maps from a PoX anchor's <stacks-block-header-hash> to <sortition-id of last block in prepare phase that chose it>
    pub fn pox_anchor_to_prepare_end(block_hash: &BlockHeaderHash) -> String {
        format!("sortition_db::pox_anchor_to_prepare_end::{}", block_hash)
    }

    pub fn pox_last_anchor() -> &'static str {
        "sortition_db::last_anchor_block"
    }

    pub fn pox_last_anchor_txid() -> &'static str {
        "sortition_db::last_anchor_block_txid"
    }

    pub fn pox_last_selected_anchor() -> &'static str {
        "sortition_db::last_selected_anchor_block"
    }

    pub fn pox_last_selected_anchor_txid() -> &'static str {
        "sortition_db::last_selected_anchor_block_txid"
    }

    pub fn pox_affirmation_map() -> &'static str {
        "sortition_db::affirmation_map"
    }

    pub fn pox_reward_cycle_unlocks(cycle: u64) -> String {
        format!("sortition_db::reward_set_unlocks::{}", cycle)
    }

    pub fn pox_reward_set_size() -> &'static str {
        "sortition_db::reward_set::size"
    }

    pub fn pox_reward_set_entry(ix: u16) -> String {
        format!("sortition_db::reward_set::entry::{}", ix)
    }

    pub fn pox_reward_set_payouts_key() -> String {
        format!("sortition_db::reward_set::payouts")
    }

    pub fn pox_reward_set_payouts_value(addrs: Vec<PoxAddress>, payout_per_addr: u128) -> String {
        serde_json::to_string(&(addrs, payout_per_addr)).unwrap()
    }

    pub fn pox_reward_set_payouts_decode(addr_str: &str) -> (Vec<PoxAddress>, u128) {
        let addrs_and_payout: (Vec<PoxAddress>, u128) = serde_json::from_str(addr_str).unwrap();
        addrs_and_payout
    }

    /// store an entry for retrieving the PoX identifier (i.e., the PoX bitvector) for this PoX fork
    pub fn pox_identifier() -> &'static str {
        "sortition_db::pox_identifier"
    }

    pub fn initial_mining_bonus_remaining() -> &'static str {
        "sortition_db::initial_mining::remaining"
    }

    pub fn initial_mining_bonus_per_block() -> &'static str {
        "sortition_db::initial_mining::per_block"
    }

    pub fn sortition_id_for_bhh(bhh: &BurnchainHeaderHash) -> String {
        format!("sortition_db::sortition_id_for_bhh::{}", bhh)
    }
    pub fn vrf_key_status(key: &VRFPublicKey) -> String {
        format!("sortition_db::vrf::{}", key.to_hex())
    }
    pub fn stacks_block_present(block_hash: &BlockHeaderHash) -> String {
        format!("sortition_db::sortition_block_hash::{}", block_hash)
    }
    pub fn last_sortition() -> &'static str {
        "sortition_db::last_sortition"
    }

    /// MARF index key for a processed stacks block.  Maps to its height.
    pub fn stacks_block_index(stacks_block_hash: &BlockHeaderHash) -> String {
        format!("sortition_db::stacks::block::{}", stacks_block_hash)
    }

    /// MARF index value for a processed stacks block
    fn stacks_block_index_value(height: u64) -> String {
        format!("{}", height)
    }

    /// MARF index key for the highest arrival index processed in a fork
    pub fn stacks_block_max_arrival_index() -> String {
        "sortition_db::stacks::block::max_arrival_index".to_string()
    }

    /// MARF index value for the highest arrival index processed in a fork
    fn stacks_block_max_arrival_index_value(index: u64) -> String {
        format!("{}", index)
    }

    pub fn reward_set_size_to_string(size: usize) -> String {
        to_hex(
            &u16::try_from(size)
                .expect("BUG: maximum reward set size should be u16")
                .to_le_bytes(),
        )
    }

    pub fn reward_set_size_from_string(size: &str) -> u16 {
        let bytes = hex_bytes(size).expect("CORRUPTION: bad format written for reward set size");
        let mut byte_buff = [0; 2];
        byte_buff.copy_from_slice(&bytes[0..2]);
        u16::from_le_bytes(byte_buff)
    }

    /// reward cycle ID that was last processed
    /// NOTE: unused now, but was used in earlier consensus rules.
    /// Preserved for testing compatibility.
    pub fn last_reward_cycle_key() -> &'static str {
        "sortition_db::last_reward_cycle"
    }

    /// NOTE: unused now, but was used in earlier consensus rules.
    /// Preserved for testing compatibility.
    pub fn last_reward_cycle_to_string(rc: u64) -> String {
        to_hex(&rc.to_le_bytes())
    }

    /// NOTE: unused now, but was used in earlier consensus rules.
    /// Preserved for testing compatibility.
    pub fn last_reward_cycle_from_string(rc_str: &str) -> u64 {
        let bytes = hex_bytes(rc_str).expect("CORRUPTION: bad format written for reward cycle ID");
        assert_eq!(
            bytes.len(),
            8,
            "CORRUPTION: expected 8 bytes for reward cycle"
        );
        let mut rc_buff = [0; 8];
        rc_buff.copy_from_slice(&bytes[0..8]);
        u64::from_le_bytes(rc_buff)
    }
}

/// Trait for structs that provide a chaintip-indexed handle into the
///  SortitionDB (i.e., a MARF view from a particular SortitionId)
pub trait SortitionHandle {
    /// Returns a connection to the SQLite db. If this handle is wrapping
    ///  a transaction, this should point to the open transaction.
    fn sqlite(&self) -> &Connection;

    /// Returns the snapshot of the burnchain block at burnchain height `block_height`.
    /// Returns None if there is no block at this height.
    fn get_block_snapshot_by_height(
        &mut self,
        block_height: u64,
    ) -> Result<Option<BlockSnapshot>, db_error>;

    /// Get the first burn block height
    fn first_burn_block_height(&self) -> u64;

    /// Get a ref to the PoX constants
    fn pox_constants(&self) -> &PoxConstants;

    /// Get the sortition ID of the sortition history tip this handle represents
    fn tip(&self) -> SortitionId;

    /// Get the highest-processed Nakamoto block on this sortition history.
    /// Returns Ok(Some(nakamoto-tip-ch, nakamoto-tip-bhh, nakamoto-tip-height))) on success, if
    /// there was a tip found
    /// Returns Ok(None) if no Nakamoto blocks are present on this sortition history
    /// Returns Err(..) on DB errors
    fn get_nakamoto_tip(&self) -> Result<Option<(ConsensusHash, BlockHeaderHash, u64)>, db_error>;

    /// is the given block a descendant of `potential_ancestor`?
    ///  * block_at_burn_height: the burn height of the sortition that chose the stacks block to check
    ///  * potential_ancestor: the stacks block hash of the potential ancestor
    fn descended_from(
        &mut self,
        block_at_burn_height: u64,
        potential_ancestor: &BlockHeaderHash,
    ) -> Result<bool, db_error> {
        let earliest_block_height_opt = self.sqlite().query_row(
            "SELECT block_height FROM snapshots WHERE winning_stacks_block_hash = ? ORDER BY block_height ASC LIMIT 1",
            &[potential_ancestor],
            |row| Ok(u64::from_row(row).expect("Expected u64 in database")))
            .optional()?;

        let earliest_block_height = match earliest_block_height_opt {
            Some(h) => h,
            None => {
                return Ok(false);
            }
        };

        let mut sn = self
            .get_block_snapshot_by_height(block_at_burn_height)?
            .ok_or_else(|| {
                test_debug!("No snapshot at height {}", block_at_burn_height);
                db_error::NotFoundError
            })?;

        while sn.block_height >= earliest_block_height {
            if !sn.sortition {
                return Ok(false);
            }
            if &sn.winning_stacks_block_hash == potential_ancestor {
                return Ok(true);
            }

            // step back to the parent
            match SortitionDB::get_block_commit_parent_sortition_id(
                self.sqlite(),
                &sn.winning_block_txid,
                &sn.sortition_id,
            )? {
                Some(parent_sortition_id) => {
                    // we have the block_commit parent memoization data
                    test_debug!(
                        "Parent sortition of {} memoized as {}",
                        &sn.winning_block_txid,
                        &parent_sortition_id
                    );
                    sn = SortitionDB::get_block_snapshot(self.sqlite(), &parent_sortition_id)?
                        .ok_or_else(|| db_error::NotFoundError)?;
                }
                None => {
                    // we do not have the block_commit parent memoization data
                    // step back to the parent
                    test_debug!("No parent sortition memo for {}", &sn.winning_block_txid);
                    let block_commit = get_block_commit_by_txid(
                        &self.sqlite(),
                        &sn.sortition_id,
                        &sn.winning_block_txid,
                    )?
                    .expect("CORRUPTION: winning block commit for snapshot not found");
                    sn = self
                        .get_block_snapshot_by_height(block_commit.parent_block_ptr as u64)?
                        .ok_or_else(|| db_error::NotFoundError)?;
                }
            }
        }
        return Ok(false);
    }
}

impl<'a> SortitionHandleTx<'a> {
    /// begin a MARF transaction with this connection
    ///  this is used by _writing_ contexts
    pub fn begin(
        conn: &'a mut SortitionDB,
        parent_chain_tip: &SortitionId,
    ) -> Result<SortitionHandleTx<'a>, db_error> {
        if !conn.readwrite {
            return Err(db_error::ReadOnly);
        }

        let handle = SortitionHandleTx::new(
            &mut conn.marf,
            SortitionHandleContext {
                chain_tip: parent_chain_tip.clone(),
                first_block_height: conn.first_block_height,
                pox_constants: conn.pox_constants.clone(),
                dryrun: conn.dryrun,
            },
        );

        Ok(handle)
    }

    /// Uses the handle's current fork identifier to get a block snapshot by
    ///   burnchain block header
    /// If the burn header hash is _not_ in the current fork, then this will return Ok(None)
    pub fn get_block_snapshot(
        &mut self,
        burn_header_hash: &BurnchainHeaderHash,
        chain_tip: &SortitionId,
    ) -> Result<Option<BlockSnapshot>, db_error> {
        let sortition_identifier_key = db_keys::sortition_id_for_bhh(burn_header_hash);
        let sortition_id = match self.get_indexed(&chain_tip, &sortition_identifier_key)? {
            None => return Ok(None),
            Some(x) => SortitionId::from_hex(&x).expect("FATAL: bad Sortition ID stored in DB"),
        };

        SortitionDB::get_block_snapshot(self.tx(), &sortition_id)
    }

    /// Get a leader key at a specific location in the burn chain's fork history, given the
    /// matching block commit's fork index root (block_height and vtxindex are the leader's
    /// calculated location in this fork).
    /// Returns None if there is no leader key at this location.
    pub fn get_leader_key_at(
        &mut self,
        key_block_height: u64,
        key_vtxindex: u32,
        tip: &SortitionId,
    ) -> Result<Option<LeaderKeyRegisterOp>, db_error> {
        assert!(key_block_height < BLOCK_HEIGHT_MAX);
        let ancestor_snapshot =
            match SortitionDB::get_ancestor_snapshot_tx(self, key_block_height, tip)? {
                Some(sn) => sn,
                None => {
                    return Ok(None);
                }
            };

        let qry = "SELECT * FROM leader_keys WHERE sortition_id = ?1 AND block_height = ?2 AND vtxindex = ?3 LIMIT 2";
        let args: &[&dyn ToSql] = &[
            &ancestor_snapshot.sortition_id,
            &u64_to_sql(key_block_height)?,
            &key_vtxindex,
        ];
        query_row_panic(self.tx(), qry, args, || {
            format!(
                "Multiple keys at {},{} in {}",
                key_block_height, key_vtxindex, tip
            )
        })
    }

    /// Find the VRF public keys consumed by each block candidate in the given list.
    /// The burn DB should have a key for each candidate; otherwise the candidate would not have
    /// been accepted.
    pub fn get_consumed_leader_keys(
        &mut self,
        parent_tip: &BlockSnapshot,
        block_candidates: &Vec<LeaderBlockCommitOp>,
    ) -> Result<Vec<LeaderKeyRegisterOp>, db_error> {
        // get the set of VRF keys consumed by these commits
        let mut leader_keys = vec![];
        for i in 0..block_candidates.len() {
            let leader_key_block_height = block_candidates[i].key_block_ptr as u64;
            let leader_key_vtxindex = block_candidates[i].key_vtxindex as u32;
            let leader_key = self
                .get_leader_key_at(
                    leader_key_block_height,
                    leader_key_vtxindex,
                    &parent_tip.sortition_id,
                )?
                .unwrap_or_else(|| {
                    panic!(
                        "FATAL: no leader key for accepted block commit {} (at {},{})",
                        &block_candidates[i].txid, leader_key_block_height, leader_key_vtxindex
                    )
                });

            leader_keys.push(leader_key);
        }

        Ok(leader_keys)
    }

    /// Get a block commit by its content-addressed location in a specific sortition.
    pub fn get_block_commit(
        &self,
        txid: &Txid,
        sortition_id: &SortitionId,
    ) -> Result<Option<LeaderBlockCommitOp>, db_error> {
        SortitionDB::get_block_commit(self.tx(), txid, sortition_id)
    }

    pub fn get_consensus_at(
        &mut self,
        block_height: u64,
    ) -> Result<Option<ConsensusHash>, db_error> {
        assert!(block_height < BLOCK_HEIGHT_MAX);
        let chain_tip = self.context.chain_tip.clone();

        match SortitionDB::get_ancestor_snapshot_tx(self, block_height, &chain_tip)? {
            Some(sn) => Ok(Some(sn.consensus_hash)),
            None => Ok(None),
        }
    }

    /// Do we expect a stacks block in this particular fork?
    /// i.e. is this block hash part of the fork history identified by tip_block_hash?
    pub fn expects_stacks_block_in_fork(
        &mut self,
        block_hash: &BlockHeaderHash,
    ) -> Result<bool, db_error> {
        let chain_tip = self.context.chain_tip.clone();
        self.get_indexed(&chain_tip, &db_keys::stacks_block_present(block_hash))
            .map(|result| result.is_some())
    }

    /// Get the latest block snapshot on this fork where a sortition occured.
    /// Search snapshots up to (but excluding) the given block height.
    /// Will always return a snapshot -- even if it's the initial sentinel snapshot.
    pub fn get_last_snapshot_with_sortition(
        &mut self,
        burn_block_height: u64,
    ) -> Result<BlockSnapshot, db_error> {
        assert!(burn_block_height < BLOCK_HEIGHT_MAX);
        test_debug!(
            "Get snapshot at from sortition tip {}, expect height {}",
            &self.context.chain_tip,
            burn_block_height
        );
        let chain_tip = self.context.chain_tip.clone();

        let get_from = match get_ancestor_sort_id_tx(self, burn_block_height, &chain_tip)? {
            Some(sortition_id) => sortition_id,
            None => {
                error!(
                    "No blockheight {} ancestor at sortition identifier {}",
                    burn_block_height, &self.context.chain_tip
                );
                return Err(db_error::NotFoundError);
            }
        };

        let ancestor_hash = match self.get_indexed(&get_from, &db_keys::last_sortition())? {
            Some(hex_str) => BurnchainHeaderHash::from_hex(&hex_str).unwrap_or_else(|_| {
                panic!(
                    "FATAL: corrupt database: failed to parse {} into a hex string",
                    &hex_str
                )
            }),
            None => {
                // no prior sortitions, so get the first
                return SortitionDB::get_first_block_snapshot(self.tx());
            }
        };

        self.get_block_snapshot(&ancestor_hash, &chain_tip)
            .map(|snapshot_opt| {
                snapshot_opt.unwrap_or_else(|| {
                    panic!("FATAL: corrupt index: no snapshot {}", ancestor_hash)
                })
            })
    }

    /// Determine whether or not a leader key has been consumed by a subsequent block commitment in
    /// this fork's history.
    /// Will return false if the leader key does not exist.
    pub fn is_leader_key_consumed(
        &mut self,
        leader_key: &LeaderKeyRegisterOp,
    ) -> Result<bool, db_error> {
        assert!(leader_key.block_height < BLOCK_HEIGHT_MAX);
        let chain_tip = self.context.chain_tip.clone();

        let key_status =
            match self.get_indexed(&chain_tip, &db_keys::vrf_key_status(&leader_key.public_key))? {
                Some(status_str) => {
                    if status_str == "1" {
                        // key is still available
                        false
                    } else if status_str == "0" {
                        // key is consumed
                        true
                    } else {
                        panic!("Invalid key status string {}", status_str);
                    }
                }
                None => {
                    // never before seen
                    false
                }
            };

        Ok(key_status)
    }

    /// Get a parent block commit at a specific location in the burn chain on a particular fork.
    /// Returns None if there is no block commit at this location.
    pub fn get_block_commit_parent(
        &mut self,
        block_height: u64,
        vtxindex: u32,
        tip: &SortitionId,
    ) -> Result<Option<LeaderBlockCommitOp>, db_error> {
        assert!(block_height < BLOCK_HEIGHT_MAX);
        let ancestor_id = match get_ancestor_sort_id_tx(self, block_height, tip)? {
            Some(id) => id,
            None => {
                return Ok(None);
            }
        };

        SortitionDB::get_block_commit_of_sortition(self.tx(), &ancestor_id, block_height, vtxindex)
    }

    pub fn has_VRF_public_key(&mut self, key: &VRFPublicKey) -> Result<bool, db_error> {
        let chain_tip = self.context.chain_tip.clone();
        let key_status = self
            .get_indexed(&chain_tip, &db_keys::vrf_key_status(key))?
            .is_some();
        Ok(key_status)
    }

    fn check_fresh_consensus_hash<F>(
        &mut self,
        consensus_hash_lifetime: u64,
        check: F,
    ) -> Result<bool, db_error>
    where
        F: Fn(&ConsensusHash) -> bool,
    {
        let chain_tip = self.context.chain_tip.clone();
        let first_snapshot = SortitionDB::get_first_block_snapshot(self.tx())?;
        let mut last_snapshot =
            SortitionDB::get_block_snapshot(self.tx(), &self.context.chain_tip)?
                .ok_or_else(|| db_error::NotFoundError)?;
        let current_block_height = last_snapshot.block_height;

        let mut oldest_height = if current_block_height < consensus_hash_lifetime {
            0
        } else {
            current_block_height - consensus_hash_lifetime
        };

        if oldest_height < first_snapshot.block_height {
            oldest_height = first_snapshot.block_height;
        }

        if check(&last_snapshot.consensus_hash) {
            return Ok(true);
        }

        for _i in oldest_height..current_block_height {
            let ancestor_snapshot = self
                .get_block_snapshot(&last_snapshot.parent_burn_header_hash, &chain_tip)?
                .unwrap_or_else(|| {
                    panic!(
                        "Discontiguous index: missing block {}",
                        last_snapshot.parent_burn_header_hash
                    )
                });
            if check(&ancestor_snapshot.consensus_hash) {
                return Ok(true);
            }
            last_snapshot = ancestor_snapshot;
        }

        return Ok(false);
    }

    /// Find out whether or not a given consensus hash is "recent" enough to be used in this fork.
    pub fn is_fresh_consensus_hash(
        &mut self,
        consensus_hash_lifetime: u64,
        consensus_hash: &ConsensusHash,
    ) -> Result<bool, db_error> {
        self.check_fresh_consensus_hash(consensus_hash_lifetime, |fresh_hash| {
            fresh_hash == consensus_hash
        })
    }

    /// Find out whether or not a given consensus hash is "recent" enough to be used in this fork.
    /// This function only checks the first 19 bytes
    pub fn is_fresh_consensus_hash_check_19b(
        &mut self,
        consensus_hash_lifetime: u64,
        consensus_hash: &ConsensusHash,
    ) -> Result<bool, db_error> {
        self.check_fresh_consensus_hash(consensus_hash_lifetime, |fresh_hash| {
            fresh_hash.as_bytes()[0..19] == consensus_hash.as_bytes()[0..19]
        })
    }
}

impl SortitionHandle for SortitionHandleTx<'_> {
    fn get_block_snapshot_by_height(
        &mut self,
        block_height: u64,
    ) -> Result<Option<BlockSnapshot>, db_error> {
        assert!(block_height < BLOCK_HEIGHT_MAX);
        let chain_tip = self.context.chain_tip.clone();
        SortitionDB::get_ancestor_snapshot_tx(self, block_height, &chain_tip)
    }

    fn first_burn_block_height(&self) -> u64 {
        self.context.first_block_height
    }

    fn pox_constants(&self) -> &PoxConstants {
        &self.context.pox_constants
    }

    fn sqlite(&self) -> &Connection {
        self.tx()
    }

    fn tip(&self) -> SortitionId {
        self.context.chain_tip.clone()
    }

    fn get_nakamoto_tip(&self) -> Result<Option<(ConsensusHash, BlockHeaderHash, u64)>, db_error> {
        let sn = SortitionDB::get_block_snapshot(self.sqlite(), &self.context.chain_tip)?
            .ok_or(db_error::NotFoundError)?;
        SortitionDB::get_canonical_nakamoto_tip_hash_and_height(self.sqlite(), &sn)
    }
}

impl SortitionHandle for SortitionHandleConn<'_> {
    fn get_block_snapshot_by_height(
        &mut self,
        block_height: u64,
    ) -> Result<Option<BlockSnapshot>, db_error> {
        SortitionHandleConn::get_block_snapshot_by_height(self, block_height)
    }

    fn first_burn_block_height(&self) -> u64 {
        self.context.first_block_height
    }

    fn pox_constants(&self) -> &PoxConstants {
        &self.context.pox_constants
    }

    fn sqlite(&self) -> &Connection {
        self.conn()
    }

    fn tip(&self) -> SortitionId {
        self.context.chain_tip.clone()
    }

    fn get_nakamoto_tip(&self) -> Result<Option<(ConsensusHash, BlockHeaderHash, u64)>, db_error> {
        let sn = SortitionDB::get_block_snapshot(self.sqlite(), &self.context.chain_tip)?
            .ok_or(db_error::NotFoundError)?;
        SortitionDB::get_canonical_nakamoto_tip_hash_and_height(self.sqlite(), &sn)
    }
}

impl<'a> SortitionHandleTx<'a> {
    pub fn set_stacks_block_accepted(
        &mut self,
        consensus_hash: &ConsensusHash,
        stacks_block_hash: &BlockHeaderHash,
        stacks_block_height: u64,
    ) -> Result<(), db_error> {
        let chain_tip = SortitionDB::get_block_snapshot(self, &self.context.chain_tip)?.expect(
            "FAIL: Setting stacks block accepted in canonical chain tip which cannot be found",
        );

        // record new arrival
        self.set_stacks_block_accepted_at_tip(
            &chain_tip,
            consensus_hash,
            stacks_block_hash,
            stacks_block_height,
        )?;

        if cfg!(test) {
            let (ch, bhh) = SortitionDB::get_canonical_stacks_chain_tip_hash(self).unwrap();
            debug!(
                "Memoized canonical Stacks chain tip is now {}/{}, written to {}",
                &ch, &bhh, &self.context.chain_tip
            );
        }

        Ok(())
    }

    /// Get the expected PoX recipients (reward set) for the next sortition, either by querying information
    ///  from the current reward cycle, or if `next_pox_info` is provided, by querying information
    ///  for the next reward cycle.
    ///
    /// Returns None if:
    ///   * The reward cycle had an anchor block, but it isn't known by this node.
    ///   * The reward cycle did not have anchor block
    ///   * The block is in the prepare phase of a reward cycle, in which case miners must burn
    ///   * The Stacking recipient set is empty (either because this reward cycle has already exhausted the set of addresses or because no one ever Stacked).
    fn pick_recipients(
        &mut self,
        burnchain: &Burnchain,
        block_height: u64,
        reward_set_vrf_seed: &SortitionHash,
        next_pox_info: Option<&RewardCycleInfo>,
    ) -> Result<Option<RewardSetInfo>, BurnchainError> {
        if let Some(next_pox_info) = next_pox_info {
            if let PoxAnchorBlockStatus::SelectedAndKnown(
                ref anchor_block,
                ref _txid,
                ref reward_set,
            ) = next_pox_info.anchor_status
            {
                if burnchain.is_in_prepare_phase(block_height) {
                    debug!(
                        "No recipients for block {}, since in prepare phase",
                        block_height
                    );
                    return Ok(None);
                }

                test_debug!(
                    "Pick recipients for anchor block {} -- {} reward recipient(s)",
                    anchor_block,
                    reward_set.rewarded_addresses.len()
                );
                if reward_set.rewarded_addresses.len() == 0 {
                    return Ok(None);
                }

                if OUTPUTS_PER_COMMIT != 2 {
                    unreachable!("BUG: PoX reward address selection only implemented for OUTPUTS_PER_COMMIT = 2");
                }

                let chosen_recipients = reward_set_vrf_seed.choose_two(
                    reward_set
                        .rewarded_addresses
                        .len()
                        .try_into()
                        .expect("BUG: u32 overflow in PoX outputs per commit"),
                );

                Ok(Some(RewardSetInfo {
                    anchor_block: anchor_block.clone(),
                    recipients: chosen_recipients
                        .into_iter()
                        .map(|ix| {
                            let recipient = reward_set.rewarded_addresses[ix as usize].clone();
                            info!("PoX recipient chosen";
                                   "recipient" => recipient.to_burnchain_repr(),
                                   "block_height" => block_height);
                            (recipient, u16::try_from(ix).unwrap())
                        })
                        .collect(),
                }))
            } else {
                test_debug!(
                    "No anchor block known for this reward cycle (starting at {})",
                    block_height
                );
                Ok(None)
            }
        } else {
            let last_anchor = self.get_last_anchor_block_hash()?;
            if let Some(anchor_block) = last_anchor {
                // known
                // get the reward set size
                let reward_set_size = self.get_reward_set_size()?;
                if reward_set_size == 0 {
                    test_debug!(
                        "No more reward recipients descending from anchor block {}",
                        anchor_block
                    );
                    Ok(None)
                } else {
                    let chosen_recipients = reward_set_vrf_seed.choose_two(reward_set_size as u32);
                    let mut recipients = vec![];
                    for ix in chosen_recipients.into_iter() {
                        let ix = u16::try_from(ix).unwrap();
                        let recipient = self.get_reward_set_entry(ix)?;
                        info!("PoX recipient chosen";
                               "recipient" => recipient.to_burnchain_repr(),
                               "block_height" => block_height);
                        recipients.push((recipient, ix));
                    }
                    Ok(Some(RewardSetInfo {
                        anchor_block,
                        recipients,
                    }))
                }
            } else {
                // no anchor block selected
                test_debug!("No anchor block selected for this reward cycle");
                Ok(None)
            }
        }
    }

    pub fn get_reward_set_payouts_at(
        &self,
        sortition_id: &SortitionId,
    ) -> Result<(Vec<PoxAddress>, u128), db_error> {
        let sql = "SELECT pox_payouts FROM snapshots WHERE sortition_id = ?1";
        let args: &[&dyn ToSql] = &[sortition_id];
        let pox_addrs_json: String = query_row(self, sql, args)?.ok_or(db_error::NotFoundError)?;

        let pox_addrs: (Vec<PoxAddress>, u128) =
            serde_json::from_str(&pox_addrs_json).expect("FATAL: failed to decode pox payout JSON");
        Ok(pox_addrs)
    }

    pub fn get_reward_set_size_at(&mut self, sortition_id: &SortitionId) -> Result<u16, db_error> {
        self.get_indexed(sortition_id, &db_keys::pox_reward_set_size())
            .map(|x| {
                db_keys::reward_set_size_from_string(
                    &x.expect("CORRUPTION: no current reward set size written"),
                )
            })
    }

    pub fn get_reward_set_entry_at(
        &mut self,
        sortition_id: &SortitionId,
        entry_ix: u16,
    ) -> Result<PoxAddress, db_error> {
        let entry_str = self
            .get_indexed(sortition_id, &db_keys::pox_reward_set_entry(entry_ix))?
            .unwrap_or_else(|| {
                panic!(
                    "CORRUPTION: expected reward set entry at index={}, but not found",
                    entry_ix
                )
            });
        Ok(PoxAddress::from_db_string(&entry_str).expect("FATAL: could not decode PoX address"))
    }

    fn get_reward_set_entry(&mut self, entry_ix: u16) -> Result<PoxAddress, db_error> {
        self.get_reward_set_entry_at(&self.context.chain_tip.clone(), entry_ix)
    }

    fn get_reward_set_size(&mut self) -> Result<u16, db_error> {
        self.get_reward_set_size_at(&self.context.chain_tip.clone())
    }

    pub fn get_last_anchor_block_hash(&mut self) -> Result<Option<BlockHeaderHash>, db_error> {
        let chain_tip = self.context.chain_tip.clone();
        let anchor_block_hash = SortitionDB::parse_last_anchor_block_hash(
            self.get_indexed(&chain_tip, &db_keys::pox_last_anchor())?,
        );
        Ok(anchor_block_hash)
    }

    pub fn get_last_anchor_block_txid(&mut self) -> Result<Option<Txid>, db_error> {
        let chain_tip = self.context.chain_tip.clone();
        let anchor_block_txid = SortitionDB::parse_last_anchor_block_txid(
            self.get_indexed(&chain_tip, &db_keys::pox_last_anchor_txid())?,
        );
        Ok(anchor_block_txid)
    }

    pub fn get_sortition_affirmation_map(&mut self) -> Result<AffirmationMap, db_error> {
        let chain_tip = self.context.chain_tip.clone();
        let affirmation_map = match self.get_indexed(&chain_tip, &db_keys::pox_affirmation_map())? {
            Some(am_str) => {
                AffirmationMap::decode(&am_str).expect("FATAL: corrupt affirmation map")
            }
            None => AffirmationMap::empty(),
        };
        Ok(affirmation_map)
    }

    pub fn get_last_selected_anchor_block_hash(
        &mut self,
    ) -> Result<Option<BlockHeaderHash>, db_error> {
        let chain_tip = self.context.chain_tip.clone();
        let anchor_block_hash = SortitionDB::parse_last_anchor_block_hash(
            self.get_indexed(&chain_tip, &db_keys::pox_last_selected_anchor())?,
        );
        Ok(anchor_block_hash)
    }

    pub fn get_last_selected_anchor_block_txid(&mut self) -> Result<Option<Txid>, db_error> {
        let chain_tip = self.context.chain_tip.clone();
        let anchor_block_txid = SortitionDB::parse_last_anchor_block_txid(
            self.get_indexed(&chain_tip, &db_keys::pox_last_selected_anchor_txid())?,
        );
        Ok(anchor_block_txid)
    }

    /// Update the canonical Stacks tip
    fn update_canonical_stacks_tip(
        &mut self,
        sort_id: &SortitionId,
        consensus_hash: &ConsensusHash,
        stacks_block_hash: &BlockHeaderHash,
        stacks_block_height: u64,
    ) -> Result<(), db_error> {
        let sql = "INSERT OR REPLACE INTO stacks_chain_tips (sortition_id,consensus_hash,block_hash,block_height) VALUES (?1,?2,?3,?4)";
        let args: &[&dyn ToSql] = &[
            sort_id,
            consensus_hash,
            stacks_block_hash,
            &u64_to_sql(stacks_block_height)?,
        ];
        self.execute(sql, args)?;
        Ok(())
    }

    /// Mark an existing snapshot's stacks block as accepted at a particular burn chain tip within a PoX fork (identified by the consensus hash),
    /// and calculate and store its arrival index.
    /// If this Stacks block extends the canonical stacks chain tip, then also update the memoized canonical
    /// stacks chain tip metadata on the burn chain tip.
    // TODO: this method's inner call to get_indexed() can occur within a MARF transaction, which
    // means it will clone() the underlying TrieRAM.  Until this is rectified, care should be taken
    // to ensure that no keys are inserted until after this method is called.  This should already
    // be the case, since the only time keys are inserted into the sortition DB MARF is when the
    // next snapshot is processed (whereas this method is called when a Stacks epoch is processed).
    fn set_stacks_block_accepted_at_tip(
        &mut self,
        burn_tip: &BlockSnapshot,
        consensus_hash: &ConsensusHash,
        stacks_block_hash: &BlockHeaderHash,
        stacks_block_height: u64,
    ) -> Result<(), db_error> {
        let block_sn = SortitionDB::get_block_snapshot_consensus(self, consensus_hash)?
            .ok_or(db_error::NotFoundError)?;

        let cur_epoch =
            SortitionDB::get_stacks_epoch(self, block_sn.block_height)?.unwrap_or_else(|| {
                panic!(
                    "FATAL: no epoch defined for burn height {}",
                    block_sn.block_height
                )
            });

        if cur_epoch.epoch_id >= StacksEpochId::Epoch30 {
            // Nakamoto blocks are always processed in order since the chain can't fork
            self.update_canonical_stacks_tip(
                &burn_tip.sortition_id,
                consensus_hash,
                stacks_block_hash,
                stacks_block_height,
            )?;
            return Ok(());
        }

        // in epoch 2.x, where we track canonical stacks tip via the sortition DB
        let arrival_index = SortitionDB::get_max_arrival_index(self)?;
        let args: &[&dyn ToSql] = &[
            &u64_to_sql(stacks_block_height)?,
            &u64_to_sql(arrival_index + 1)?,
            consensus_hash,
            stacks_block_hash,
        ];

        debug!(
            "Set Stacks block {}/{} ({}) as arrival #{} on tip {} ({},{})",
            consensus_hash,
            stacks_block_hash,
            stacks_block_height,
            arrival_index + 1,
            &burn_tip.burn_header_hash,
            &burn_tip.consensus_hash,
            burn_tip.block_height
        );

        // NOTE: in Nakamoto, this may return zero rows since blocks are no longer coupled to
        // snapshots.  However, it will update at least one row if the block is a tenure-start
        // block.
        self.execute("UPDATE snapshots SET stacks_block_accepted = 1, stacks_block_height = ?1, arrival_index = ?2 WHERE consensus_hash = ?3 AND winning_stacks_block_hash = ?4", args)?;

        // update arrival data across all Stacks forks
        let (best_ch, best_bhh, best_height) = self.find_new_block_arrivals(burn_tip)?;
        self.update_canonical_stacks_tip(&burn_tip.sortition_id, &best_ch, &best_bhh, best_height)?;
        self.update_new_block_arrivals(burn_tip, best_ch, best_bhh, best_height)?;

        Ok(())
    }
}

impl<'a> SortitionHandleConn<'a> {
    /// open a reader handle from a consensus hash
    pub fn open_reader_consensus(
        connection: &'a SortitionDBConn<'a>,
        chain_tip: &ConsensusHash,
    ) -> Result<SortitionHandleConn<'a>, db_error> {
        let sn = match SortitionDB::get_block_snapshot_consensus(&connection.conn(), chain_tip)? {
            Some(sn) => {
                if !sn.pox_valid {
                    warn!(
                        "No such chain tip consensus hash {}: not on a valid PoX fork",
                        chain_tip
                    );
                    return Err(db_error::InvalidPoxSortition);
                }
                sn
            }
            None => {
                test_debug!("No such chain tip consensus hash {}", chain_tip);
                return Err(db_error::NotFoundError);
            }
        };

        SortitionHandleConn::open_reader(connection, &sn.sortition_id)
    }

    /// Does the sortition db expect to receive blocks
    /// signed by this signer set?
    ///
    /// This only works if `consensus_hash` is within two reward cycles (4200 blocks) of the
    /// sortition pointed to by this handle's sortiton tip.  If it isn't, then this
    /// method returns Ok(false).  This is to prevent a DDoS vector whereby compromised stale
    /// Signer keys can be used to blast out lots of Nakamoto blocks that will be accepted
    /// but never processed.  So, `consensus_hash` can be in the same reward cycle as
    /// `self.context.chain_tip`, or the previous, but no earlier.
    pub fn expects_signer_signature(
        &self,
        consensus_hash: &ConsensusHash,
        signer_signature: &WSTSSignature,
        message: &[u8],
        aggregate_public_key: &Point,
    ) -> Result<bool, db_error> {
        let sn = SortitionDB::get_block_snapshot(self, &self.context.chain_tip)?
            .ok_or(db_error::NotFoundError)
            .map_err(|e| {
                warn!("No sortition for tip: {:?}", &self.context.chain_tip);
                e
            })?;

        let ch_sn = SortitionDB::get_block_snapshot_consensus(self, consensus_hash)?
            .ok_or(db_error::NotFoundError)
            .map_err(|e| {
                warn!("No sortition for consensus hash: {:?}", consensus_hash);
                e
            })?;

        if ch_sn.block_height
            + u64::from(self.context.pox_constants.reward_cycle_length)
            + u64::from(self.context.pox_constants.prepare_length)
            < sn.block_height
        {
            // too far in the past
            debug!("Block with consensus hash {} is too far in the past", consensus_hash;
                   "consensus_hash" => %consensus_hash,
                   "block_height" => ch_sn.block_height,
                   "tip_block_height" => sn.block_height
            );
            return Ok(false);
        }

        // this given consensus hash must be an ancestor of our chain tip
        let ch_at = self
            .get_consensus_at(ch_sn.block_height)?
            .ok_or(db_error::NotFoundError)
            .map_err(|e| {
                warn!("No ancestor consensus hash";
                      "tip" => %self.context.chain_tip,
                      "consensus_hash" => %consensus_hash,
                      "consensus_hash height" => %ch_sn.block_height
                );
                e
            })?;

        if ch_at != ch_sn.consensus_hash {
            // not an ancestor
            warn!("Consensus hash is not an ancestor of the sortition tip";
                  "tip" => %self.context.chain_tip,
                  "consensus_hash" => %consensus_hash
            );
            return Err(db_error::NotFoundError);
        }

        // is this consensus hash in this fork?
        if SortitionDB::get_burnchain_header_hash_by_consensus(self, consensus_hash)?.is_none() {
            return Ok(false);
        }

        Ok(signer_signature.verify(aggregate_public_key, message))
    }

    pub fn get_reward_set_size_at(&self, sortition_id: &SortitionId) -> Result<u16, db_error> {
        self.get_indexed(sortition_id, &db_keys::pox_reward_set_size())
            .map(|x| {
                db_keys::reward_set_size_from_string(
                    &x.expect("CORRUPTION: no current reward set size written"),
                )
            })
    }

    pub fn get_last_anchor_block_hash(&self) -> Result<Option<BlockHeaderHash>, db_error> {
        let anchor_block_hash = SortitionDB::parse_last_anchor_block_hash(
            self.get_indexed(&self.context.chain_tip, &db_keys::pox_last_anchor())?,
        );
        Ok(anchor_block_hash)
    }

    pub fn get_last_anchor_block_txid(&self) -> Result<Option<Txid>, db_error> {
        let anchor_block_txid = SortitionDB::parse_last_anchor_block_txid(
            self.get_indexed(&self.context.chain_tip, &db_keys::pox_last_anchor_txid())?,
        );
        Ok(anchor_block_txid)
    }

    pub fn get_sortition_affirmation_map(&self) -> Result<AffirmationMap, db_error> {
        let chain_tip = self.context.chain_tip.clone();
        let affirmation_map = match self.get_indexed(&chain_tip, &db_keys::pox_affirmation_map())? {
            Some(am_str) => {
                AffirmationMap::decode(&am_str).expect("FATAL: corrupt affirmation map")
            }
            None => AffirmationMap::empty(),
        };
        Ok(affirmation_map)
    }

    pub fn get_last_selected_anchor_block_hash(&self) -> Result<Option<BlockHeaderHash>, db_error> {
        let anchor_block_hash = SortitionDB::parse_last_anchor_block_hash(self.get_indexed(
            &self.context.chain_tip,
            &db_keys::pox_last_selected_anchor(),
        )?);
        Ok(anchor_block_hash)
    }

    pub fn get_last_selected_anchor_block_txid(&self) -> Result<Option<Txid>, db_error> {
        let anchor_block_txid = SortitionDB::parse_last_anchor_block_txid(self.get_indexed(
            &self.context.chain_tip,
            &db_keys::pox_last_selected_anchor_txid(),
        )?);
        Ok(anchor_block_txid)
    }

    /// Get the last processed reward cycle.
    /// Since we always process a RewardSetInfo at the start of a reward cycle (anchor block or
    /// no), this is simply the same as asking which reward cycle this SortitionHandleConn's
    /// sortition tip is in.
    pub fn get_last_processed_reward_cycle(&self) -> Result<u64, db_error> {
        let sn = SortitionDB::get_block_snapshot(self, &self.context.chain_tip)?
            .ok_or(db_error::NotFoundError)?;
        let rc = self
            .context
            .pox_constants
            .block_height_to_reward_cycle(self.context.first_block_height, sn.block_height)
            .expect("FATAL: sortition from before system start");
        let rc_start_block = self
            .context
            .pox_constants
            .reward_cycle_to_block_height(self.context.first_block_height, rc);
        let last_rc = if sn.block_height >= rc_start_block {
            rc
        } else {
            // NOTE: the reward cycle is "processed" at reward cycle index 1, not index 0
            rc.saturating_sub(1)
        };

        Ok(last_rc)
    }

    pub fn get_reward_cycle_unlocks(
        &mut self,
        cycle: u64,
    ) -> Result<Option<PoxStartCycleInfo>, db_error> {
        let start_info = self
            .get_tip_indexed(&db_keys::pox_reward_cycle_unlocks(cycle))?
            .map(|x| {
                PoxStartCycleInfo::deserialize(&x)
                    .expect("CORRUPTION: Failed to deserialize PoxStartCycleInfo from database")
            });
        Ok(start_info)
    }

    pub fn get_pox_id(&self) -> Result<PoxId, db_error> {
        let pox_id = self
            .get_tip_indexed(db_keys::pox_identifier())?
            .map(|s| s.parse().expect("BUG: Bad PoX identifier stored in DB"))
            .expect("BUG: No PoX identifier stored.");
        Ok(pox_id)
    }

    /// open a reader handle
    pub fn open_reader(
        connection: &'a SortitionDBConn<'a>,
        chain_tip: &SortitionId,
    ) -> Result<SortitionHandleConn<'a>, db_error> {
        Ok(SortitionHandleConn {
            context: SortitionHandleContext {
                chain_tip: chain_tip.clone(),
                first_block_height: connection.context.first_block_height,
                pox_constants: connection.context.pox_constants.clone(),
                dryrun: connection.context.dryrun,
            },
            index: &connection.index,
        })
    }

    fn get_tip_indexed(&self, key: &str) -> Result<Option<String>, db_error> {
        self.get_indexed(&self.context.chain_tip, key)
    }

    fn get_sortition_id_for_bhh(
        &self,
        burn_header_hash: &BurnchainHeaderHash,
    ) -> Result<Option<SortitionId>, db_error> {
        let sortition_identifier_key = db_keys::sortition_id_for_bhh(burn_header_hash);
        let sortition_id = match self.get_tip_indexed(&sortition_identifier_key)? {
            None => return Ok(None),
            Some(x) => SortitionId::from_hex(&x).expect("FATAL: bad Sortition ID stored in DB"),
        };
        Ok(Some(sortition_id))
    }

    /// Uses the handle's current fork identifier to get a block snapshot by
    ///   burnchain block header
    /// If the burn header hash is _not_ in the current fork, then this will return Ok(None)
    pub fn get_block_snapshot(
        &self,
        burn_header_hash: &BurnchainHeaderHash,
    ) -> Result<Option<BlockSnapshot>, db_error> {
        let sortition_id = match self.get_sortition_id_for_bhh(burn_header_hash)? {
            None => return Ok(None),
            Some(x) => x,
        };
        SortitionDB::get_block_snapshot(self.conn(), &sortition_id)
    }

    /// Has `consensus_hash` been processed in the current fork?
    pub fn processed_block(&self, consensus_hash: &ConsensusHash) -> Result<bool, db_error> {
        let Some(snapshot) = SortitionDB::get_block_snapshot_consensus(self, consensus_hash)?
        else {
            return Ok(false);
        };
        let Some(expected_sortition_id) =
            self.get_sortition_id_for_bhh(&snapshot.burn_header_hash)?
        else {
            return Ok(false);
        };
        let matched_fork = expected_sortition_id == snapshot.sortition_id;
        Ok(matched_fork)
    }

    pub fn get_tip_snapshot(&self) -> Result<Option<BlockSnapshot>, db_error> {
        SortitionDB::get_block_snapshot(self.conn(), &self.context.chain_tip)
    }

    pub fn get_first_block_snapshot(&self) -> Result<BlockSnapshot, db_error> {
        SortitionDB::get_first_block_snapshot(self.conn())
    }

    /// Get consensus hash from a particular chain tip's history
    /// Returns None if the block height or block hash does not correspond to a
    /// known snapshot.
    pub fn get_consensus_at(&self, block_height: u64) -> Result<Option<ConsensusHash>, db_error> {
        assert!(block_height < BLOCK_HEIGHT_MAX);

        match SortitionDB::get_ancestor_snapshot(self, block_height, &self.context.chain_tip)? {
            Some(sn) => Ok(Some(sn.consensus_hash)),
            None => Ok(None),
        }
    }

    pub fn get_block_snapshot_by_height(
        &self,
        block_height: u64,
    ) -> Result<Option<BlockSnapshot>, db_error> {
        assert!(block_height < BLOCK_HEIGHT_MAX);

        // Note: This would return None if `block_height` were the height of `chain_tip`.
        SortitionDB::get_ancestor_snapshot(self, block_height, &self.context.chain_tip)
    }

    /// Get the block snapshot of the parent stacks block of the given stacks block.
    /// The returned block-commit is for the given (consensus_hash, block_hash).
    /// The returned BlockSnapshot is for the parent of the block identified by (consensus_hash,
    /// block_hash).
    pub fn get_block_snapshot_of_parent_stacks_block(
        &self,
        consensus_hash: &ConsensusHash,
        block_hash: &BlockHeaderHash,
    ) -> Result<Option<(LeaderBlockCommitOp, BlockSnapshot)>, db_error> {
        let block_commit = match SortitionDB::get_block_commit_for_stacks_block(
            self.conn(),
            consensus_hash,
            &block_hash,
        )? {
            Some(bc) => bc,
            None => {
                // unsoliciated
                debug!("No block commit for {}/{}", consensus_hash, block_hash);
                return Ok(None);
            }
        };

        // get the stacks chain tip this block commit builds off of
        let stacks_chain_tip =
            if block_commit.parent_block_ptr == 0 && block_commit.parent_vtxindex == 0 {
                // no parent -- this is the first-ever Stacks block in this fork
                test_debug!(
                    "Block {}/{} mines off of genesis",
                    consensus_hash,
                    block_hash
                );
                self.get_first_block_snapshot()?
            } else {
                let parent_commit = match self.get_block_commit_parent(
                    block_commit.parent_block_ptr.into(),
                    block_commit.parent_vtxindex.into(),
                )? {
                    Some(commit) => commit,
                    None => {
                        // unsolicited -- orphaned
                        warn!(
                        "Received unsolicited block, could not find parent: {}/{}, parent={}/{}",
                        consensus_hash, block_hash, block_commit.parent_block_ptr, consensus_hash
                    );
                        return Ok(None);
                    }
                };

                debug!(
                    "Block {}/{} mines off of parent {},{}",
                    consensus_hash, block_hash, parent_commit.block_height, parent_commit.vtxindex
                );
                self.get_block_snapshot(&parent_commit.burn_header_hash)?
                    .expect("FATAL: burn DB does not have snapshot for parent block commit")
            };

        Ok(Some((block_commit, stacks_chain_tip)))
    }

    /// Get the latest block snapshot on this fork where a sortition occured.
    /// Search snapshots up to (but excluding) the given block height.
    /// Will always return a snapshot -- even if it's the initial sentinel snapshot.
    pub fn get_last_snapshot_with_sortition(
        &self,
        burn_block_height: u64,
    ) -> Result<BlockSnapshot, db_error> {
        assert!(burn_block_height < BLOCK_HEIGHT_MAX);
        test_debug!(
            "Get snapshot at from sortition tip {}, expect height {}",
            &self.context.chain_tip,
            burn_block_height
        );
        let get_from = match get_ancestor_sort_id(self, burn_block_height, &self.context.chain_tip)?
        {
            Some(sortition_id) => sortition_id,
            None => {
                error!(
                    "No blockheight {} ancestor at sortition identifier {}",
                    burn_block_height, &self.context.chain_tip
                );
                return Err(db_error::NotFoundError);
            }
        };

        let ancestor_hash = match self.get_indexed(&get_from, &db_keys::last_sortition())? {
            Some(hex_str) => BurnchainHeaderHash::from_hex(&hex_str).unwrap_or_else(|_| {
                panic!(
                    "FATAL: corrupt database: failed to parse {} into a hex string",
                    &hex_str
                )
            }),
            None => {
                // no prior sortitions, so get the first
                return self.get_first_block_snapshot();
            }
        };

        self.get_block_snapshot(&ancestor_hash).map(|snapshot_opt| {
            snapshot_opt
                .unwrap_or_else(|| panic!("FATAL: corrupt index: no snapshot {}", ancestor_hash))
        })
    }

    pub fn get_leader_key_at(
        &self,
        key_block_height: u64,
        key_vtxindex: u32,
    ) -> Result<Option<LeaderKeyRegisterOp>, db_error> {
        SortitionDB::get_leader_key_at(
            self,
            key_block_height,
            key_vtxindex,
            &self.context.chain_tip,
        )
    }

    pub fn get_block_commit_parent(
        &self,
        block_height: u64,
        vtxindex: u32,
    ) -> Result<Option<LeaderBlockCommitOp>, db_error> {
        SortitionDB::get_block_commit_parent(self, block_height, vtxindex, &self.context.chain_tip)
    }

    /// Get a block commit by txid. In the event of a burnchain fork, this may not be unique.
    ///   this function simply returns one of those block commits: only use data that is
    ///   immutable across burnchain/pox forks, e.g., parent block ptr,  
    pub fn get_block_commit_by_txid(
        &self,
        sort_id: &SortitionId,
        txid: &Txid,
    ) -> Result<Option<LeaderBlockCommitOp>, db_error> {
        get_block_commit_by_txid(self.conn(), sort_id, txid)
    }

    /// Return a vec of sortition winner's burn header hash and stacks header hash, ordered by
    ///   increasing block height in the range (block_height_begin, block_height_end]
    fn get_sortition_winners_in_fork(
        &self,
        block_height_begin: u32,
        block_height_end: u32,
    ) -> Result<Vec<(SortitionId, Txid, u64)>, BurnchainError> {
        let mut result = vec![];
        for height in (block_height_begin + 1)..(block_height_end + 1) {
            debug!("Looking for winners at height = {}", height);
            let snapshot =
                SortitionDB::get_ancestor_snapshot(self, height as u64, &self.context.chain_tip)?
                    .ok_or_else(|| {
                    warn!("Missing parent"; "sortition_height" => %height);
                    BurnchainError::MissingParentBlock
                })?;
            if snapshot.sortition {
                result.push((
                    snapshot.sortition_id,
                    snapshot.winning_block_txid,
                    snapshot.block_height,
                ));
            }
        }
        Ok(result)
    }

    /// Helper method to get the burn block height of the end of a prepare phase block.
    /// Returns Ok(Some((effective_height, absolute_height))) on success
    /// Returns Ok(None) if the effective height of this block was 0, meaning that it's the first
    /// block.
    /// Returns Err(BurnchainError::MissingParentBlock) if we couldn't find the sortition for this
    /// burnchain block hash
    /// Returns Err(CoordiantorError::NotPrepareEndBlock) if this wasn't the last block in a
    /// prepare phase.
    fn get_heights_for_prepare_phase_end_block(
        &self,
        prepare_end_bhh: &BurnchainHeaderHash,
        pox_consts: &PoxConstants,
        check_position: bool,
    ) -> Result<Option<(u32, u32)>, CoordinatorError> {
        let prepare_end_sortid =
            self.get_sortition_id_for_bhh(prepare_end_bhh)?
                .ok_or_else(|| {
                    warn!("Missing parent"; "burn_header_hash" => %prepare_end_bhh, "sortition_tip" => %&self.context.chain_tip);
                    BurnchainError::MissingParentBlock
                })?;
        let block_height = SortitionDB::get_block_height(self.deref(), &prepare_end_sortid)?
            .expect("CORRUPTION: SortitionID known, but no block height in SQL store");

        // if this block is the _end_ of a prepare phase,
        let effective_height = block_height - self.context.first_block_height as u32;
        let position_in_cycle = effective_height % pox_consts.reward_cycle_length;
        if position_in_cycle != 0 {
            debug!(
                "effective_height = {}, reward cycle length == {}",
                effective_height, pox_consts.reward_cycle_length
            );
            if check_position {
                return Err(CoordinatorError::NotPrepareEndBlock);
            }
        }

        if effective_height == 0 {
            debug!(
                "effective_height = {}, reward cycle length == {}",
                effective_height, pox_consts.reward_cycle_length
            );
            return Ok(None);
        }

        Ok(Some((effective_height, block_height)))
    }

    /// Get the chosen PoX anchor block for a reward cycle, given the last block of its prepare
    /// phase.
    ///
    /// In epochs 2.05 and earlier, this was the Stacks block that received F*w confirmations.
    ///
    /// In epoch 2.1 and later, this was the Stacks block whose block-commit received not only F*w
    /// confirmations from subsequent block-commits in the prepare phase, but also the most BTC
    /// burnt from all such candidates (and if there is still a tie, then the higher block-commit
    /// is chosen).  In particular, the block-commit is not required to be the winning block-commit
    /// or even a valid block-commit, unlike in 2.05.  However, this will be a winning block-commit
    /// if at least 20% of the BTC was spent honestly.
    ///
    /// Here, instead of reasoning about which epoch we're in, the caller will instead supply an
    /// optional handle to the burnchain database.  If it's `Some(..)`, then the epoch 2.1 rules
    /// are used -- the PoX anchor block will be determined from block-commits.  If it's `None`,
    /// then the epoch 2.05 rules are used -- the PoX anchor block will be determined from present
    /// Stacks blocks.
    pub fn get_chosen_pox_anchor(
        &self,
        burnchain_db_conn: Option<&DBConn>,
        prepare_end_bhh: &BurnchainHeaderHash,
        pox_consts: &PoxConstants,
    ) -> Result<Option<(ConsensusHash, BlockHeaderHash, Txid)>, CoordinatorError> {
        match burnchain_db_conn {
            Some(conn) => self.get_chosen_pox_anchor_v210(conn, prepare_end_bhh, pox_consts),
            None => self.get_chosen_pox_anchor_v205(prepare_end_bhh, pox_consts),
        }
    }

    /// Use the epoch 2.1 method for choosing a PoX anchor block.
    /// The PoX anchor block corresponds to the block-commit that received F*w confirmations in its
    /// prepare phase, and had the most BTC of all such candidates, and was the highest of all such
    /// candidates.  This information is stored in the burnchain DB.
    ///
    /// Note that it does not matter if the anchor block-commit does not correspond to a valid
    /// Stacks block, or even won sortition.  The result is the same for the honest network
    /// participants: they mark the anchor block as absent in their affirmation maps, and this PoX
    /// fork's quality is degraded as such.
    pub fn get_chosen_pox_anchor_v210(
        &self,
        burnchain_db_conn: &DBConn,
        prepare_end_bhh: &BurnchainHeaderHash,
        pox_consts: &PoxConstants,
    ) -> Result<Option<(ConsensusHash, BlockHeaderHash, Txid)>, CoordinatorError> {
        let rc = match self.get_heights_for_prepare_phase_end_block(
            prepare_end_bhh,
            pox_consts,
            true,
        )? {
            Some((_, block_height)) => {
                let rc = pox_consts
                    .block_height_to_reward_cycle(
                        self.context.first_block_height,
                        block_height.into(),
                    )
                    .ok_or(CoordinatorError::NotPrepareEndBlock)?;
                rc
            }
            None => {
                // there can't be an anchor block
                return Ok(None);
            }
        };
        let (anchor_block_op, anchor_block_metadata) = {
            let mut res = None;
            let metadatas = BurnchainDB::get_anchor_block_commit_metadatas(burnchain_db_conn, rc)?;

            // find the one on this fork
            for metadata in metadatas {
                let sn = SortitionDB::get_ancestor_snapshot(
                    self,
                    metadata.block_height,
                    &self.context.chain_tip,
                )?
                .expect("FATAL: accepted block-commit but no sortition at height");
                if sn.burn_header_hash == metadata.burn_block_hash {
                    // this is the metadata on this burnchain fork
                    res = match BurnchainDB::get_anchor_block_commit(
                        burnchain_db_conn,
                        &sn.burn_header_hash,
                        rc,
                    )? {
                        Some(x) => Some(x),
                        None => {
                            continue;
                        }
                    };
                    if res.is_some() {
                        break;
                    }
                }
            }
            if let Some(x) = res {
                x
            } else {
                // no anchor block
                test_debug!("No anchor block for reward cycle {}", rc);
                return Ok(None);
            }
        };

        // sanity check: we must have processed this burnchain block already
        let anchor_sort_id = self.get_sortition_id_for_bhh(&anchor_block_metadata.burn_block_hash)?
            .ok_or_else(|| {
                warn!("Missing anchor block sortition"; "burn_header_hash" => %anchor_block_metadata.burn_block_hash, "sortition_tip" => %&self.context.chain_tip);
                BurnchainError::MissingParentBlock
            })?;

        let anchor_sn = SortitionDB::get_block_snapshot(self, &anchor_sort_id)?
            .ok_or(BurnchainError::MissingParentBlock)?;

        // the sortition does not even need to have picked this anchor block; all that matters is
        // that miners confirmed it.  If the winning block hash doesn't even correspond to a Stacks
        // block, then the honest miners in the network will affirm that it's absent.
        let ch = anchor_sn.consensus_hash;
        Ok(Some((
            ch,
            anchor_block_op.block_header_hash,
            anchor_block_op.txid,
        )))
    }

    /// This is the method for calculating the PoX anchor block for a reward cycle in epoch 2.05 and earlier.
    /// Return identifying information for a PoX anchor block for the reward cycle that
    ///   begins the block after `prepare_end_bhh`.
    /// If a PoX anchor block is chosen, this returns Some, if a PoX anchor block was not
    ///   selected, return `None`
    /// `prepare_end_bhh`: this is the burn block which is the last block in the prepare phase
    ///                 for the corresponding reward cycle
    fn get_chosen_pox_anchor_v205(
        &self,
        prepare_end_bhh: &BurnchainHeaderHash,
        pox_consts: &PoxConstants,
    ) -> Result<Option<(ConsensusHash, BlockHeaderHash, Txid)>, CoordinatorError> {
        match self.get_chosen_pox_anchor_check_position_v205(prepare_end_bhh, pox_consts, true) {
            Ok(Ok((c_hash, bh_hash, txid, _))) => Ok(Some((c_hash, bh_hash, txid))),
            Ok(Err(_)) => Ok(None),
            Err(e) => Err(e),
        }
    }

    /// This is the method for calculating the PoX anchor block for a reward cycle in epoch 2.05 and earlier.
    /// If no PoX anchor block is found, it returns Ok(Err(maximum confirmations of all candidates))
    pub fn get_chosen_pox_anchor_check_position_v205(
        &self,
        prepare_end_bhh: &BurnchainHeaderHash,
        pox_consts: &PoxConstants,
        check_position: bool,
    ) -> Result<Result<(ConsensusHash, BlockHeaderHash, Txid, u32), u32>, CoordinatorError> {
        let (effective_height, block_height) = match self.get_heights_for_prepare_phase_end_block(
            prepare_end_bhh,
            pox_consts,
            check_position,
        )? {
            Some(x) => x,
            None => {
                // effective height was 0
                return Ok(Err(0));
            }
        };

        let prepare_end = block_height;
        let prepare_begin = prepare_end.saturating_sub(pox_consts.prepare_length);

        let mut candidate_anchors = HashMap::new();
        let mut memoized_candidates: HashMap<_, (SortitionId, Txid, u64)> = HashMap::new();

        // iterate over every sortition winner in the prepare phase
        //   looking for their highest ancestor _before_ prepare_begin.
        let winners = self.get_sortition_winners_in_fork(prepare_begin, prepare_end)?;
        for (winner_sort_id, winner_commit_txid, winner_block_height) in winners.into_iter() {
            let mut cursor = (winner_sort_id, winner_commit_txid, winner_block_height);
            let mut found_ancestor = true;

            while cursor.2 > (prepare_begin as u64) {
                // check if we've already discovered the candidate for this block
                if let Some(ancestor) = memoized_candidates.get(&cursor.2) {
                    cursor = ancestor.clone();
                } else {
                    // get the block commit
                    let block_commit = self.get_block_commit_by_txid(&cursor.0, &cursor.1)?.expect(
                        "CORRUPTED: Failed to fetch block commit for known sortition winner",
                    );
                    // is this a height=1 block?
                    if block_commit.is_parent_genesis() {
                        debug!("First parent before prepare phase for block winner is the genesis block, dropping block's PoX anchor vote";
                               "sortition_id" => %&cursor.0,
                               "winner_txid" => %&cursor.1,
                               "burn_block_height" => cursor.2);
                        found_ancestor = false;
                        break;
                    }

                    // find the parent sortition
                    let sn = SortitionDB::get_ancestor_snapshot(
                        self,
                        block_commit.parent_block_ptr as u64,
                        &self.context.chain_tip,
                    )?
                    .expect(
                        "CORRUPTED: accepted block commit, but parent pointer not in sortition set",
                    );
                    assert!(sn.sortition, "CORRUPTED: accepted block commit, but parent pointer not a sortition winner");

                    cursor = (sn.sortition_id, sn.winning_block_txid, sn.block_height);
                }
            }
            if !found_ancestor {
                continue;
            }
            // this is the burn block height of the sortition that chose the
            //   highest ancestor of winner_stacks_bh whose sortition occurred before prepare_begin
            //  the winner of that sortition is the PoX anchor block candidate that winner_stacks_bh is "voting for"
            let highest_ancestor = cursor.2;
            memoized_candidates.insert(winner_block_height, cursor);
            if let Some(x) = candidate_anchors.get_mut(&highest_ancestor) {
                *x += 1;
            } else {
                candidate_anchors.insert(highest_ancestor, 1u32);
            }
        }

        // did any candidate receive >= F*w?
        let mut result = None;
        let mut max_confirmed_by = 0;
        for (candidate, confirmed_by) in candidate_anchors.into_iter() {
            if confirmed_by > max_confirmed_by {
                max_confirmed_by = confirmed_by;
            }
            if confirmed_by >= pox_consts.anchor_threshold {
                // find the sortition at height
                let sn =
                    SortitionDB::get_ancestor_snapshot(self, candidate, &self.context.chain_tip)?
                        .expect("BUG: cannot find chosen PoX candidate's sortition");
                assert!(
                    result
                        .replace((
                            sn.consensus_hash,
                            sn.winning_stacks_block_hash,
                            sn.winning_block_txid,
                            confirmed_by
                        ))
                        .is_none(),
                    "BUG: multiple anchor blocks received more confirmations than anchor_threshold"
                );
            }
        }

        let reward_cycle_id = effective_height / pox_consts.reward_cycle_length;
        match result {
            None => {
                info!(
                    "Reward cycle #{} ({}): (F*w) not reached, expecting consensus over proof of burn",
                    reward_cycle_id, block_height
                );
                Ok(Err(max_confirmed_by))
            }
            Some(response) => {
                info!("Reward cycle #{} ({}): {:?} reached (F*w), expecting consensus over proof of transfer", reward_cycle_id, block_height, result);
                Ok(Ok(response))
            }
        }
    }
}

// Connection methods
impl SortitionDB {
    /// Begin a transaction.
    pub fn tx_begin<'a>(&'a mut self) -> Result<SortitionDBTx<'a>, db_error> {
        if !self.readwrite {
            return Err(db_error::ReadOnly);
        }

        let index_tx = SortitionDBTx::new(
            &mut self.marf,
            SortitionDBTxContext {
                first_block_height: self.first_block_height,
                pox_constants: self.pox_constants.clone(),
                dryrun: self.dryrun,
            },
        );
        Ok(index_tx)
    }

    /// Make an indexed connectino
    pub fn index_conn<'a>(&'a self) -> SortitionDBConn<'a> {
        SortitionDBConn::new(
            &self.marf,
            SortitionDBTxContext {
                first_block_height: self.first_block_height,
                pox_constants: self.pox_constants.clone(),
                dryrun: self.dryrun,
            },
        )
    }

    pub fn index_handle<'a>(&'a self, chain_tip: &SortitionId) -> SortitionHandleConn<'a> {
        SortitionHandleConn::new(
            &self.marf,
            SortitionHandleContext {
                first_block_height: self.first_block_height,
                chain_tip: chain_tip.clone(),
                pox_constants: self.pox_constants.clone(),
                dryrun: self.dryrun,
            },
        )
    }

    pub fn tx_handle_begin<'a>(
        &'a mut self,
        chain_tip: &SortitionId,
    ) -> Result<SortitionHandleTx<'a>, db_error> {
        if !self.readwrite {
            return Err(db_error::ReadOnly);
        }
        Ok(SortitionHandleTx::new(
            &mut self.marf,
            SortitionHandleContext {
                first_block_height: self.first_block_height,
                chain_tip: chain_tip.clone(),
                pox_constants: self.pox_constants.clone(),
                dryrun: self.dryrun,
            },
        ))
    }

    pub fn conn<'a>(&'a self) -> &'a Connection {
        self.marf.sqlite_conn()
    }

    fn open_index(index_path: &str) -> Result<MARF<SortitionId>, db_error> {
        test_debug!("Open index at {}", index_path);
        let open_opts = MARFOpenOpts::default();
        let marf = MARF::from_path(index_path, open_opts).map_err(|_e| db_error::Corruption)?;
        sql_pragma(marf.sqlite_conn(), "foreign_keys", &true)?;
        Ok(marf)
    }

    /// Open the database on disk.  It must already exist and be instantiated.
    /// It's best not to call this if you are able to call connect().  If you must call this, do so
    /// after you call connect() somewhere else, since connect() performs additional validations.
    pub fn open(
        path: &str,
        readwrite: bool,
        pox_constants: PoxConstants,
    ) -> Result<SortitionDB, db_error> {
        let index_path = db_mkdirs(path)?;
        debug!(
            "Open sortdb as '{}', with index as '{}'",
            if readwrite { "readwrite" } else { "readonly" },
            index_path
        );

        let marf = SortitionDB::open_index(&index_path)?;
        let (first_block_height, first_burn_header_hash) =
            SortitionDB::get_first_block_height_and_hash(marf.sqlite_conn())?;

        let mut db = SortitionDB {
            path: path.to_string(),
            marf,
            readwrite,
            dryrun: false,
            pox_constants,
            first_block_height,
            first_burn_header_hash,
        };

        db.check_schema_version_or_error()?;
        Ok(db)
    }

    /// Open a new copy of this SortitionDB. Will use the same `readwrite` flag
    ///  of `self`.
    pub fn reopen(&self) -> Result<SortitionDB, db_error> {
        Self::open(&self.path, self.readwrite, self.pox_constants.clone())
    }

    /// Open the burn database at the given path.  Open read-only or read/write.
    /// If opened for read/write and it doesn't exist, instantiate it.
    pub fn connect(
        path: &str,
        first_block_height: u64,
        first_burn_hash: &BurnchainHeaderHash,
        first_burn_header_timestamp: u64,
        epochs: &[StacksEpoch],
        pox_constants: PoxConstants,
        migrator: Option<SortitionDBMigrator>,
        readwrite: bool,
    ) -> Result<SortitionDB, db_error> {
        let create_flag = match fs::metadata(path) {
            Err(e) => {
                if e.kind() == ErrorKind::NotFound {
                    // need to create
                    if readwrite {
                        true
                    } else {
                        return Err(db_error::NoDBError);
                    }
                } else {
                    return Err(db_error::IOError(e));
                }
            }
            Ok(_md) => false,
        };

        let index_path = db_mkdirs(path)?;
        debug!(
            "Connect/Open {} sortdb as '{}', with index as '{}'",
            if create_flag { "(create)" } else { "" },
            if readwrite { "readwrite" } else { "readonly" },
            index_path
        );

        let marf = SortitionDB::open_index(&index_path)?;

        let mut db = SortitionDB {
            path: path.to_string(),
            marf,
            readwrite,
            dryrun: false,
            first_block_height,
            pox_constants,
            first_burn_header_hash: first_burn_hash.clone(),
        };

        if create_flag {
            // instantiate!
            db.instantiate(
                first_block_height,
                first_burn_hash,
                first_burn_header_timestamp,
                epochs,
            )?;
        }

        db.check_schema_version_and_update(epochs, migrator)?;

        // validate -- must contain the given first block and first block hash
        let snapshot = SortitionDB::get_first_block_snapshot(db.conn())?;
        if !snapshot.is_initial()
            || snapshot.block_height != first_block_height
            || snapshot.burn_header_hash != *first_burn_hash
        {
            error!("Invalid genesis snapshot: sn.is_initial = {}, sn.block_height = {}, sn.burn_hash = {}, expect.block_height = {}, expect.burn_hash = {}",
                   snapshot.is_initial(), snapshot.block_height, &snapshot.burn_header_hash, first_block_height, first_burn_hash);
            return Err(db_error::Corruption);
        }

        if readwrite {
            db.add_indexes()?;
        }

        Ok(db)
    }

    fn instantiate(
        &mut self,
        first_block_height: u64,
        first_burn_header_hash: &BurnchainHeaderHash,
        first_burn_header_timestamp: u64,
        epochs_ref: &[StacksEpoch],
    ) -> Result<(), db_error> {
        debug!(
            "Instantiate SortDB: first block is {},{}",
            first_block_height, first_burn_header_hash
        );

        sql_pragma(self.conn(), "journal_mode", &"WAL")?;
        sql_pragma(self.conn(), "foreign_keys", &true)?;

        let mut db_tx = SortitionHandleTx::begin(self, &SortitionId::sentinel())?;

        // create first (sentinel) snapshot
        debug!("Make first snapshot");
        let mut first_snapshot = BlockSnapshot::initial(
            first_block_height,
            first_burn_header_hash,
            first_burn_header_timestamp,
        );

        assert!(first_snapshot.parent_burn_header_hash != first_snapshot.burn_header_hash);
        assert_eq!(
            first_snapshot.parent_burn_header_hash,
            BurnchainHeaderHash::sentinel()
        );

        for row_text in SORTITION_DB_INITIAL_SCHEMA {
            db_tx.execute_batch(row_text)?;
        }
        SortitionDB::apply_schema_2(&db_tx, epochs_ref)?;
        SortitionDB::apply_schema_3(&db_tx)?;
        SortitionDB::apply_schema_4(&db_tx)?;
        SortitionDB::apply_schema_5(&db_tx, epochs_ref)?;
        SortitionDB::apply_schema_6(&db_tx, epochs_ref)?;
        SortitionDB::apply_schema_7(&db_tx, epochs_ref)?;
        SortitionDB::apply_schema_8_tables(&db_tx, epochs_ref)?;

        db_tx.instantiate_index()?;

        let mut first_sn = first_snapshot.clone();
        first_sn.sortition_id = SortitionId::sentinel();
        let (index_root, pox_payout) =
            db_tx.index_add_fork_info(&mut first_sn, &first_snapshot, &[], None, None, None)?;
        first_snapshot.index_root = index_root;

        db_tx.insert_block_snapshot(&first_snapshot, pox_payout)?;
        db_tx.store_transition_ops(
            &first_snapshot.sortition_id,
            &BurnchainStateTransition::noop(),
        )?;

        db_tx.commit()?;

        // NOTE: we don't need to provide a migrator here because we're not migrating
        self.apply_schema_8_migration(None)?;

        self.add_indexes()?;

        debug!("Instantiated SortDB");
        Ok(())
    }

    /// Validates given StacksEpochs (will runtime panic if there is any invalid StacksEpoch structuring) and
    ///  inserts them into the SortitionDB's epochs table.
    fn validate_and_insert_epochs(
        db_tx: &Transaction,
        epochs: &[StacksEpoch],
    ) -> Result<(), db_error> {
        let epochs = StacksEpoch::validate_epochs(epochs);
        for epoch in epochs.into_iter() {
            let args: &[&dyn ToSql] = &[
                &(epoch.epoch_id as u32),
                &u64_to_sql(epoch.start_height)?,
                &u64_to_sql(epoch.end_height)?,
                &epoch.block_limit,
                &epoch.network_epoch,
            ];
            db_tx.execute(
                "INSERT INTO epochs (epoch_id,start_block_height,end_block_height,block_limit,network_epoch) VALUES (?1,?2,?3,?4,?5)",
                args
            )?;
        }
        Ok(())
    }

    /// Validates given StacksEpochs (will runtime panic if there is any invalid StacksEpoch structuring) and
    /// replaces them into the SortitionDB's epochs table
    fn validate_and_replace_epochs(
        db_tx: &Transaction,
        epochs: &[StacksEpoch],
    ) -> Result<(), db_error> {
        let epochs = StacksEpoch::validate_epochs(epochs);
        let existing_epochs = Self::get_stacks_epochs(db_tx)?;
        if existing_epochs == epochs {
            return Ok(());
        }

        let tip = SortitionDB::get_canonical_burn_chain_tip(db_tx)?;
        let existing_epoch_idx = StacksEpoch::find_epoch(&existing_epochs, tip.block_height)
            .unwrap_or_else(|| {
                panic!(
                    "FATAL: Sortition tip {} has no epoch in its existing epochs table",
                    tip.block_height
                );
            });

        let new_epoch_idx =
            StacksEpoch::find_epoch(&epochs, tip.block_height).unwrap_or_else(|| {
                panic!(
                    "FATAL: Sortition tip {} has no epoch in the configured epochs list",
                    tip.block_height
                );
            });

        // can't retcon epochs -- all epochs up to (but excluding) the tip's epoch in both epoch
        // lists must be the same.
        for i in 0..existing_epoch_idx.min(new_epoch_idx) {
            if existing_epochs[i] != epochs[i] {
                panic!(
                    "FATAL: tried to retcon epoch {:?} into epoch {:?}",
                    &existing_epochs[i], &epochs[i]
                );
            }
        }

        // can't change parameters of the current epoch in either epoch list,
        // except for the end height (and only if it hasn't been reached yet)
        let mut diff_epoch = existing_epochs[existing_epoch_idx].clone();
        diff_epoch.end_height = epochs[new_epoch_idx].end_height;

        if diff_epoch != epochs[new_epoch_idx] {
            panic!(
                "FATAL: tried to change current epoch {:?} into {:?}",
                &existing_epochs[existing_epoch_idx], &epochs[new_epoch_idx]
            );
        }

        if tip.block_height >= epochs[new_epoch_idx].end_height {
            panic!("FATAL: tip has reached or passed the end of the configured epoch");
        }

        info!("Replace existing epochs with new epochs");
        db_tx.execute("DELETE FROM epochs;", NO_PARAMS)?;
        for epoch in epochs.into_iter() {
            let args: &[&dyn ToSql] = &[
                &(epoch.epoch_id as u32),
                &u64_to_sql(epoch.start_height)?,
                &u64_to_sql(epoch.end_height)?,
                &epoch.block_limit,
                &epoch.network_epoch,
            ];
            db_tx.execute(
                "INSERT INTO epochs (epoch_id,start_block_height,end_block_height,block_limit,network_epoch) VALUES (?1,?2,?3,?4,?5)",
                args
            )?;
        }
        Ok(())
    }

    /// Get a block commit by its content-addressed location in a specific sortition.
    pub fn get_block_commit(
        conn: &Connection,
        txid: &Txid,
        sortition_id: &SortitionId,
    ) -> Result<Option<LeaderBlockCommitOp>, db_error> {
        let qry = "SELECT * FROM block_commits WHERE txid = ?1 AND sortition_id = ?2";
        let args: [&dyn ToSql; 2] = [&txid, &sortition_id];
        query_row(conn, qry, &args)
    }

    /// Get the Sortition ID for the burnchain block containing `txid`'s parent.
    /// `txid` is the burnchain txid of a block-commit.
    pub fn get_block_commit_parent_sortition_id(
        conn: &Connection,
        txid: &Txid,
        sortition_id: &SortitionId,
    ) -> Result<Option<SortitionId>, db_error> {
        let qry = "SELECT parent_sortition_id AS sortition_id FROM block_commit_parents WHERE block_commit_parents.block_commit_txid = ?1 AND block_commit_parents.block_commit_sortition_id = ?2";
        let args: &[&dyn ToSql] = &[txid, sortition_id];
        query_row(conn, qry, args)
    }

    /// Load up all snapshots, in ascending order by block height.  Great for testing!
    pub fn get_all_snapshots(&self) -> Result<Vec<BlockSnapshot>, db_error> {
        let qry = "SELECT * FROM snapshots ORDER BY block_height ASC";
        query_rows(self.conn(), qry, NO_PARAMS)
    }

    /// Get all snapshots for a burn block hash, even if they're not on the canonical PoX fork.
    pub fn get_all_snapshots_for_burn_block(
        conn: &DBConn,
        bhh: &BurnchainHeaderHash,
    ) -> Result<Vec<BlockSnapshot>, db_error> {
        let qry = "SELECT * FROM snapshots WHERE burn_header_hash = ?1";
        query_rows(conn, qry, &[bhh])
    }

    /// Get all snapshots for a burn block height, even if they're not on the canonical PoX fork
    pub fn get_all_snapshots_by_burn_height(
        conn: &DBConn,
        height: u64,
    ) -> Result<Vec<BlockSnapshot>, db_error> {
        let qry = "SELECT * FROM snapshots WHERE block_height = ?1";
        query_rows(conn, qry, &[u64_to_sql(height)?])
    }

    /// Get all preprocessed reward sets and their associated anchor blocks
    pub fn get_all_preprocessed_reward_sets(
        conn: &DBConn,
    ) -> Result<Vec<(SortitionId, RewardCycleInfo)>, db_error> {
        let sql = "SELECT * FROM preprocessed_reward_sets;";
        let mut stmt = conn.prepare(sql)?;
        let mut qry = stmt.query(NO_PARAMS)?;
        let mut ret = vec![];
        while let Some(row) = qry.next()? {
            let sort_id: SortitionId = row.get("sortition_id")?;
            let reward_set_str: String = row.get("reward_set")?;
            let reward_set: RewardCycleInfo =
                serde_json::from_str(&reward_set_str).map_err(|_| db_error::ParseError)?;
            ret.push((sort_id, reward_set));
        }
        Ok(ret)
    }

    /// Get the height of a consensus hash, even if it's not on the canonical PoX fork.
    #[cfg_attr(test, mutants::skip)]
    pub fn get_consensus_hash_height(&self, ch: &ConsensusHash) -> Result<Option<u64>, db_error> {
        let qry = "SELECT block_height FROM snapshots WHERE consensus_hash = ?1";
        let mut heights: Vec<u64> = query_rows(self.conn(), qry, &[ch])?;
        if let Some(height) = heights.pop() {
            for next_height in heights {
                if height != next_height {
                    panic!("BUG: consensus hash {} has two different heights", ch);
                }
            }
            Ok(Some(height))
        } else {
            Ok(None)
        }
    }

    /// Get the schema version of a sortition DB, given the path to it.
    /// Returns the version string, if it exists.
    ///
    /// Does **not** migrate the database (like `open()` or `connect()` would)
    pub fn get_db_version_from_path(path: &str) -> Result<Option<String>, db_error> {
        if fs::metadata(path).is_err() {
            return Err(db_error::NoDBError);
        }
        let index_path = db_mkdirs(path)?;
        let marf = SortitionDB::open_index(&index_path)?;
        SortitionDB::get_schema_version(marf.sqlite_conn())
    }

    /// Get the height of the highest burnchain block, given the DB path.
    /// Importantly, this will *not* apply any schema migrations.
    /// This is used to check if the DB is compatible with the current epoch.
    pub fn get_highest_block_height_from_path(path: &str) -> Result<u64, db_error> {
        if fs::metadata(path).is_err() {
            return Err(db_error::NoDBError);
        }
        let index_path = db_mkdirs(path)?;
        let marf = SortitionDB::open_index(&index_path)?;
        let sql = "SELECT MAX(block_height) FROM snapshots";
        Ok(query_rows(&marf.sqlite_conn(), sql, NO_PARAMS)?
            .pop()
            .expect("BUG: no snapshots in block_snapshots"))
    }

    /// Is a particular database version supported by a given epoch?
    pub fn is_db_version_supported_in_epoch(epoch: StacksEpochId, version: &str) -> bool {
        match epoch {
            StacksEpochId::Epoch10 => true,
            StacksEpochId::Epoch20 => {
                version == "1"
                    || version == "2"
                    || version == "3"
                    || version == "4"
                    || version == "5"
                    || version == "6"
                    || version == "7"
                    || version == "8"
            }
            StacksEpochId::Epoch2_05 => {
                version == "2"
                    || version == "3"
                    || version == "4"
                    || version == "5"
                    || version == "6"
                    || version == "7"
                    || version == "8"
            }
            StacksEpochId::Epoch21 => {
                version == "3"
                    || version == "4"
                    || version == "5"
                    || version == "6"
                    || version == "7"
                    || version == "8"
            }
            StacksEpochId::Epoch22 => {
                version == "3"
                    || version == "4"
                    || version == "5"
                    || version == "6"
                    || version == "7"
                    || version == "8"
            }
            StacksEpochId::Epoch23 => {
                version == "3"
                    || version == "4"
                    || version == "5"
                    || version == "6"
                    || version == "7"
                    || version == "8"
            }
            StacksEpochId::Epoch24 => {
                version == "3"
                    || version == "4"
                    || version == "5"
                    || version == "6"
                    || version == "7"
                    || version == "8"
            }
            StacksEpochId::Epoch25 => {
                version == "3"
                    || version == "4"
                    || version == "5"
                    || version == "6"
                    || version == "7"
                    || version == "8"
            }
            StacksEpochId::Epoch30 => {
                version == "3"
                    || version == "4"
                    || version == "5"
                    || version == "6"
                    || version == "7"
                    || version == "8"
            }
        }
    }

    /// Get the database schema version, given a DB connection
    fn get_schema_version(conn: &Connection) -> Result<Option<String>, db_error> {
        let version = conn
            .query_row(
                "SELECT MAX(version) from db_config",
                rusqlite::NO_PARAMS,
                |row| row.get(0),
            )
            .optional()?;
        Ok(version)
    }

    fn apply_schema_2(tx: &DBTx, epochs: &[StacksEpoch]) -> Result<(), db_error> {
        for sql_exec in SORTITION_DB_SCHEMA_2 {
            tx.execute_batch(sql_exec)?;
        }

        SortitionDB::validate_and_insert_epochs(&tx, epochs)?;

        tx.execute(
            "INSERT OR REPLACE INTO db_config (version) VALUES (?1)",
            &["2"],
        )?;

        Ok(())
    }

    fn apply_schema_3(tx: &DBTx) -> Result<(), db_error> {
        for sql_exec in SORTITION_DB_SCHEMA_3 {
            tx.execute_batch(sql_exec)?;
        }
        tx.execute(
            "INSERT OR REPLACE INTO db_config (version) VALUES (?1)",
            &["3"],
        )?;
        Ok(())
    }

    fn apply_schema_4(tx: &DBTx) -> Result<(), db_error> {
        for sql_exec in SORTITION_DB_SCHEMA_4 {
            tx.execute_batch(sql_exec)?;
        }

        let typical_rules: &[&dyn ToSql] = &[&(ASTRules::Typical as u8), &0i64];

        let precheck_size_rules: &[&dyn ToSql] = &[
            &(ASTRules::PrecheckSize as u8),
            &u64_to_sql(AST_RULES_PRECHECK_SIZE)?,
        ];

        tx.execute(
            "INSERT INTO ast_rule_heights (ast_rule_id,block_height) VALUES (?1, ?2)",
            typical_rules,
        )?;
        tx.execute(
            "INSERT INTO ast_rule_heights (ast_rule_id,block_height) VALUES (?1, ?2)",
            precheck_size_rules,
        )?;
        tx.execute(
            "INSERT OR REPLACE INTO db_config (version) VALUES (?1)",
            &["4"],
        )?;
        Ok(())
    }

    #[cfg_attr(test, mutants::skip)]
    fn apply_schema_5(tx: &DBTx, epochs: &[StacksEpoch]) -> Result<(), db_error> {
        // the schema 5 changes simply **replace** the contents of the epochs table
        //  by dropping all the current rows and then revalidating and inserting
        //  `epochs`
        for sql_exec in SORTITION_DB_SCHEMA_5 {
            tx.execute_batch(sql_exec)?;
        }

        SortitionDB::validate_and_insert_epochs(&tx, epochs)?;

        tx.execute(
            "INSERT OR REPLACE INTO db_config (version) VALUES (?1)",
            &["5"],
        )?;

        Ok(())
    }

    #[cfg_attr(test, mutants::skip)]
    fn apply_schema_6(tx: &DBTx, epochs: &[StacksEpoch]) -> Result<(), db_error> {
        for sql_exec in SORTITION_DB_SCHEMA_6 {
            tx.execute_batch(sql_exec)?;
        }

        SortitionDB::validate_and_insert_epochs(&tx, epochs)?;

        tx.execute(
            "INSERT OR REPLACE INTO db_config (version) VALUES (?1)",
            &["6"],
        )?;

        Ok(())
    }

    #[cfg_attr(test, mutants::skip)]
    fn apply_schema_7(tx: &DBTx, epochs: &[StacksEpoch]) -> Result<(), db_error> {
        for sql_exec in SORTITION_DB_SCHEMA_7 {
            tx.execute_batch(sql_exec)?;
        }

        SortitionDB::validate_and_insert_epochs(&tx, epochs)?;

        tx.execute(
            "INSERT OR REPLACE INTO db_config (version) VALUES (?1)",
            &["7"],
        )?;

        Ok(())
    }

    /// Apply just the table creation/alterations for schema 8.  Don't attempt migration yet.
    fn apply_schema_8_tables(tx: &DBTx, epochs: &[StacksEpoch]) -> Result<(), db_error> {
        if table_exists(tx, "stacks_chain_tips")? {
            info!("Schema 8 tables appear to have been created already; skipping this step");
            return Ok(());
        }

        for sql_exec in SORTITION_DB_SCHEMA_8 {
            tx.execute_batch(sql_exec)?;
        }

        SortitionDB::validate_and_insert_epochs(&tx, epochs)?;
        Ok(())
    }

    /// When applying schema 8, instantiate the `stacks_chain_tips` table
    /// NOTE: this only works in epochs 2.5 and earlier
    pub(crate) fn apply_schema_8_stacks_chain_tips(
        &mut self,
        canonical_tip: &BlockSnapshot,
    ) -> Result<(), db_error> {
        let first_block_height = self.first_block_height;
        let tx = self.tx_begin()?;

        // skip if this step was done
        if table_exists(&tx, "stacks_chain_tips")? {
            let sql = "SELECT 1 FROM stacks_chain_tips WHERE sortition_id = ?1";
            let args = rusqlite::params![&canonical_tip.sortition_id];
            if let Ok(Some(_)) = query_row::<i64, _>(&tx, sql, args) {
                info!("`stacks_chain_tips` appears to have been populated already; skipping this step");
                return Ok(());
            }
        }

        for height in first_block_height..=canonical_tip.block_height {
            let snapshots = SortitionDB::get_all_snapshots_by_burn_height(&tx, height)?;
            debug!(
                "Populate stacks_chain_tips for {} sortition(s) at height {}",
                snapshots.len(),
                height
            );
            for snapshot in snapshots.into_iter() {
                let sql = "INSERT OR REPLACE INTO stacks_chain_tips (sortition_id,consensus_hash,block_hash,block_height) VALUES (?1,?2,?3,?4)";
                let args: &[&dyn ToSql] = &[
                    &snapshot.sortition_id,
                    &snapshot.canonical_stacks_tip_consensus_hash,
                    &snapshot.canonical_stacks_tip_hash,
                    &u64_to_sql(snapshot.canonical_stacks_tip_height)?,
                ];
                tx.execute(sql, args)?;
            }
        }
        tx.commit()?;
        Ok(())
    }

    /// When applying schema 8, instantiate the `preprocessed_reward_sets` table
    pub(crate) fn apply_schema_8_preprocessed_reward_sets(
        &mut self,
        canonical_tip: &BlockSnapshot,
        mut migrator: SortitionDBMigrator,
    ) -> Result<(), db_error> {
        let pox_constants = self.pox_constants.clone();
        for rc in 0..=(canonical_tip.block_height / u64::from(pox_constants.reward_cycle_length)) {
            if pox_constants.reward_cycle_to_block_height(self.first_block_height, rc)
                > canonical_tip.block_height
            {
                break;
            }
            info!("Regenerating reward set for cycle {}", &rc);
            migrator.regenerate_reward_cycle_info(self, rc)?;
        }

        Ok(())
    }

    /// Apply schema 8 migration.  Call after `apply_schema_8_tables()`.
    /// This migration path is different from the others in that it manages sortition DB
    /// transactions on its own (namely, it needs access to the SortitionDB MARF).
    ///
    /// To _migrate_ the sortition DB from schema 7, it needs access to the Stacks chainstate in
    /// order to obtain prior reward sets.  This is encapsulated in the `SortitionDBMigrator`
    /// implementation.  However, to _instantiate_ the sortition DB, no migrator is needed (since
    /// the chainstate will also be empty).
    fn apply_schema_8_migration(
        &mut self,
        mut migrator: Option<SortitionDBMigrator>,
    ) -> Result<(), db_error> {
        let canonical_tip = SortitionDB::get_canonical_burn_chain_tip(self.conn())?;

        // port over `stacks_chain_tips` table
        info!("Instantiating `stacks_chain_tips` table...");
        self.apply_schema_8_stacks_chain_tips(&canonical_tip)?;

        // port over `preprocessed_reward_sets` table
        if let Some(migrator) = migrator.take() {
            info!("Instantiating `preprocessed_reward_sets` table...");
            self.apply_schema_8_preprocessed_reward_sets(&canonical_tip, migrator)?;
        } else {
            // NOTE: if we're instantiating the DB, this is fine.
            info!("No migrator implementation given; `preprocessed_reward_sets` will not be prepopulated");
        }

        let tx = self.tx_begin()?;
        tx.execute(
            "INSERT OR REPLACE INTO db_config (version) VALUES (?1)",
            &["8"],
        )?;
        tx.commit()?;

        Ok(())
    }

    fn check_schema_version_or_error(&mut self) -> Result<(), db_error> {
        match SortitionDB::get_schema_version(self.conn()) {
            Ok(Some(version)) => {
                let expected_version = SORTITION_DB_VERSION.to_string();
                if version == expected_version {
                    Ok(())
                } else {
                    let version_u64 = version.parse::<u64>().unwrap();
                    Err(db_error::OldSchema(version_u64))
                }
            }
            Ok(None) => panic!("The schema version of the sortition DB is not recorded."),
            Err(e) => panic!("Error obtaining the version of the sortition DB: {:?}", e),
        }
    }

    /// Migrate the sortition DB to its latest version, given the set of system epochs.
    /// The `migrator` should only be `None` if the DB is being instantiated, or if the DB is
    /// instantiated and migrated to the latest schema.
    /// Otherwise, it should be `Some(..)`.
    fn check_schema_version_and_update(
        &mut self,
        epochs: &[StacksEpoch],
        mut migrator: Option<SortitionDBMigrator>,
    ) -> Result<(), db_error> {
        let expected_version = SORTITION_DB_VERSION.to_string();
        loop {
            match SortitionDB::get_schema_version(self.conn()) {
                Ok(Some(version)) => {
                    if version == "1" {
                        let tx = self.tx_begin()?;
                        SortitionDB::apply_schema_2(&tx.deref(), epochs)?;
                        tx.commit()?;
                    } else if version == "2" {
                        // add the tables of schema 3, but do not populate them.
                        let tx = self.tx_begin()?;
                        SortitionDB::apply_schema_3(&tx.deref())?;
                        tx.commit()?;
                    } else if version == "3" {
                        let tx = self.tx_begin()?;
                        SortitionDB::apply_schema_4(&tx.deref())?;
                        tx.commit()?;
                    } else if version == "4" {
                        let tx = self.tx_begin()?;
                        SortitionDB::apply_schema_5(&tx.deref(), epochs)?;
                        tx.commit()?;
                    } else if version == "5" {
                        let tx = self.tx_begin()?;
                        SortitionDB::apply_schema_6(&tx.deref(), epochs)?;
                        tx.commit()?;
                    } else if version == "6" {
                        let tx = self.tx_begin()?;
                        SortitionDB::apply_schema_7(&tx.deref(), epochs)?;
                        tx.commit()?;
                    } else if version == "7" {
                        let tx = self.tx_begin()?;
                        SortitionDB::apply_schema_8_tables(&tx.deref(), epochs)?;
                        tx.commit()?;

                        self.apply_schema_8_migration(migrator.take())?;
                    } else if version == expected_version {
                        let tx = self.tx_begin()?;
                        SortitionDB::validate_and_replace_epochs(&tx, epochs)?;
                        tx.commit()?;

                        return Ok(());
                    } else {
                        panic!("The schema version of the sortition DB is invalid.")
                    }
                }
                Ok(None) => panic!("The schema version of the sortition DB is not recorded."),
                Err(e) => panic!("Error obtaining the version of the sortition DB: {:?}", e),
            }
        }
    }

    /// Open and migrate the sortition DB if it exists.
    pub fn migrate_if_exists(
        path: &str,
        epochs: &[StacksEpoch],
        migrator: SortitionDBMigrator,
    ) -> Result<(), db_error> {
        // NOTE: the sortition DB created here will not be used for anything, so it's safe to use
        // the mainnet_default PoX constants
        if let Err(db_error::OldSchema(_)) =
            SortitionDB::open(path, false, PoxConstants::mainnet_default())
        {
            let index_path = db_mkdirs(path)?;
            let marf = SortitionDB::open_index(&index_path)?;
            let mut db = SortitionDB {
                path: path.to_string(),
                marf,
                readwrite: true,
                dryrun: false,
                first_block_height: migrator.get_burnchain().first_block_height,
                first_burn_header_hash: migrator.get_burnchain().first_block_hash.clone(),
                pox_constants: migrator.get_burnchain().pox_constants.clone(),
            };
            db.check_schema_version_and_update(epochs, Some(migrator))
        } else {
            debug!("SortitionDB is at the latest schema");
            Ok(())
        }
    }

    fn add_indexes(&mut self) -> Result<(), db_error> {
        // do we need to instantiate indexes?
        // only do a transaction if we need to, since this gets called each time the sortition DB
        // is opened.
        let exists: i64 = query_row(
            self.conn(),
            "SELECT 1 FROM sqlite_master WHERE type = 'index' AND name = ?1",
            &[LAST_SORTITION_DB_INDEX],
        )?
        .unwrap_or(0);
        if exists == 0 {
            let tx = self.tx_begin()?;
            for row_text in SORTITION_DB_INDEXES {
                tx.execute_batch(row_text)?;
            }
            tx.commit()?;
        }
        Ok(())
    }

    #[cfg(any(test, feature = "testing"))]
    pub fn override_ast_rule_height<'a>(
        tx: &mut DBTx<'a>,
        ast_rules: ASTRules,
        height: u64,
    ) -> Result<(), db_error> {
        let rules: &[&dyn ToSql] = &[&u64_to_sql(height)?, &(ast_rules as u8)];

        tx.execute(
            "UPDATE ast_rule_heights SET block_height = ?1 WHERE ast_rule_id = ?2",
            rules,
        )?;
        Ok(())
    }

    #[cfg(not(any(test, feature = "testing")))]
    pub fn override_ast_rule_height<'a>(
        _tx: &mut DBTx<'a>,
        _ast_rules: ASTRules,
        _height: u64,
    ) -> Result<(), db_error> {
        Ok(())
    }

    /// What's the default AST rules at the given block height?
    pub fn get_ast_rules(conn: &DBConn, height: u64) -> Result<ASTRules, db_error> {
        let ast_rule_sets: Vec<(ASTRules, u64)> = query_rows(
            conn,
            "SELECT * FROM ast_rule_heights ORDER BY block_height ASC",
            NO_PARAMS,
        )?;

        assert!(ast_rule_sets.len() > 0);
        let mut last_height = ast_rule_sets[0].1;
        let mut last_rules = ast_rule_sets[0].0;
        for (ast_rules, ast_rule_height) in ast_rule_sets.into_iter() {
            if last_height <= height && height < ast_rule_height {
                return Ok(last_rules);
            }
            last_height = ast_rule_height;
            last_rules = ast_rules;
        }

        return Ok(last_rules);
    }

    /// Store a pre-processed reward set.
    /// `sortition_id` is the first sortition ID of the prepare phase
    pub fn store_preprocessed_reward_set(
        sort_tx: &mut DBTx,
        sortition_id: &SortitionId,
        rc_info: &RewardCycleInfo,
    ) -> Result<(), db_error> {
        let sql = "INSERT INTO preprocessed_reward_sets (sortition_id,reward_set) VALUES (?1,?2)";
        let rc_json = serde_json::to_string(rc_info).map_err(db_error::SerializationError)?;
        let args: &[&dyn ToSql] = &[sortition_id, &rc_json];
        sort_tx.execute(sql, args)?;
        Ok(())
    }

    /// Figure out the reward cycle for `tip` and lookup the preprocessed
    ///  reward set (if it exists) for the active reward cycle during `tip`
    pub fn get_preprocessed_reward_set_of(
        &self,
        tip: &SortitionId,
    ) -> Result<Option<RewardCycleInfo>, db_error> {
        let tip_sn = SortitionDB::get_block_snapshot(self.conn(), tip)?.ok_or_else(|| {
            error!(
                "Could not find snapshot for sortition while fetching reward set";
                "tip_sortition_id" => %tip,
            );
            db_error::NotFoundError
        })?;

        let reward_cycle_id = self
            .pox_constants
            .block_height_to_reward_cycle(self.first_block_height, tip_sn.block_height)
            .expect("FATAL: stored snapshot with block height < first_block_height");

        let prepare_phase_start = self
            .pox_constants
            .reward_cycle_to_block_height(self.first_block_height, reward_cycle_id)
            .saturating_sub(self.pox_constants.prepare_length.into());

        let first_sortition = get_ancestor_sort_id(
            &self.index_conn(),
            prepare_phase_start,
            &tip_sn.sortition_id,
        )?
        .ok_or_else(|| {
            error!(
                "Could not find prepare phase start ancestor while fetching reward set";
                "tip_sortition_id" => %tip,
                "reward_cycle_id" => reward_cycle_id,
                "prepare_phase_start_height" => prepare_phase_start
            );
            db_error::NotFoundError
        })?;

        info!("Fetching preprocessed reward set";
              "tip_sortition_id" => %tip,
              "reward_cycle_id" => reward_cycle_id,
              "prepare_phase_start_sortition_id" => %first_sortition,
        );

        Self::get_preprocessed_reward_set(self.conn(), &first_sortition)
    }

    /// Get a pre-processed reawrd set.
    /// `sortition_id` is the first sortition ID of the prepare phase.
    pub fn get_preprocessed_reward_set(
        sortdb: &DBConn,
        sortition_id: &SortitionId,
    ) -> Result<Option<RewardCycleInfo>, db_error> {
        let sql = "SELECT reward_set FROM preprocessed_reward_sets WHERE sortition_id = ?1";
        let args: &[&dyn ToSql] = &[sortition_id];
        let reward_set_opt: Option<String> =
            sortdb.query_row(sql, args, |row| row.get(0)).optional()?;

        let rc_info = reward_set_opt
            .map(|reward_set_str| serde_json::from_str(&reward_set_str))
            .transpose()
            .map_err(|_| db_error::ParseError)?;

        Ok(rc_info)
    }

    pub fn get_preprocessed_reward_set_size(&self, tip: &SortitionId) -> Option<u16> {
        let Ok(Some(reward_info)) = &self.get_preprocessed_reward_set_of(&tip) else {
            return None;
        };
        let Some(reward_set) = reward_info.known_selected_anchor_block() else {
            return None;
        };

        reward_set
            .signers
            .clone()
            .map(|x| x.len())
            .unwrap_or(0)
            .try_into()
            .ok()
    }
}

impl<'a> SortitionDBTx<'a> {
    pub fn find_sortition_tip_affirmation_map(
        &mut self,
        chain_tip: &SortitionId,
    ) -> Result<AffirmationMap, db_error> {
        let affirmation_map = match self.get_indexed(chain_tip, &db_keys::pox_affirmation_map())? {
            Some(am_str) => {
                AffirmationMap::decode(&am_str).expect("FATAL: corrupt affirmation map")
            }
            None => AffirmationMap::empty(),
        };

        // remove the first entry -- it's always `n` based on the way we construct it, while the
        // heaviest affirmation map just has nothing.
        Ok(match affirmation_map.as_slice() {
            [] => AffirmationMap::empty(),
            a => AffirmationMap::new(a[1..].to_vec()),
        })
    }
}

impl<'a> SortitionDBConn<'a> {
    pub fn as_handle<'b>(&'b self, chain_tip: &SortitionId) -> SortitionHandleConn<'b> {
        SortitionHandleConn {
            index: self.index,
            context: SortitionHandleContext {
                first_block_height: self.context.first_block_height.clone(),
                chain_tip: chain_tip.clone(),
                pox_constants: self.context.pox_constants.clone(),
                dryrun: self.context.dryrun,
            },
        }
    }

    /// Given a burnchain consensus hash,
    /// go get the last N Stacks block headers that won sortition
    /// leading up to the given header hash.  The ith slot in the vector will be Some(...) if there
    /// was a sortition, and None if not.
    /// Returns up to num_headers prior block header hashes.
    /// The list of hashes will be in ascending order -- the lowest-height block is item 0.
    /// The last hash will be the hash for the given consensus hash.
    pub fn get_stacks_header_hashes(
        &self,
        num_headers: u64,
        tip_consensus_hash: &ConsensusHash,
        cache: &BlockHeaderCache,
    ) -> Result<Vec<(ConsensusHash, Option<BlockHeaderHash>)>, db_error> {
        let mut ret = vec![];
        let tip_snapshot = SortitionDB::get_block_snapshot_consensus(self, tip_consensus_hash)?
            .ok_or_else(|| db_error::NotFoundError)?;

        if !tip_snapshot.pox_valid {
            warn!("Consensus hash {:?} corresponds to a sortition that is not on the canonical PoX fork", tip_consensus_hash);
            return Err(db_error::InvalidPoxSortition);
        }

        assert!(
            tip_snapshot.block_height >= self.context.first_block_height,
            "DB corruption: have snapshot with a smaller block height than the first block height"
        );

        let db_handle = self.as_handle(&tip_snapshot.sortition_id);

        let headers_count =
            if tip_snapshot.block_height - self.context.first_block_height < num_headers {
                tip_snapshot.block_height - self.context.first_block_height
            } else {
                num_headers
            };

        let mut ancestor_consensus_hash = tip_snapshot.consensus_hash;

        for _i in 0..headers_count {
            if let Some((header_hash_opt, prev_consensus_hash)) =
                cache.get(&ancestor_consensus_hash)
            {
                // cache hit
                ret.push((ancestor_consensus_hash, header_hash_opt.clone()));
                ancestor_consensus_hash = prev_consensus_hash.clone();
                continue;
            }

            // cache miss
            let ancestor_snapshot = SortitionDB::get_block_snapshot_consensus(
                db_handle.conn(),
                &ancestor_consensus_hash,
            )?
            .unwrap_or_else(|| {
                panic!(
                    "Discontiguous index: missing block for consensus hash {}",
                    ancestor_consensus_hash
                )
            });

            // this can happen if this call is interleaved with a PoX invalidation transaction
            if !ancestor_snapshot.pox_valid {
                warn!("Consensus hash {:?} corresponds to a sortition that is not on the canonical PoX fork", ancestor_consensus_hash);
                return Err(db_error::InvalidPoxSortition);
            }

            let header_hash_opt = if ancestor_snapshot.sortition {
                Some(ancestor_snapshot.winning_stacks_block_hash.clone())
            } else {
                None
            };

            debug!(
                "CACHE MISS {} (height {}): {:?}",
                &ancestor_consensus_hash, ancestor_snapshot.block_height, &header_hash_opt
            );

            ret.push((ancestor_snapshot.consensus_hash, header_hash_opt.clone()));

            let ancestor_snapshot_parent = SortitionDB::get_block_snapshot(
                db_handle.conn(),
                &ancestor_snapshot.parent_sortition_id,
            )?
            .unwrap_or_else(|| {
                panic!(
                    "Discontiguous index: missing parent block of parent burn header hash {}",
                    &ancestor_snapshot.parent_burn_header_hash
                )
            });

            ancestor_consensus_hash = ancestor_snapshot_parent.consensus_hash;
        }

        ret.reverse();
        Ok(ret)
    }

    pub fn find_parent_snapshot_for_stacks_block(
        &self,
        consensus_hash: &ConsensusHash,
        block_hash: &BlockHeaderHash,
    ) -> Result<Option<BlockSnapshot>, db_error> {
        let db_handle = SortitionHandleConn::open_reader_consensus(self, consensus_hash)?;
        let parent_block_snapshot = match db_handle
            .get_block_snapshot_of_parent_stacks_block(consensus_hash, &block_hash)
        {
            Ok(Some((_, sn))) => {
                debug!(
                    "Parent of {}/{} is {}/{}",
                    consensus_hash, block_hash, sn.consensus_hash, sn.winning_stacks_block_hash
                );
                sn
            }
            Ok(None) => {
                debug!(
                    "Received block with unknown parent snapshot: {}/{}",
                    consensus_hash, block_hash,
                );
                return Ok(None);
            }
            Err(db_error::InvalidPoxSortition) => {
                warn!(
                    "Received block {}/{} on a non-canonical PoX sortition",
                    consensus_hash, block_hash,
                );
                return Ok(None);
            }
            Err(e) => {
                return Err(e);
            }
        };

        Ok(Some(parent_block_snapshot))
    }

    #[cfg_attr(test, mutants::skip)]
    pub fn get_reward_set_size_at(&mut self, sortition_id: &SortitionId) -> Result<u16, db_error> {
        self.get_indexed(sortition_id, &db_keys::pox_reward_set_size())
            .map(|x| {
                db_keys::reward_set_size_from_string(
                    &x.expect("CORRUPTION: no current reward set size written"),
                )
            })
    }

    pub fn get_reward_set_entry_at(
        &mut self,
        sortition_id: &SortitionId,
        entry_ix: u16,
    ) -> Result<PoxAddress, db_error> {
        let entry_str = self
            .get_indexed(sortition_id, &db_keys::pox_reward_set_entry(entry_ix))?
            .unwrap_or_else(|| {
                panic!(
                    "CORRUPTION: expected reward set entry at index={}, but not found",
                    entry_ix
                )
            });
        Ok(PoxAddress::from_db_string(&entry_str).expect("FATAL: could not decode PoX address"))
    }

    pub fn get_reward_set_payouts_at(
        &self,
        sortition_id: &SortitionId,
    ) -> Result<(Vec<PoxAddress>, u128), db_error> {
        let sql = "SELECT pox_payouts FROM snapshots WHERE sortition_id = ?1";
        let args: &[&dyn ToSql] = &[sortition_id];
        let pox_addrs_json: String =
            query_row(self.conn(), sql, args)?.ok_or(db_error::NotFoundError)?;

        let pox_addrs: (Vec<PoxAddress>, u128) =
            serde_json::from_str(&pox_addrs_json).expect("FATAL: failed to decode pox payout JSON");
        Ok(pox_addrs)
    }
}

// High-level functions used by ChainsCoordinator
impl SortitionDB {
    pub fn get_sortition_id(
        &self,
        burnchain_header_hash: &BurnchainHeaderHash,
        sortition_tip: &SortitionId,
    ) -> Result<Option<SortitionId>, BurnchainError> {
        let handle = self.index_handle(sortition_tip);
        handle
            .get_sortition_id_for_bhh(burnchain_header_hash)
            .map_err(BurnchainError::from)
    }

    pub fn is_sortition_processed(
        &self,
        burnchain_header_hash: &BurnchainHeaderHash,
    ) -> Result<Option<SortitionId>, BurnchainError> {
        let qry = "SELECT sortition_id FROM snapshots WHERE burn_header_hash = ? AND pox_valid = 1";
        query_row(self.conn(), qry, &[burnchain_header_hash]).map_err(BurnchainError::from)
    }

    fn get_block_height(
        conn: &Connection,
        sortition_id: &SortitionId,
    ) -> Result<Option<u32>, db_error> {
        let qry = "SELECT block_height FROM snapshots WHERE sortition_id = ? LIMIT 1";
        conn.query_row(qry, &[sortition_id], |row| row.get(0))
            .optional()
            .map_err(db_error::from)
    }

    /// Is the given block an expected PoX anchor in this sortition history?
    ///  if so, return the Stacks block hash
    pub fn is_stacks_block_pox_anchor(
        &mut self,
        block: &BlockHeaderHash,
        sortition_tip: &SortitionId,
    ) -> Result<Option<BlockHeaderHash>, BurnchainError> {
        let handle = self.index_handle(sortition_tip);
        let expects_block_as_anchor = handle
            .get_tip_indexed(&db_keys::pox_anchor_to_prepare_end(block))?
            .map(|_| block.clone());

        return Ok(expects_block_as_anchor);
    }

    fn parse_last_anchor_block_hash(s: Option<String>) -> Option<BlockHeaderHash> {
        s.map(|s| {
            if s == "" {
                None
            } else {
                Some(BlockHeaderHash::from_hex(&s).expect("BUG: Bad BlockHeaderHash stored in DB"))
            }
        })
        .flatten()
    }

    fn parse_last_anchor_block_txid(s: Option<String>) -> Option<Txid> {
        s.map(|s| {
            if s == "" {
                None
            } else {
                Some(Txid::from_hex(&s).expect("BUG: Bad Txid stored in DB"))
            }
        })
        .flatten()
    }

    /// Mark a Stacks block snapshot as valid again, but update its memoized canonical Stacks tip
    /// height and block-accepted flag.
    #[cfg_attr(test, mutants::skip)]
    pub fn revalidate_snapshot_with_block(
        tx: &DBTx,
        sortition_id: &SortitionId,
        canonical_stacks_ch: &ConsensusHash,
        canonical_stacks_bhh: &BlockHeaderHash,
        canonical_stacks_height: u64,
        stacks_block_accepted: Option<bool>,
    ) -> Result<(), BurnchainError> {
        if let Some(stacks_block_accepted) = stacks_block_accepted {
            let args: &[&dyn ToSql] = &[
                sortition_id,
                &u64_to_sql(canonical_stacks_height)?,
                canonical_stacks_bhh,
                canonical_stacks_ch,
                &stacks_block_accepted,
            ];
            tx.execute(
                "UPDATE snapshots SET pox_valid = 1, canonical_stacks_tip_height = ?2, canonical_stacks_tip_hash = ?3, canonical_stacks_tip_consensus_hash = ?4, stacks_block_accepted = ?5 WHERE sortition_id = ?1",
                args
            )?;
        } else {
            let args: &[&dyn ToSql] = &[
                sortition_id,
                &u64_to_sql(canonical_stacks_height)?,
                canonical_stacks_bhh,
                canonical_stacks_ch,
            ];
            tx.execute(
                "UPDATE snapshots SET pox_valid = 1, canonical_stacks_tip_height = ?2, canonical_stacks_tip_hash = ?3, canonical_stacks_tip_consensus_hash = ?4 WHERE sortition_id = ?1",
                args
            )?;
        }
        Ok(())
    }

    /// Invalidate all block snapshots that descend from the given burnchain block, and for each
    /// invalidated snapshot, apply `cls` to it with the given sortition DB transaction, the
    /// current burnchain block being considered, and the list of burnchain blocks still to be
    /// considered.  That last argument will have length 0 on the last call to `cls`.
    ///
    /// Run `after` with the sorition handle tx right before committing.
    pub fn invalidate_descendants_with_closures<F, G>(
        &mut self,
        burn_block: &BurnchainHeaderHash,
        mut cls: F,
        mut after: G,
    ) -> Result<(), BurnchainError>
    where
        F: FnMut(&mut SortitionDBTx, &BurnchainHeaderHash, &Vec<BurnchainHeaderHash>) -> (),
        G: FnMut(&mut SortitionDBTx) -> (),
    {
        let mut db_tx = self.tx_begin()?;
        let mut queue = vec![burn_block.clone()];

        while let Some(header) = queue.pop() {
            {
                // scope this to keep the borrow-checker happy
                let mut stmt = db_tx.prepare(
                    "SELECT DISTINCT burn_header_hash FROM snapshots WHERE parent_burn_header_hash = ?",
                )?;
                for next_header in stmt.query_map(&[&header], |row| row.get(0))? {
                    queue.push(next_header?);
                }
            }
            cls(&mut db_tx, &header, &queue);

            debug!("Invalidate descendants of burn block {}", &header);

            #[cfg(any(test, feature = "testing"))]
            {
                let to_invalidate: Vec<BlockSnapshot> = query_rows(
                    &db_tx,
                    "SELECT * FROM snapshots WHERE parent_burn_header_hash = ?1",
                    &[&header],
                )?;
                for invalid in to_invalidate {
                    debug!("Invalidate child of {}: {:?}", &header, &invalid);
                }
            }

            db_tx.tx().execute(
                r#"UPDATE snapshots SET
                pox_valid = 0,
                arrival_index = 0,
                canonical_stacks_tip_height = 0,
                canonical_stacks_tip_hash = "0000000000000000000000000000000000000000000000000000000000000000",
                canonical_stacks_tip_consensus_hash = "0000000000000000000000000000000000000000",
                stacks_block_accepted = 0
                WHERE parent_burn_header_hash = ?"#,
                &[&header],
            )?;
        }

        after(&mut db_tx);

        db_tx.commit()?;
        Ok(())
    }

    pub fn invalidate_descendants_of(
        &mut self,
        burn_block: &BurnchainHeaderHash,
    ) -> Result<(), BurnchainError> {
        self.invalidate_descendants_with_closures(burn_block, |_tx, _bhh, _queue| {}, |_tx| {})
    }

    /// Find all sortition IDs with memoized canonical stacks block pointers that are higher than the
    /// given height.  This is used to identify "dirty" but still valid snapshots whose memoized
    /// pointers are no longer valid.
    pub fn find_snapshots_with_dirty_canonical_block_pointers(
        conn: &DBConn,
        canonical_stacks_height: u64,
    ) -> Result<Vec<SortitionId>, db_error> {
        let dirty_sortitions : Vec<SortitionId> = query_rows(conn, "SELECT sortition_id FROM snapshots WHERE canonical_stacks_tip_height > ?1 AND pox_valid = 1", &[&u64_to_sql(canonical_stacks_height)?])?;
        Ok(dirty_sortitions)
    }

    /// Get the last sortition in the prepare phase that chose a particular Stacks block as the anchor,
    ///   or if the anchor is not expected, return None
    pub fn get_prepare_end_for(
        &mut self,
        sortition_tip: &SortitionId,
        anchor: &BlockHeaderHash,
    ) -> Result<Option<BlockSnapshot>, BurnchainError> {
        let handle = self.index_handle(sortition_tip);
        let prepare_end_sortid = match handle
            .get_tip_indexed(&db_keys::pox_anchor_to_prepare_end(anchor))?
        {
            Some(s) => SortitionId::from_hex(&s).expect("CORRUPTION: DB stored bad sortition ID"),
            None => return Ok(None),
        };
        let snapshot =
            SortitionDB::get_block_snapshot(self.conn(), &prepare_end_sortid)?.unwrap_or_else(|| panic!("BUG: Sortition ID for prepare phase end is known, but no BlockSnapshot is stored: {}",
            &prepare_end_sortid));
        Ok(Some(snapshot))
    }

    /// Get the PoX ID at the particular sortition_tip
    pub fn get_pox_id(&mut self, sortition_tip: &SortitionId) -> Result<PoxId, BurnchainError> {
        let handle = self.index_handle(sortition_tip);
        handle.get_pox_id().map_err(BurnchainError::from)
    }

    pub fn get_sortition_result(
        &self,
        id: &SortitionId,
    ) -> Result<Option<(BlockSnapshot, BurnchainStateTransitionOps)>, BurnchainError> {
        let snapshot = match SortitionDB::get_block_snapshot(self.conn(), id)? {
            Some(x) => x,
            None => return Ok(None),
        };

        let sql_transition_ops = "SELECT accepted_ops, consumed_keys FROM snapshot_transition_ops WHERE sortition_id = ?";
        let transition_ops = self
            .conn()
            .query_row(sql_transition_ops, &[id], |row| {
                let accepted_ops: String = row.get_unwrap(0);
                let consumed_leader_keys: String = row.get_unwrap(1);
                Ok(BurnchainStateTransitionOps {
                    accepted_ops: serde_json::from_str(&accepted_ops)
                        .expect("CORRUPTION: DB stored bad transition ops"),
                    consumed_leader_keys: serde_json::from_str(&consumed_leader_keys)
                        .expect("CORRUPTION: DB stored bad transition ops"),
                })
            })
            .optional()?
            .expect("CORRUPTION: DB stored BlockSnapshot, but not the transition ops");

        Ok(Some((snapshot, transition_ops)))
    }

    /// Compute the next PoX ID
    pub fn make_next_pox_id(parent_pox: PoxId, next_pox_info: Option<&RewardCycleInfo>) -> PoxId {
        let mut next_pox = parent_pox;
        if let Some(ref next_pox_info) = next_pox_info {
            if next_pox_info.is_reward_info_known() {
                info!(
                    "Begin reward-cycle sortition with present anchor block={:?}",
                    &next_pox_info.selected_anchor_block(),
                );
                next_pox.extend_with_present_block();
            } else {
                info!(
                    "Begin reward-cycle sortition with absent anchor block={:?}",
                    &next_pox_info.selected_anchor_block(),
                );
                next_pox.extend_with_not_present_block();
            }
        };
        next_pox
    }

    /// Calculate the next sortition ID, given the PoX ID so far and the reward info
    pub fn make_next_sortition_id(
        parent_pox: PoxId,
        this_block_hash: &BurnchainHeaderHash,
        next_pox_info: Option<&RewardCycleInfo>,
    ) -> SortitionId {
        let next_pox = Self::make_next_pox_id(parent_pox, next_pox_info);
        let next_sortition_id = SortitionId::new(this_block_hash, &next_pox);
        next_sortition_id
    }

    /// Evaluate the sortition (SIP-001 miner block election) in the burnchain block defined by
    /// `burn_header`. Returns the new snapshot and burnchain state
    /// transition.
    ///
    /// # Arguments
    /// * `burn_header` - the burnchain block header to process sortition for
    /// * `ops` - the parsed blockstack operations (will be validated in this function)
    /// * `burnchain` - a reference to the burnchain information struct
    /// * `from_tip` - tip of the "sortition chain" that is being built on
    /// * `next_pox_info` - iff this sortition is the first block in a reward cycle, this should be Some
    /// * `announce_to` - a function that will be invoked with the calculated reward set before this method
    ///                   commits its results. This is used to post the calculated reward set to an event observer.
    pub fn evaluate_sortition<F: FnOnce(Option<RewardSetInfo>) -> ()>(
        &mut self,
        burn_header: &BurnchainBlockHeader,
        ops: Vec<BlockstackOperationType>,
        burnchain: &Burnchain,
        from_tip: &SortitionId,
        next_pox_info: Option<RewardCycleInfo>,
        announce_to: F,
    ) -> Result<(BlockSnapshot, BurnchainStateTransition), BurnchainError> {
        let dryrun = self.dryrun;
        let parent_sort_id = self
            .get_sortition_id(&burn_header.parent_block_hash, from_tip)?
            .ok_or_else(|| {
                warn!("Unknown block {:?}", burn_header.parent_block_hash);
                BurnchainError::MissingParentBlock
            })?;

        let cur_epoch = SortitionDB::get_stacks_epoch(self.conn(), burn_header.block_height)?
            .unwrap_or_else(|| {
                panic!(
                    "FATAL: no epoch defined for burn height {}",
                    burn_header.block_height
                )
            });

        let mut sortition_db_handle = SortitionHandleTx::begin(self, &parent_sort_id)?;
        let parent_snapshot = sortition_db_handle
            .get_block_snapshot(&burn_header.parent_block_hash, &parent_sort_id)?
            .ok_or_else(|| {
                warn!("Unknown block {:?}", burn_header.parent_block_hash);
                BurnchainError::MissingParentBlock
            })?;

        let parent_pox = sortition_db_handle.get_pox_id()?;
        test_debug!(
            "parent PoX ID of {:?} off of {} is {}",
            &burn_header.parent_block_hash,
            &from_tip,
            &parent_pox
        );

        let reward_set_vrf_hash = parent_snapshot
            .sortition_hash
            .mix_burn_header(&parent_snapshot.burn_header_hash);

        let reward_set_info = if burnchain
            .pox_constants
            .is_after_pox_sunset_end(burn_header.block_height, cur_epoch.epoch_id)
        {
            test_debug!(
                "No recipients for burn height {}: epoch = {}, sunset_end = {}",
                burnchain.pox_constants.sunset_end,
                cur_epoch.epoch_id,
                burn_header.block_height
            );
            None
        } else {
            sortition_db_handle.pick_recipients(
                burnchain,
                burn_header.block_height,
                &reward_set_vrf_hash,
                next_pox_info.as_ref(),
            )?
        };

        // Get any initial mining bonus which would be due to the winner of this block.
        let bonus_remaining =
            sortition_db_handle.get_initial_mining_bonus_remaining(&parent_sort_id)?;

        let initial_mining_bonus = if bonus_remaining > 0 {
            let mining_bonus_per_block = sortition_db_handle
                .get_initial_mining_bonus_per_block(&parent_sort_id)?
                .expect("BUG: initial mining bonus amount written, but not the per block amount.");
            cmp::min(bonus_remaining, mining_bonus_per_block)
        } else {
            0
        };

        let new_snapshot = sortition_db_handle.process_block_txs(
            &parent_snapshot,
            burn_header,
            burnchain,
            ops,
            next_pox_info,
            parent_pox,
            reward_set_info.as_ref(),
            initial_mining_bonus,
        )?;

        if !dryrun {
            sortition_db_handle
                .store_transition_ops(&new_snapshot.0.sortition_id, &new_snapshot.1)?;
        }

        announce_to(reward_set_info);

        if !dryrun {
            // commit everything!
            sortition_db_handle.commit().expect(
                "Failed to commit to sortition db after announcing reward set info, state corrupted.",
            );
        }
        Ok((new_snapshot.0, new_snapshot.1))
    }

    pub fn get_next_block_recipients(
        &mut self,
        burnchain: &Burnchain,
        parent_snapshot: &BlockSnapshot,
        next_pox_info: Option<&RewardCycleInfo>,
    ) -> Result<Option<RewardSetInfo>, BurnchainError> {
        let reward_set_vrf_hash = parent_snapshot
            .sortition_hash
            .mix_burn_header(&parent_snapshot.burn_header_hash);

        let cur_epoch =
            SortitionDB::get_stacks_epoch(self.conn(), parent_snapshot.block_height + 1)?
                .unwrap_or_else(|| {
                    panic!(
                        "FATAL: no epoch defined for burn height {}",
                        parent_snapshot.block_height + 1
                    )
                });

        let mut sortition_db_handle =
            SortitionHandleTx::begin(self, &parent_snapshot.sortition_id)?;
        if cur_epoch.epoch_id < StacksEpochId::Epoch21
            && parent_snapshot.block_height + 1 >= burnchain.pox_constants.sunset_end
        {
            Ok(None)
        } else {
            sortition_db_handle.pick_recipients(
                burnchain,
                parent_snapshot.block_height + 1,
                &reward_set_vrf_hash,
                next_pox_info,
            )
        }
    }

    pub fn is_stacks_block_in_sortition_set(
        &self,
        sortition_id: &SortitionId,
        block_to_check: &BlockHeaderHash,
    ) -> Result<bool, BurnchainError> {
        let result = self
            .index_handle(sortition_id)
            .get_tip_indexed(&db_keys::stacks_block_present(block_to_check))?;
        Ok(result.is_some())
    }

    #[cfg_attr(test, mutants::skip)]
    pub fn latest_stacks_blocks_processed(
        &self,
        sortition_id: &SortitionId,
    ) -> Result<u64, BurnchainError> {
        let db_handle = self.index_handle(sortition_id);
        SortitionDB::get_max_arrival_index(&db_handle).map_err(|e| BurnchainError::from(e))
    }

    /// Get a burn blockchain snapshot, given a burnchain configuration struct.
    /// Used mainly by the network code to determine what the chain tip currently looks like.
    pub fn get_burnchain_view(
        conn: &SortitionDBConn,
        burnchain: &Burnchain,
        chain_tip: &BlockSnapshot,
    ) -> Result<BurnchainView, db_error> {
        if chain_tip.block_height < burnchain.first_block_height {
            // should never happen, but don't panic since this is network-callable code
            error!(
                "Invalid block height from DB: {}: expected at least {}",
                chain_tip.block_height, burnchain.first_block_height
            );
            return Err(db_error::Corruption);
        }

        if chain_tip.block_height < burnchain.stable_confirmations as u64 {
            // should never happen, but don't panic since this is network-callable code
            error!(
                "Invalid block height from DB: {}: expected at least {}",
                chain_tip.block_height, burnchain.stable_confirmations
            );
            return Err(db_error::Corruption);
        }

        let stable_block_height = cmp::max(
            burnchain.first_block_height,
            chain_tip.block_height - (burnchain.stable_confirmations as u64),
        );

        // get all burn block hashes between the chain tip, and the stable height back
        // MAX_NEIGHBOR_BLOCK_DELAY
        let oldest_height = if stable_block_height < MAX_NEIGHBOR_BLOCK_DELAY {
            0
        } else {
            stable_block_height - MAX_NEIGHBOR_BLOCK_DELAY
        };

        let mut last_burn_block_hashes = HashMap::new();
        let tip_height = chain_tip.block_height;

        let mut cursor = chain_tip.clone();
        let mut cur_height = cursor.block_height;

        for _height in oldest_height..(tip_height + 1) {
            let (ancestor_hash, ancestor_height) =
                if cursor.block_height > burnchain.first_block_height {
                    match SortitionDB::get_block_snapshot(conn, &cursor.parent_sortition_id) {
                        Ok(Some(new_cursor)) => {
                            let ret = (cursor.burn_header_hash.clone(), cursor.block_height);

                            cursor = new_cursor;
                            assert_eq!(cursor.block_height + 1, cur_height);

                            cur_height = cursor.block_height;
                            ret
                        }
                        _ => {
                            cur_height = cur_height.saturating_sub(1);
                            (burnchain.first_block_hash.clone(), cur_height)
                        }
                    }
                } else {
                    cur_height = cur_height.saturating_sub(1);
                    (burnchain.first_block_hash.clone(), cur_height)
                };

            last_burn_block_hashes.insert(ancestor_height, ancestor_hash);
        }

        let burn_stable_block_hash = last_burn_block_hashes
            .get(&stable_block_height)
            .unwrap_or(&burnchain.first_block_hash)
            .clone();

        test_debug!(
            "Chain view: {},{}-{},{},{}",
            chain_tip.block_height,
            chain_tip.burn_header_hash,
            stable_block_height,
            &burn_stable_block_hash,
            &chain_tip.canonical_stacks_tip_consensus_hash,
        );
        Ok(BurnchainView {
            burn_block_height: chain_tip.block_height,
            burn_block_hash: chain_tip.burn_header_hash,
            burn_stable_block_height: stable_block_height,
            burn_stable_block_hash: burn_stable_block_hash,
            last_burn_block_hashes: last_burn_block_hashes,
            rc_consensus_hash: chain_tip.canonical_stacks_tip_consensus_hash,
        })
    }
}

// Querying methods
impl SortitionDB {
    /// Get the canonical burn chain tip -- the tip of the longest burn chain we know about.
    /// Break ties deterministically by ordering on burnchain block hash.
    pub fn get_canonical_burn_chain_tip(conn: &Connection) -> Result<BlockSnapshot, db_error> {
        let qry = "SELECT * FROM snapshots WHERE pox_valid = 1 ORDER BY block_height DESC, burn_header_hash ASC LIMIT 1";
        query_row(conn, qry, NO_PARAMS)
            .map(|opt| opt.expect("CORRUPTION: No canonical burnchain tip"))
    }

    /// Get the highest burn chain tip even if it's not PoX-valid.
    /// Break ties deterministically by ordering on burnchain block hash.
    pub fn get_highest_known_burn_chain_tip(conn: &Connection) -> Result<BlockSnapshot, db_error> {
        let qry =
            "SELECT * FROM snapshots ORDER BY block_height DESC, burn_header_hash ASC LIMIT 1";
        query_row(conn, qry, NO_PARAMS).map(|opt| opt.expect("CORRUPTION: No burnchain tips"))
    }

    /// Get the canonical burn chain tip -- the tip of the longest burn chain we know about.
    /// Break ties deterministically by ordering on burnchain block hash.
    pub fn get_canonical_chain_tip_bhh(conn: &Connection) -> Result<BurnchainHeaderHash, db_error> {
        let qry = "SELECT burn_header_hash FROM snapshots WHERE pox_valid = 1 ORDER BY block_height DESC, burn_header_hash ASC LIMIT 1";
        match conn.query_row(qry, NO_PARAMS, |row| row.get(0)).optional() {
            Ok(opt) => Ok(opt.expect("CORRUPTION: No canonical burnchain tip")),
            Err(e) => Err(db_error::from(e)),
        }
    }

    /// Get the canonical burn chain tip -- the tip of the longest burn chain we know about.
    /// Break ties deterministically by ordering on burnchain block hash.
    ///
    /// Returns Err if the underlying SQLite call fails.
    pub fn get_canonical_sortition_tip(conn: &Connection) -> Result<SortitionId, db_error> {
        let qry = "SELECT sortition_id FROM snapshots WHERE pox_valid = 1 ORDER BY block_height DESC, burn_header_hash ASC LIMIT 1";
        match conn.query_row(qry, NO_PARAMS, |row| row.get(0)).optional() {
            Ok(opt) => Ok(opt.expect("CORRUPTION: No canonical burnchain tip")),
            Err(e) => Err(db_error::from(e)),
        }
    }

    /// Find the affirmation map represented by a given sortition ID.
    pub fn find_sortition_tip_affirmation_map(
        &self,
        tip_id: &SortitionId,
    ) -> Result<AffirmationMap, db_error> {
        let ih = self.index_handle(tip_id);
        let am = ih.get_sortition_affirmation_map()?;

        // remove the first entry -- it's always `n` based on the way we construct it, while the
        // heaviest affirmation map just has nothing.
        if am.len() > 0 {
            Ok(AffirmationMap::new(am.as_slice()[1..].to_vec()))
        } else {
            Ok(AffirmationMap::empty())
        }
    }

    /// Get the list of Stack-STX operations processed in a given burnchain block.
    /// This will be the same list in each PoX fork; it's up to the Stacks block-processing logic
    /// to reject them.
    pub fn get_stack_stx_ops(
        conn: &Connection,
        burn_header_hash: &BurnchainHeaderHash,
    ) -> Result<Vec<StackStxOp>, db_error> {
        query_rows(
            conn,
            "SELECT * FROM stack_stx WHERE burn_header_hash = ? ORDER BY vtxindex",
            &[burn_header_hash],
        )
    }

    /// Get the list of Delegate-STX operations processed in a given burnchain block.
    /// This will be the same list in each PoX fork; it's up to the Stacks block-processing logic
    /// to reject them.
    pub fn get_delegate_stx_ops(
        conn: &Connection,
        burn_header_hash: &BurnchainHeaderHash,
    ) -> Result<Vec<DelegateStxOp>, db_error> {
        query_rows(
            conn,
            "SELECT * FROM delegate_stx WHERE burn_header_hash = ? ORDER BY vtxindex",
            &[burn_header_hash],
        )
    }

    /// Get the list of `vote-for-aggregate-key` operations processed in a given burnchain block.
    /// This will be the same list in each PoX fork; it's up to the Stacks block-processing logic
    /// to reject them.
    pub fn get_vote_for_aggregate_key_ops(
        conn: &Connection,
        burn_header_hash: &BurnchainHeaderHash,
    ) -> Result<Vec<VoteForAggregateKeyOp>, db_error> {
        query_rows(
            conn,
            "SELECT * FROM vote_for_aggregate_key WHERE burn_header_hash = ? ORDER BY vtxindex",
            &[burn_header_hash],
        )
    }

    /// Get the list of Transfer-STX operations processed in a given burnchain block.
    /// This will be the same list in each PoX fork; it's up to the Stacks block-processing logic
    /// to reject them.
    pub fn get_transfer_stx_ops(
        conn: &Connection,
        burn_header_hash: &BurnchainHeaderHash,
    ) -> Result<Vec<TransferStxOp>, db_error> {
        query_rows(
            conn,
            "SELECT * FROM transfer_stx WHERE burn_header_hash = ? ORDER BY vtxindex",
            &[burn_header_hash],
        )
    }

    /// Get the parent burnchain header hash of a given burnchain header hash
    fn get_parent_burnchain_header_hash(
        conn: &Connection,
        burnchain_header_hash: &BurnchainHeaderHash,
    ) -> Result<Option<BurnchainHeaderHash>, db_error> {
        let sql = "SELECT parent_burn_header_hash AS burn_header_hash FROM snapshots WHERE burn_header_hash = ?1";
        let args: &[&dyn ToSql] = &[burnchain_header_hash];
        let mut rows = query_rows::<BurnchainHeaderHash, _>(conn, sql, args)?;

        // there can be more than one if there was a PoX reorg.  If so, make sure they're _all the
        // same_ (otherwise we have corruption and must panic)
        if let Some(bhh) = rows.pop() {
            for row in rows.into_iter() {
                if row != bhh {
                    panic!(
                        "FATAL: burnchain header hash {} has two parents: {} and {}",
                        burnchain_header_hash, &bhh, &row
                    );
                }
            }
            Ok(Some(bhh))
        } else {
            Ok(None)
        }
    }

    /// Get the last N ancestor burnchain header hashes, given a burnchain header hash.
    /// This is done without regards to PoX forks.
    ///
    /// The returned list will be formatted as follows:
    ///
    /// * burn_header_hash
    /// * 1st ancestor of burn_header_hash
    /// * 2nd ancestor of burn_header_hash
    /// ...
    /// * Nth ancestor of burn_header_hash
    ///
    /// That is, the resulting list will have up to N+1 items.
    ///
    /// If an ancestor is not found, then return early.
    /// The returned list always starts with `burn_header_hash`.
    pub fn get_ancestor_burnchain_header_hashes(
        conn: &Connection,
        burn_header_hash: &BurnchainHeaderHash,
        count: u64,
    ) -> Result<Vec<BurnchainHeaderHash>, db_error> {
        let mut ret = vec![burn_header_hash.clone()];
        for _i in 0..count {
            let parent_bhh = match SortitionDB::get_parent_burnchain_header_hash(
                conn,
                ret.last().expect("FATAL: empty burn header hash list"),
            )? {
                Some(bhh) => bhh,
                None => {
                    break;
                }
            };
            ret.push(parent_bhh);
        }
        Ok(ret)
    }

    pub fn index_handle_at_tip<'a>(&'a self) -> SortitionHandleConn<'a> {
        let sortition_id = SortitionDB::get_canonical_sortition_tip(self.conn()).unwrap();
        self.index_handle(&sortition_id)
    }

    /// Open a tx handle at the burn chain tip
    pub fn tx_begin_at_tip<'a>(&'a mut self) -> SortitionHandleTx<'a> {
        let sortition_id = SortitionDB::get_canonical_sortition_tip(self.conn()).unwrap();
        self.tx_handle_begin(&sortition_id).unwrap()
    }

    /// Given a starting sortition ID, go and find the canonical Nakamoto tip
    /// Returns Ok(Some(tip info)) on success
    /// Returns Ok(None) if there are no Nakamoto blocks in this tip
    /// Returns Err(..) on other DB error
    pub fn get_canonical_nakamoto_tip_hash_and_height(
        conn: &Connection,
        tip: &BlockSnapshot,
    ) -> Result<Option<(ConsensusHash, BlockHeaderHash, u64)>, db_error> {
        let mut cursor = tip.clone();
        loop {
            let result_at_tip : Option<(ConsensusHash, BlockHeaderHash, u64)> = conn.query_row_and_then(
                "SELECT consensus_hash,block_hash,block_height FROM stacks_chain_tips WHERE sortition_id = ? ORDER BY block_height DESC LIMIT 1",
                &[&cursor.sortition_id],
                |row| Ok((row.get_unwrap(0), row.get_unwrap(1), (u64::try_from(row.get_unwrap::<_, i64>(2)).expect("FATAL: block height too high"))))
            ).optional()?;
            if let Some(stacks_tip) = result_at_tip {
                return Ok(Some(stacks_tip));
            }
            let Some(next_cursor) =
                SortitionDB::get_block_snapshot(conn, &cursor.parent_sortition_id)?
            else {
                return Ok(None);
            };
            cursor = next_cursor
        }
    }

    /// Get the canonical Stacks chain tip -- this gets memoized on the canonical burn chain tip.
    pub fn get_canonical_stacks_chain_tip_hash_and_height(
        conn: &Connection,
    ) -> Result<(ConsensusHash, BlockHeaderHash, u64), db_error> {
        let sn = SortitionDB::get_canonical_burn_chain_tip(conn)?;
        let cur_epoch =
            SortitionDB::get_stacks_epoch(conn, sn.block_height)?.unwrap_or_else(|| {
                panic!(
                    "FATAL: no epoch defined for burn height {}",
                    sn.block_height
                )
            });

        if cur_epoch.epoch_id >= StacksEpochId::Epoch30 {
            // nakamoto behavior -- look to the stacks_chain_tip table
            //  if the chain tip of the current sortition hasn't been set, have to iterate to parent
            return Self::get_canonical_nakamoto_tip_hash_and_height(conn, &sn)?
                .ok_or(db_error::NotFoundError);
        }

        // epoch 2.x behavior -- look at the snapshot itself
        let stacks_block_hash = sn.canonical_stacks_tip_hash;
        let consensus_hash = sn.canonical_stacks_tip_consensus_hash;
        let stacks_block_height = sn.canonical_stacks_tip_height;
        Ok((consensus_hash, stacks_block_hash, stacks_block_height))
    }

    /// Get the canonical Stacks chain tip -- this gets memoized on the canonical burn chain tip.
    pub fn get_canonical_stacks_chain_tip_hash(
        conn: &Connection,
    ) -> Result<(ConsensusHash, BlockHeaderHash), db_error> {
        Self::get_canonical_stacks_chain_tip_hash_and_height(conn)
            .map(|(ch, bhh, _height)| (ch, bhh))
    }

    /// Get the maximum arrival index for any known snapshot.
    fn get_max_arrival_index(conn: &Connection) -> Result<u64, db_error> {
        match conn
            .query_row(
                "SELECT IFNULL(MAX(arrival_index), 1) FROM snapshots",
                NO_PARAMS,
                |row| Ok(u64::from_row(row).expect("Expected u64 in database")),
            )
            .optional()?
        {
            Some(arrival_index) => Ok(if arrival_index == 0 { 1 } else { arrival_index }),
            None => Ok(1),
        }
    }

    /// Get a snapshot with an arrived block (i.e. a block that was marked as processed)
    fn get_snapshot_by_arrival_index(
        conn: &Connection,
        arrival_index: u64,
    ) -> Result<Option<BlockSnapshot>, db_error> {
        query_row_panic(
            conn,
            "SELECT * FROM snapshots WHERE arrival_index = ?1 AND stacks_block_accepted > 0 AND pox_valid = 1",
            &[&u64_to_sql(arrival_index)?],
            || "BUG: multiple snapshots have the same non-zero arrival index".to_string(),
        )
    }

    pub fn get_burnchain_header_hash_by_consensus(
        conn: &Connection,
        consensus_hash: &ConsensusHash,
    ) -> Result<Option<BurnchainHeaderHash>, db_error> {
        let qry = "SELECT burn_header_hash FROM snapshots WHERE consensus_hash = ?1 AND pox_valid = 1 LIMIT 1";
        let args = [&consensus_hash];
        query_row_panic(conn, qry, &args, || {
            format!(
                "FATAL: multiple block snapshots for the same block with consensus hash {}",
                consensus_hash
            )
        })
    }

    pub fn get_sortition_id_by_consensus(
        conn: &Connection,
        consensus_hash: &ConsensusHash,
    ) -> Result<Option<SortitionId>, db_error> {
        let qry = "SELECT sortition_id FROM snapshots WHERE consensus_hash = ?1 AND pox_valid = 1 LIMIT 1";
        let args = [&consensus_hash];
        query_row_panic(conn, qry, &args, || {
            format!(
                "FATAL: multiple block snapshots for the same block with consensus hash {}",
                consensus_hash
            )
        })
    }

    /// Get a snapshot for an existing burn chain block given its consensus hash.
    /// The snapshot may not be valid.
    pub fn get_block_snapshot_consensus(
        conn: &Connection,
        consensus_hash: &ConsensusHash,
    ) -> Result<Option<BlockSnapshot>, db_error> {
        let qry = "SELECT * FROM snapshots WHERE consensus_hash = ?1";
        let args = [&consensus_hash];
        query_row_panic(conn, qry, &args, || {
            format!(
                "FATAL: multiple block snapshots for the same block with consensus hash {}",
                consensus_hash
            )
        })
    }

    /// Determine if a burnchain block has been processed
    pub fn has_block_snapshot_consensus(
        conn: &Connection,
        consensus_hash: &ConsensusHash,
    ) -> Result<bool, db_error> {
        let qry = "SELECT 1 FROM snapshots WHERE consensus_hash = ?1";
        let args = [&consensus_hash];
        let res: Option<i64> = query_row_panic(conn, qry, &args, || {
            format!(
                "FATAL: multiple block snapshots for the same block with consensus hash {}",
                consensus_hash
            )
        })?;
        Ok(res.is_some())
    }

    /// Get a snapshot for an processed sortition.
    /// The snapshot may not be valid
    pub fn get_block_snapshot(
        conn: &Connection,
        sortition_id: &SortitionId,
    ) -> Result<Option<BlockSnapshot>, db_error> {
        let qry = "SELECT * FROM snapshots WHERE sortition_id = ?1";
        let args = [&sortition_id];
        query_row_panic(conn, qry, &args, || {
            format!(
                "FATAL: multiple block snapshots for the same block {}",
                sortition_id
            )
        })
        .map(|x| {
            if x.is_none() {
                test_debug!("No snapshot with sortition ID {}", sortition_id);
            }
            x
        })
    }

    /// Get the first snapshot
    pub fn get_first_block_snapshot(conn: &Connection) -> Result<BlockSnapshot, db_error> {
        let qry = "SELECT * FROM snapshots WHERE consensus_hash = ?1";
        let result = query_row_panic(conn, qry, &[&ConsensusHash::empty()], || {
            "FATAL: multiple first-block snapshots".into()
        })?;
        match result {
            None => {
                // should never happen
                panic!("FATAL: no first snapshot");
            }
            Some(snapshot) => Ok(snapshot),
        }
    }

    /// Get the first-ever block height and hash
    pub(crate) fn get_first_block_height_and_hash(
        conn: &Connection,
    ) -> Result<(u64, BurnchainHeaderHash), db_error> {
        let sql = "SELECT block_height, burn_header_hash FROM snapshots WHERE consensus_hash = ?1";
        let args = rusqlite::params!(&ConsensusHash::empty());
        let mut stmt = conn.prepare(sql)?;
        let mut rows = stmt.query(args)?;
        while let Some(row) = rows.next()? {
            let height_i64: i64 = row.get("block_height")?;
            let hash: BurnchainHeaderHash = row.get("burn_header_hash")?;
            let height = u64::try_from(height_i64).map_err(|_| {
                warn!("Height does not fit into a u64");
                db_error::ParseError
            })?;
            return Ok((height, hash));
        }
        // NOTE: shouldn't be reachable because we instantiate with a first snapshot
        return Err(db_error::NotFoundError);
    }

    pub fn is_pox_active(
        &self,
        burnchain: &Burnchain,
        block: &BlockSnapshot,
    ) -> Result<bool, db_error> {
        let mut reward_start_height = burnchain.reward_cycle_to_block_height(
            burnchain
                .block_height_to_reward_cycle(block.block_height)
                .ok_or_else(|| {
                    warn!(
                        "block height {} does not have a reward cycle",
                        block.block_height
                    );
                    db_error::NotFoundError
                })?,
        );

        // N.B. the reward cycle start height is 1 + (reward_cycle_number * reward_cycle_length),
        // which can be bigger than block.block_height. If this is true, then we really meant the
        // last reward cycle
        if reward_start_height > block.block_height && block.block_height > 0 {
            reward_start_height = burnchain.reward_cycle_to_block_height(
                burnchain
                    .block_height_to_reward_cycle(block.block_height - 1)
                    .ok_or_else(|| {
                        warn!(
                            "block height {} does not have a reward cycle",
                            block.block_height - 1
                        );
                        db_error::NotFoundError
                    })?,
            );
        }

        let sort_id_of_start =
            get_ancestor_sort_id(&self.index_conn(), reward_start_height, &block.sortition_id)?
                .ok_or_else(|| {
                    warn!(
                "reward start height {} (from block height {}) does not have a sortition from {}",
                reward_start_height, block.block_height, &block.sortition_id
            );
                    db_error::NotFoundError
                })?;

        let handle = self.index_handle(&sort_id_of_start);
        Ok(handle.get_reward_set_size_at(&sort_id_of_start)? > 0)
    }

    /// Find out how any burn tokens were destroyed in a given block on a given fork.
    pub fn get_block_burn_amount(
        conn: &Connection,
        block_snapshot: &BlockSnapshot,
    ) -> Result<u64, db_error> {
        let block_commits =
            SortitionDB::get_block_commits_by_block(conn, &block_snapshot.sortition_id)?;
        let mut burn_total: u64 = 0;

        for i in 0..block_commits.len() {
            burn_total = burn_total
                .checked_add(block_commits[i].burn_fee)
                .expect("Way too many tokens burned");
        }
        Ok(burn_total)
    }

    /// Get all block commitments registered in a block on the burn chain's history in this fork.
    /// Returns the list of block commits in order by vtxindex.
    pub fn get_block_commits_by_block(
        conn: &Connection,
        sortition: &SortitionId,
    ) -> Result<Vec<LeaderBlockCommitOp>, db_error> {
        let qry = "SELECT * FROM block_commits WHERE sortition_id = ?1 ORDER BY vtxindex ASC";
        let args: &[&dyn ToSql] = &[sortition];

        query_rows(conn, qry, args)
    }

    /// Get all the missed block commits that were intended to be included in the given
    ///  block but were not
    pub fn get_missed_commits_by_intended(
        conn: &Connection,
        sortition: &SortitionId,
    ) -> Result<Vec<MissedBlockCommit>, db_error> {
        let qry = "SELECT * FROM missed_commits WHERE intended_sortition_id = ?1";
        let args: &[&dyn ToSql] = &[sortition];

        query_rows(conn, qry, args)
    }

    /// Get all leader keys registered in a block on the burn chain's history in this fork.
    /// Returns the list of leader keys in order by vtxindex.
    pub fn get_leader_keys_by_block(
        conn: &Connection,
        sortition: &SortitionId,
    ) -> Result<Vec<LeaderKeyRegisterOp>, db_error> {
        let qry = "SELECT * FROM leader_keys WHERE sortition_id = ?1 ORDER BY vtxindex ASC";
        let args: &[&dyn ToSql] = &[sortition];

        query_rows(conn, qry, args)
    }

    /// Get the vtxindex of the winning sortition.
    /// The sortition may not be valid.
    pub fn get_block_winning_vtxindex(
        conn: &Connection,
        sortition: &SortitionId,
    ) -> Result<Option<u16>, db_error> {
        let qry = "SELECT vtxindex FROM block_commits WHERE sortition_id = ?1 
                    AND txid = (
                      SELECT winning_block_txid FROM snapshots WHERE sortition_id = ?2 LIMIT 1) LIMIT 1";
        let args: &[&dyn ToSql] = &[sortition, sortition];
        conn.query_row(qry, args, |row| row.get(0))
            .optional()
            .map_err(db_error::from)
    }

    /// Given the fork index hash of a chain tip, and a block height that is an ancestor of the last
    /// block in this fork, find the snapshot of the block at that height.
    ///
    /// Returns None if there is no ancestor at this height.
    pub fn get_ancestor_snapshot<C: SortitionContext>(
        ic: &IndexDBConn<'_, C, SortitionId>,
        ancestor_block_height: u64,
        tip_block_hash: &SortitionId,
    ) -> Result<Option<BlockSnapshot>, db_error> {
        assert!(ancestor_block_height < BLOCK_HEIGHT_MAX);

        let ancestor = match get_ancestor_sort_id(ic, ancestor_block_height, tip_block_hash)? {
            Some(id) => id,
            None => {
                debug!(
                    "No ancestor block {} from {} in index",
                    ancestor_block_height, tip_block_hash
                );
                return Ok(None);
            }
        };

        SortitionDB::get_block_snapshot(ic, &ancestor)
    }

    /// Given the fork index hash of a chain tip, and a block height that is an ancestor of the last
    /// block in this fork, find the snapshot of the block at that height.
    pub fn get_ancestor_snapshot_tx<C: SortitionContext>(
        ic: &mut IndexDBTx<'_, C, SortitionId>,
        ancestor_block_height: u64,
        tip_block_hash: &SortitionId,
    ) -> Result<Option<BlockSnapshot>, db_error> {
        assert!(ancestor_block_height < BLOCK_HEIGHT_MAX);

        let ancestor = match get_ancestor_sort_id_tx(ic, ancestor_block_height, tip_block_hash)? {
            Some(id) => id,
            None => {
                debug!(
                    "No ancestor block {} from {} in index",
                    ancestor_block_height, tip_block_hash
                );
                return Ok(None);
            }
        };

        SortitionDB::get_block_snapshot(ic.tx(), &ancestor)
    }

    /// Get a parent block commit at a specific location in the burn chain on a particular fork.
    /// Returns None if there is no block commit at this location.
    pub fn get_block_commit_parent<C: SortitionContext>(
        ic: &IndexDBConn<'_, C, SortitionId>,
        block_height: u64,
        vtxindex: u32,
        tip: &SortitionId,
    ) -> Result<Option<LeaderBlockCommitOp>, db_error> {
        assert!(block_height < BLOCK_HEIGHT_MAX);
        let ancestor_id = match get_ancestor_sort_id(ic, block_height, tip)? {
            Some(id) => id,
            None => {
                return Ok(None);
            }
        };

        SortitionDB::get_block_commit_of_sortition(ic, &ancestor_id, block_height, vtxindex)
    }

    fn get_block_commit_of_sortition(
        conn: &Connection,
        sortition: &SortitionId,
        block_height: u64,
        vtxindex: u32,
    ) -> Result<Option<LeaderBlockCommitOp>, db_error> {
        assert!(block_height < BLOCK_HEIGHT_MAX);

        let qry = "SELECT * FROM block_commits WHERE sortition_id = ?1 AND block_height = ?2 AND vtxindex = ?3 LIMIT 2";
        let args: &[&dyn ToSql] = &[sortition, &u64_to_sql(block_height)?, &vtxindex];
        query_row_panic(conn, qry, args, || {
            format!(
                "Multiple parent blocks at {},{} in {}",
                block_height, vtxindex, sortition
            )
        })
    }

    /// Get a leader key at a specific location in the burn chain's fork history, given the
    /// matching block commit's fork index root (block_height and vtxindex are the leader's
    /// calculated location in this fork).
    /// Returns None if there is no leader key at this location.
    pub fn get_leader_key_at<C: SortitionContext>(
        ic: &IndexDBConn<'_, C, SortitionId>,
        key_block_height: u64,
        key_vtxindex: u32,
        tip: &SortitionId,
    ) -> Result<Option<LeaderKeyRegisterOp>, db_error> {
        assert!(key_block_height < BLOCK_HEIGHT_MAX);
        let ancestor_snapshot = match SortitionDB::get_ancestor_snapshot(ic, key_block_height, tip)?
        {
            Some(sn) => sn,
            None => {
                return Ok(None);
            }
        };

        let qry = "SELECT * FROM leader_keys WHERE sortition_id = ?1 AND block_height = ?2 AND vtxindex = ?3 LIMIT 2";
        let args: &[&dyn ToSql] = &[
            &ancestor_snapshot.sortition_id,
            &u64_to_sql(key_block_height)?,
            &key_vtxindex,
        ];
        query_row_panic(ic, qry, args, || {
            format!(
                "Multiple keys at {},{} in {}",
                key_block_height, key_vtxindex, tip
            )
        })
    }

    /// Get a block commit by its committed block.
    /// For Stacks 2.x, `block_hash` is just the hash of the block
    /// For Nakamoto, `block_hash` is the StacksBlockId of the last tenure's first block
    pub fn get_block_commit_for_stacks_block(
        conn: &Connection,
        consensus_hash: &ConsensusHash,
        block_hash: &BlockHeaderHash,
    ) -> Result<Option<LeaderBlockCommitOp>, db_error> {
        let (sortition_id, winning_txid) = match SortitionDB::get_block_snapshot_consensus(
            conn,
            consensus_hash,
        )? {
            Some(sn) => {
                if !sn.pox_valid {
                    warn!("Consensus hash {:?} corresponds to a sortition that is not on the canonical PoX fork", consensus_hash);
                    return Err(db_error::InvalidPoxSortition);
                }
                (sn.sortition_id, sn.winning_block_txid)
            }
            None => {
                return Ok(None);
            }
        };

        let qry = "SELECT * FROM block_commits WHERE sortition_id = ?1 AND block_header_hash = ?2 AND txid = ?3";
        let args: [&dyn ToSql; 3] = [&sortition_id, &block_hash, &winning_txid];
        query_row_panic(conn, qry, &args, || {
            format!("FATAL: multiple block commits for {}", &block_hash)
        })
    }

    /// Get a block snapshot for a winning block hash in a given burn chain fork.
    pub fn get_block_snapshot_for_winning_stacks_block(
        ic: &SortitionDBConn,
        tip: &SortitionId,
        block_hash: &BlockHeaderHash,
    ) -> Result<Option<BlockSnapshot>, db_error> {
        match ic.get_indexed(tip, &db_keys::stacks_block_present(block_hash))? {
            Some(sortition_id_hex) => {
                let sortition_id = SortitionId::from_hex(&sortition_id_hex)
                    .expect("FATAL: DB stored non-parseable sortition id");
                SortitionDB::get_block_snapshot(ic, &sortition_id)
            }
            None => Ok(None),
        }
    }

    /// Merge the result of get_stacks_header_hashes() into a BlockHeaderCache
    pub fn merge_block_header_cache(
        cache: &mut BlockHeaderCache,
        header_data: &Vec<(ConsensusHash, Option<BlockHeaderHash>)>,
    ) -> () {
        if header_data.len() > 0 {
            let mut i = header_data.len() - 1;
            while i > 0 {
                let cur_consensus_hash = &header_data[i].0;
                let cur_block_opt = &header_data[i].1;

                if let Some((ref cached_block_opt, _)) = cache.get(cur_consensus_hash) {
                    assert_eq!(cached_block_opt, cur_block_opt);
                } else {
                    let prev_consensus_hash = header_data[i - 1].0.clone();
                    cache.insert(
                        (*cur_consensus_hash).clone(),
                        ((*cur_block_opt).clone(), prev_consensus_hash.clone()),
                    );
                }

                i -= 1;
            }
        }
        debug!("Block header cache has {} items", cache.len());
    }

    /// Get the StacksEpoch for a given burn block height
    pub fn get_stacks_epoch(
        conn: &DBConn,
        burn_block_height: u64,
    ) -> Result<Option<StacksEpoch>, db_error> {
        let sql =
            "SELECT * FROM epochs WHERE start_block_height <= ?1 AND ?2 < end_block_height LIMIT 1";
        let args: &[&dyn ToSql] = &[
            &u64_to_sql(burn_block_height)?,
            &u64_to_sql(burn_block_height)?,
        ];
        query_row(conn, sql, args)
    }

    /// Get all sortition IDs at the given burnchain block height (including ones that aren't on
    /// the canonical PoX fork)
    pub fn get_sortition_ids_at_height(
        conn: &DBConn,
        height: u64,
    ) -> Result<Vec<SortitionId>, db_error> {
        query_rows(
            conn,
            "SELECT sortition_id FROM snapshots WHERE block_height = ?1",
            &[&u64_to_sql(height)?],
        )
    }

    /// Get all StacksEpochs, in order by ascending start height
    pub fn get_stacks_epochs(conn: &DBConn) -> Result<Vec<StacksEpoch>, db_error> {
        let sql = "SELECT * FROM epochs ORDER BY start_block_height ASC";
        query_rows(conn, sql, NO_PARAMS)
    }

    pub fn get_stacks_epoch_by_epoch_id(
        conn: &DBConn,
        epoch_id: &StacksEpochId,
    ) -> Result<Option<StacksEpoch>, db_error> {
        let sql = "SELECT * FROM epochs WHERE epoch_id = ?1 LIMIT 1";
        let args: &[&dyn ToSql] = &[&(*epoch_id as u32)];
        query_row(conn, sql, args)
    }

    /// Are microblocks disabled by Epoch 2.5 at the height specified
    /// in `at_burn_height`?
    pub fn are_microblocks_disabled(conn: &DBConn, at_burn_height: u64) -> Result<bool, db_error> {
        match Self::get_stacks_epoch_by_epoch_id(conn, &StacksEpochId::Epoch25)? {
            Some(epoch_25) => Ok(at_burn_height >= epoch_25.start_height),
            None => {
                // Epoch 2.5 is not defined, so it cannot disable microblocks
                Ok(false)
            }
        }
    }

    /// Get the last reward cycle in epoch 2.05
    pub fn get_last_epoch_2_05_reward_cycle(&self) -> Result<u64, db_error> {
        Self::static_get_last_epoch_2_05_reward_cycle(
            self.conn(),
            self.first_block_height,
            &self.pox_constants,
        )
    }

    /// Get the last reward cycle in epoch 2.05
    pub fn static_get_last_epoch_2_05_reward_cycle(
        conn: &DBConn,
        first_block_height: u64,
        pox_constants: &PoxConstants,
    ) -> Result<u64, db_error> {
        let epochs = SortitionDB::get_stacks_epochs(conn)?;

        for epoch in epochs {
            if epoch.epoch_id == StacksEpochId::Epoch2_05 {
                return Ok(pox_constants
                    .block_height_to_reward_cycle(first_block_height, epoch.end_height)
                    .expect("FATAL: end block of epoch 2.05 is before system start height"));
            }
        }

        Ok(u64::MAX)
    }

    /// Get the latest block snapshot on this fork where a sortition occured.
    /// Search snapshots up to (but excluding) the given block height.
    /// Will always return a snapshot -- even if it's the initial sentinel snapshot.
    pub fn get_last_snapshot_with_sortition_tx(
        tx: &mut SortitionDBTx,
        burn_block_height: u64,
        chain_tip: &SortitionId,
    ) -> Result<BlockSnapshot, db_error> {
        assert!(burn_block_height < BLOCK_HEIGHT_MAX);
        test_debug!(
            "Get snapshot at from sortition tip {}, expect height {}",
            chain_tip,
            burn_block_height
        );
        let get_from = match get_ancestor_sort_id_tx(tx, burn_block_height, chain_tip)? {
            Some(sortition_id) => sortition_id,
            None => {
                error!(
                    "No blockheight {} ancestor at sortition identifier {}",
                    burn_block_height, &chain_tip
                );
                return Err(db_error::NotFoundError);
            }
        };

        let ancestor_hash = match tx.get_indexed(&get_from, &db_keys::last_sortition())? {
            Some(hex_str) => BurnchainHeaderHash::from_hex(&hex_str).unwrap_or_else(|_| {
                panic!(
                    "FATAL: corrupt database: failed to parse {} into a hex string",
                    &hex_str
                )
            }),
            None => {
                // no prior sortitions, so get the first
                return SortitionDB::get_first_block_snapshot(tx);
            }
        };

        let sortition_identifier_key = db_keys::sortition_id_for_bhh(&ancestor_hash);
        let sortition_id = match tx.get_indexed(chain_tip, &sortition_identifier_key)? {
            None => return SortitionDB::get_first_block_snapshot(tx),
            Some(x) => SortitionId::from_hex(&x).expect("FATAL: bad Sortition ID stored in DB"),
        };

        SortitionDB::get_block_snapshot(tx, &sortition_id)
            .map(|x| x.expect("FATAL: no snapshot for MARF'ed sortition ID"))
    }
}

impl<'a> SortitionHandleTx<'a> {
    /// Append a snapshot to a chain tip, and update various chain tip statistics.
    /// Returns the new state root of this fork.
    /// `initialize_bonus` - if Some(..), then this snapshot is the first mined snapshot,
    ///    and this method should initialize the `initial_mining_bonus` fields in the sortition db.
    pub fn append_chain_tip_snapshot(
        &mut self,
        parent_snapshot: &BlockSnapshot,
        snapshot: &BlockSnapshot,
        block_ops: &Vec<BlockstackOperationType>,
        missed_commits: &Vec<MissedBlockCommit>,
        next_pox_info: Option<RewardCycleInfo>,
        reward_info: Option<&RewardSetInfo>,
        initialize_bonus: Option<InitialMiningBonus>,
    ) -> Result<TrieHash, db_error> {
        assert_eq!(
            snapshot.parent_burn_header_hash,
            parent_snapshot.burn_header_hash
        );
        assert_eq!(snapshot.parent_sortition_id, parent_snapshot.sortition_id);
        assert_eq!(parent_snapshot.block_height + 1, snapshot.block_height);
        if snapshot.sortition {
            assert_eq!(parent_snapshot.num_sortitions + 1, snapshot.num_sortitions);
        } else {
            assert_eq!(parent_snapshot.num_sortitions, snapshot.num_sortitions);
        }

        let mut parent_sn = parent_snapshot.clone();
        let (root_hash, pox_payout) = self.index_add_fork_info(
            &mut parent_sn,
            snapshot,
            block_ops,
            next_pox_info,
            reward_info,
            initialize_bonus,
        )?;

        let mut sn = snapshot.clone();
        sn.index_root = root_hash.clone();

        let cur_epoch =
            SortitionDB::get_stacks_epoch(self, snapshot.block_height)?.unwrap_or_else(|| {
                panic!(
                    "FATAL: no epoch defined for burn height {}",
                    snapshot.block_height
                )
            });

        if cur_epoch.epoch_id >= StacksEpochId::Epoch30 {
            // nakamoto behavior
            // look at stacks_chain_tips table
            let res: Result<_, db_error> = self.deref().query_row_and_then(
                "SELECT consensus_hash,block_hash,block_height FROM stacks_chain_tips WHERE sortition_id = ? ORDER BY block_height DESC LIMIT 1",
                &[&parent_snapshot.sortition_id],
                |row| Ok((row.get_unwrap(0), row.get_unwrap(1), (u64::try_from(row.get_unwrap::<_, i64>(2)).expect("FATAL: block height too high"))))
            );
            let (
                canonical_stacks_tip_consensus_hash,
                canonical_stacks_tip_block_hash,
                canonical_stacks_tip_height,
            ) = res?;
            debug!(
                "Setting stacks_chain_tips values";
                "sortition_id" => %sn.sortition_id,
                "parent_sortition_id" => %parent_snapshot.sortition_id,
                "stacks_tip_height" => canonical_stacks_tip_height,
                "stacks_tip_hash" => %canonical_stacks_tip_block_hash,
                "stacks_tip_consensus" => %canonical_stacks_tip_consensus_hash
            );
            sn.canonical_stacks_tip_height = canonical_stacks_tip_height;
            sn.canonical_stacks_tip_hash = canonical_stacks_tip_block_hash;
            sn.canonical_stacks_tip_consensus_hash = canonical_stacks_tip_consensus_hash;
        } else {
            // epoch 2.x behavior
            // preserve memoized stacks chain tip from this burn chain fork
            sn.canonical_stacks_tip_height = parent_sn.canonical_stacks_tip_height;
            sn.canonical_stacks_tip_hash = parent_sn.canonical_stacks_tip_hash;
            sn.canonical_stacks_tip_consensus_hash = parent_sn.canonical_stacks_tip_consensus_hash;
        }

        if self.context.dryrun {
            // don't do any inserts
            return Ok(root_hash);
        }

        self.insert_block_snapshot(&sn, pox_payout)?;

        for block_op in block_ops {
            self.store_burnchain_transaction(block_op, &sn.sortition_id)?;
        }

        for missed_commit in missed_commits {
            self.insert_missed_block_commit(missed_commit)?;
        }

        self.update_canonical_stacks_tip(
            &sn.sortition_id,
            &sn.canonical_stacks_tip_consensus_hash,
            &sn.canonical_stacks_tip_hash,
            sn.canonical_stacks_tip_height,
        )?;

        #[cfg(test)]
        {
            let (block_consensus_hash, block_bhh) =
                SortitionDB::get_canonical_stacks_chain_tip_hash(self).unwrap();

            debug!(
                "After sortition {}, canonical Stacks tip is {}/{}",
                &snapshot.consensus_hash, &block_consensus_hash, &block_bhh
            );
        }
        Ok(root_hash)
    }

    pub fn get_initial_mining_bonus_remaining(
        &mut self,
        chain_tip: &SortitionId,
    ) -> Result<u128, db_error> {
        self.get_indexed(&chain_tip, db_keys::initial_mining_bonus_remaining())?
            .map(|s| Ok(s.parse().expect("BUG: bad mining bonus stored in DB")))
            .unwrap_or(Ok(0))
    }

    pub fn get_initial_mining_bonus_per_block(
        &mut self,
        chain_tip: &SortitionId,
    ) -> Result<Option<u128>, db_error> {
        Ok(self
            .get_indexed(&chain_tip, db_keys::initial_mining_bonus_per_block())?
            .map(|s| s.parse().expect("BUG: bad mining bonus stored in DB")))
    }

    #[cfg(any(test, feature = "testing"))]
    fn store_burn_distribution(
        &mut self,
        new_sortition: &SortitionId,
        transition: &BurnchainStateTransition,
    ) {
        let create = "CREATE TABLE IF NOT EXISTS snapshot_burn_distributions (sortition_id TEXT PRIMARY KEY, data TEXT NOT NULL);";
        self.execute(create, NO_PARAMS).unwrap();
        let sql = "INSERT INTO snapshot_burn_distributions (sortition_id, data) VALUES (?, ?)";
        let args: &[&dyn ToSql] = &[
            new_sortition,
            &serde_json::to_string(&transition.burn_dist).unwrap(),
        ];
        self.execute(sql, args).unwrap();
    }

    #[cfg(not(any(test, feature = "testing")))]
    fn store_burn_distribution(
        &mut self,
        _new_sortition: &SortitionId,
        _transition: &BurnchainStateTransition,
    ) {
    }

    fn store_transition_ops(
        &mut self,
        new_sortition: &SortitionId,
        transition: &BurnchainStateTransition,
    ) -> Result<(), db_error> {
        let sql = "INSERT INTO snapshot_transition_ops (sortition_id, accepted_ops, consumed_keys) VALUES (?, ?, ?)";
        let args: &[&dyn ToSql] = &[
            new_sortition,
            &serde_json::to_string(&transition.accepted_ops).unwrap(),
            &serde_json::to_string(&transition.consumed_leader_keys).unwrap(),
        ];
        self.execute(sql, args)?;
        self.store_burn_distribution(new_sortition, transition);
        Ok(())
    }

    pub fn get_pox_id(&mut self) -> Result<PoxId, db_error> {
        let chain_tip = self.context.chain_tip.clone();
        let pox_id = self
            .get_indexed(&chain_tip, db_keys::pox_identifier())?
            .map(|s| s.parse().expect("BUG: Bad PoX identifier stored in DB"))
            .expect("BUG: No PoX identifier stored.");
        Ok(pox_id)
    }

    /// Store a blockstack burnchain operation
    fn store_burnchain_transaction(
        &mut self,
        blockstack_op: &BlockstackOperationType,
        sort_id: &SortitionId,
    ) -> Result<(), db_error> {
        match blockstack_op {
            BlockstackOperationType::LeaderKeyRegister(ref op) => {
                info!(
                    "ACCEPTED({}) leader key register {} at {},{}",
                    op.block_height, &op.txid, op.block_height, op.vtxindex
                );
                self.insert_leader_key(op, sort_id)
            }
            BlockstackOperationType::LeaderBlockCommit(ref op) => {
                info!(
                    "ACCEPTED({}) leader block commit {} at {},{}",
                    op.block_height, &op.txid, op.block_height, op.vtxindex;
                    "apparent_sender" => %op.apparent_sender
                );
                self.insert_block_commit(op, sort_id)
            }
            BlockstackOperationType::StackStx(ref op) => {
                info!(
                    "ACCEPTED({}) stack stx opt {} at {},{}",
                    op.block_height, &op.txid, op.block_height, op.vtxindex
                );
                self.insert_stack_stx(op)
            }
            BlockstackOperationType::TransferStx(ref op) => {
                info!(
                    "ACCEPTED({}) transfer stx opt {} at {},{}",
                    op.block_height, &op.txid, op.block_height, op.vtxindex
                );
                self.insert_transfer_stx(op)
            }
            BlockstackOperationType::PreStx(ref op) => {
                info!(
                    "ACCEPTED({}) pre stack stx op {} at {},{}",
                    op.block_height, &op.txid, op.block_height, op.vtxindex
                );
                // no need to store this op in the sortition db.
                Ok(())
            }
            BlockstackOperationType::DelegateStx(ref op) => {
                info!(
                    "ACCEPTED({}) delegate stx opt {} at {},{}",
                    op.block_height, &op.txid, op.block_height, op.vtxindex
                );
                self.insert_delegate_stx(op)
            }
            BlockstackOperationType::VoteForAggregateKey(ref op) => {
                info!(
                    "ACCEPTED({}) vote for aggregate key {} at {},{}",
                    op.block_height, &op.txid, op.block_height, op.vtxindex
                );
                self.insert_vote_for_aggregate_key(op)
            }
        }
    }

    /// Insert a leader key registration.
    /// No validity checking will be done, beyond what is encoded in the leader_keys table
    /// constraints.  That is, type mismatches and serialization issues will be caught, but nothing else.
    /// The corresponding snapshot must already be inserted
    fn insert_leader_key(
        &mut self,
        leader_key: &LeaderKeyRegisterOp,
        sort_id: &SortitionId,
    ) -> Result<(), db_error> {
        assert!(leader_key.block_height < BLOCK_HEIGHT_MAX);

        let args: &[&dyn ToSql] = &[
            &leader_key.txid,
            &leader_key.vtxindex,
            &u64_to_sql(leader_key.block_height)?,
            &leader_key.burn_header_hash,
            &leader_key.consensus_hash,
            &leader_key.public_key.to_hex(),
            &to_hex(&leader_key.memo),
            sort_id,
        ];

        self.execute("INSERT INTO leader_keys (txid, vtxindex, block_height, burn_header_hash, consensus_hash, public_key, memo, sortition_id) VALUES (?1, ?2, ?3, ?4, ?5, ?6, ?7, ?8)", args)?;

        Ok(())
    }

    /// Insert a stack-stx op
    fn insert_stack_stx(&mut self, op: &StackStxOp) -> Result<(), db_error> {
        let args: &[&dyn ToSql] = &[
            &op.txid,
            &op.vtxindex,
            &u64_to_sql(op.block_height)?,
            &op.burn_header_hash,
            &op.sender.to_string(),
            &op.reward_addr.to_db_string(),
            &op.stacked_ustx.to_string(),
            &op.num_cycles,
            &serde_json::to_string(&op.signer_key).unwrap(),
            &serde_json::to_string(&op.max_amount).unwrap(),
            &op.auth_id,
        ];

        self.execute("REPLACE INTO stack_stx (txid, vtxindex, block_height, burn_header_hash, sender_addr, reward_addr, stacked_ustx, num_cycles, signer_key, max_amount, auth_id) VALUES (?1, ?2, ?3, ?4, ?5, ?6, ?7, ?8, ?9, ?10, ?11)", args)?;

        Ok(())
    }

    /// Insert a delegate-stx op
    fn insert_delegate_stx(&mut self, op: &DelegateStxOp) -> Result<(), db_error> {
        let args: &[&dyn ToSql] = &[
            &op.txid,
            &op.vtxindex,
            &u64_to_sql(op.block_height)?,
            &op.burn_header_hash,
            &op.sender.to_string(),
            &op.delegate_to.to_string(),
            &serde_json::to_string(&op.reward_addr).unwrap(),
            &op.delegated_ustx.to_string(),
            &opt_u64_to_sql(op.until_burn_height)?,
        ];

        self.execute("REPLACE INTO delegate_stx (txid, vtxindex, block_height, burn_header_hash, sender_addr, delegate_to, reward_addr, delegated_ustx, until_burn_height) VALUES (?1, ?2, ?3, ?4, ?5, ?6, ?7, ?8, ?9)", args)?;

        Ok(())
    }

    /// Insert a vote-for-aggregate-key op
    fn insert_vote_for_aggregate_key(
        &mut self,
        op: &VoteForAggregateKeyOp,
    ) -> Result<(), db_error> {
        let args: &[&dyn ToSql] = &[
            &op.txid,
            &op.vtxindex,
            &u64_to_sql(op.block_height)?,
            &op.burn_header_hash,
            &op.sender.to_string(),
            &serde_json::to_string(&op.aggregate_key).unwrap(),
            &op.round,
            &u64_to_sql(op.reward_cycle)?,
            &op.signer_index,
            &serde_json::to_string(&op.signer_key).unwrap(),
        ];

        self.execute("REPLACE INTO vote_for_aggregate_key (txid, vtxindex, block_height, burn_header_hash, sender_addr, aggregate_key, round, reward_cycle, signer_index, signer_key) VALUES (?1, ?2, ?3, ?4, ?5, ?6, ?7, ?8, ?9, ?10)", args)?;

        Ok(())
    }

    /// Insert a transfer-stx op
    fn insert_transfer_stx(&mut self, op: &TransferStxOp) -> Result<(), db_error> {
        let args: &[&dyn ToSql] = &[
            &op.txid,
            &op.vtxindex,
            &u64_to_sql(op.block_height)?,
            &op.burn_header_hash,
            &op.sender.to_string(),
            &op.recipient.to_string(),
            &op.transfered_ustx.to_string(),
            &to_hex(&op.memo),
        ];

        self.execute("REPLACE INTO transfer_stx (txid, vtxindex, block_height, burn_header_hash, sender_addr, recipient_addr, transfered_ustx, memo) VALUES (?1, ?2, ?3, ?4, ?5, ?6, ?7, ?8)", args)?;

        Ok(())
    }

    /// Insert a leader block commitment.
    /// No validity checking will be done, beyond what is encoded in the block_commits table
    /// constraints.  That is, type mismatches and serialization issues will be caught, but nothing else.
    /// The corresponding snapshot must already be inserted
    fn insert_block_commit(
        &mut self,
        block_commit: &LeaderBlockCommitOp,
        sort_id: &SortitionId,
    ) -> Result<(), db_error> {
        assert!(block_commit.block_height < BLOCK_HEIGHT_MAX);

        // serialize tx input to JSON
        let tx_input_str = serde_json::to_string(&block_commit.input)
            .map_err(|e| db_error::SerializationError(e))?;

        // serialize apparent sender to JSON
        let apparent_sender_str = serde_json::to_string(&block_commit.apparent_sender)
            .map_err(|e| db_error::SerializationError(e))?;

        // find parent block commit's snapshot's sortition ID.
        // If the parent_block_ptr doesn't point to a valid snapshot, then store an empty
        // sortition.  If we're not testing, then this should never happen.
        let parent_sortition_id = self
            .get_block_snapshot_by_height(block_commit.parent_block_ptr as u64)?
            .map(|parent_commit_sn| parent_commit_sn.sortition_id)
            .unwrap_or(SortitionId([0x00; 32]));

        if !cfg!(test) {
            if block_commit.parent_block_ptr != 0 || block_commit.parent_vtxindex != 0 {
                assert!(parent_sortition_id != SortitionId([0x00; 32]));
            }
        }

        let args: &[&dyn ToSql] = &[
            &block_commit.txid,
            &block_commit.vtxindex,
            &u64_to_sql(block_commit.block_height)?,
            &block_commit.burn_header_hash,
            &block_commit.block_header_hash,
            &block_commit.new_seed,
            &block_commit.parent_block_ptr,
            &block_commit.parent_vtxindex,
            &block_commit.key_block_ptr,
            &block_commit.key_vtxindex,
            &to_hex(&block_commit.memo[..]),
            &block_commit.burn_fee.to_string(),
            &tx_input_str,
            sort_id,
            &serde_json::to_value(&block_commit.commit_outs).unwrap(),
            &block_commit.sunset_burn.to_string(),
            &apparent_sender_str,
            &block_commit.burn_parent_modulus,
        ];

        self.execute("INSERT INTO block_commits (txid, vtxindex, block_height, burn_header_hash, block_header_hash, new_seed, parent_block_ptr, parent_vtxindex, key_block_ptr, key_vtxindex, memo, burn_fee, input, sortition_id, commit_outs, sunset_burn, apparent_sender, burn_parent_modulus) \
                      VALUES (?1, ?2, ?3, ?4, ?5, ?6, ?7, ?8, ?9, ?10, ?11, ?12, ?13, ?14, ?15, ?16, ?17, ?18)", args)?;

        let parent_args: &[&dyn ToSql] = &[sort_id, &block_commit.txid, &parent_sortition_id];

        debug!(
            "Parent sortition of {},{},{} is {} (parent at {},{})",
            &block_commit.txid,
            block_commit.block_height,
            block_commit.vtxindex,
            &parent_sortition_id,
            block_commit.parent_block_ptr,
            block_commit.parent_vtxindex
        );
        let res = self.execute("INSERT INTO block_commit_parents (block_commit_sortition_id, block_commit_txid, parent_sortition_id) VALUES (?1, ?2, ?3)", parent_args);

        // in tests, this table doesn't always exist.  Do nothing in that case, but in prod, error
        // out if this fails.
        if !cfg!(test) {
            res?;
        }

        Ok(())
    }

    /// Insert a missed block commit
    fn insert_missed_block_commit(&mut self, op: &MissedBlockCommit) -> Result<(), db_error> {
        // serialize tx input to JSON
        let tx_input_str =
            serde_json::to_string(&op.input).map_err(|e| db_error::SerializationError(e))?;

        let args: &[&dyn ToSql] = &[&op.txid, &op.intended_sortition, &tx_input_str];

        self.execute(
            "INSERT OR REPLACE INTO missed_commits (txid, intended_sortition_id, input) \
                      VALUES (?1, ?2, ?3)",
            args,
        )?;
        info!(
            "ACCEPTED missed block commit";
            "txid" => %op.txid,
            "intended_sortition" => %op.intended_sortition,
        );

        Ok(())
    }

    /// Insert a snapshots row from a block's-worth of operations.
    /// Do not call directly -- use append_chain_tip_snapshot to preserve the fork table structure.
    fn insert_block_snapshot(
        &self,
        snapshot: &BlockSnapshot,
        total_pox_payouts: (Vec<PoxAddress>, u128),
    ) -> Result<(), db_error> {
        assert!(snapshot.block_height < BLOCK_HEIGHT_MAX);
        assert!(snapshot.num_sortitions < BLOCK_HEIGHT_MAX);

        let pox_payouts_json = serde_json::to_string(&total_pox_payouts)
            .expect("FATAL: could not encode `total_pox_payouts` as JSON");

        test_debug!(
            "Insert block snapshot state {} for block {} ({},{}) {}, winner = {}",
            snapshot.index_root,
            snapshot.block_height,
            snapshot.burn_header_hash,
            snapshot.parent_burn_header_hash,
            snapshot.num_sortitions,
            &snapshot.winning_stacks_block_hash
        );

        // there had better not be any other valid snapshots for this block
        if snapshot.pox_valid {
            let all_valid_sortitions: Vec<i64> = query_rows(
                self,
                "SELECT 1 FROM snapshots WHERE burn_header_hash = ?1 AND pox_valid = 1 LIMIT 1",
                &[&snapshot.burn_header_hash],
            )?;
            if all_valid_sortitions.len() > 0 {
                error!("FATAL: Tried to insert snapshot {:?}, but already have pox-valid sortition for {:?}", &snapshot, &snapshot.burn_header_hash);
                panic!();
            }
        }

        let args: &[&dyn ToSql] = &[
            &u64_to_sql(snapshot.block_height)?,
            &snapshot.burn_header_hash,
            &u64_to_sql(snapshot.burn_header_timestamp)?,
            &snapshot.parent_burn_header_hash,
            &snapshot.consensus_hash,
            &snapshot.ops_hash,
            &snapshot.total_burn.to_string(),
            &snapshot.sortition,
            &snapshot.sortition_hash,
            &snapshot.winning_block_txid,
            &snapshot.winning_stacks_block_hash,
            &snapshot.index_root,
            &u64_to_sql(snapshot.num_sortitions)?,
            &snapshot.stacks_block_accepted,
            &u64_to_sql(snapshot.stacks_block_height)?,
            &u64_to_sql(snapshot.arrival_index)?,
            &u64_to_sql(snapshot.canonical_stacks_tip_height)?,
            &snapshot.canonical_stacks_tip_hash,
            &snapshot.canonical_stacks_tip_consensus_hash,
            &snapshot.sortition_id,
            &snapshot.parent_sortition_id,
            &snapshot.pox_valid,
            &snapshot.accumulated_coinbase_ustx.to_string(),
            &pox_payouts_json,
            &snapshot.miner_pk_hash,
        ];

        self.execute("INSERT INTO snapshots \
                      (block_height, burn_header_hash, burn_header_timestamp, parent_burn_header_hash, consensus_hash, ops_hash, total_burn, sortition, sortition_hash, winning_block_txid, winning_stacks_block_hash, index_root, num_sortitions, \
                      stacks_block_accepted, stacks_block_height, arrival_index, canonical_stacks_tip_height, canonical_stacks_tip_hash, canonical_stacks_tip_consensus_hash, sortition_id, parent_sortition_id, pox_valid, accumulated_coinbase_ustx, \
                      pox_payouts, miner_pk_hash) \
                      VALUES (?1, ?2, ?3, ?4, ?5, ?6, ?7, ?8, ?9, ?10, ?11, ?12, ?13, ?14, ?15, ?16, ?17, ?18, ?19, ?20, ?21, ?22, ?23, ?24, ?25)", args)
            .map_err(db_error::SqliteError)?;

        Ok(())
    }

    /// Get the expected number of PoX payouts per output
    fn get_num_pox_payouts(&self, burn_block_height: u64) -> usize {
        let op_num_outputs = if Burnchain::static_is_in_prepare_phase(
            self.context.first_block_height,
            self.context.pox_constants.reward_cycle_length as u64,
            self.context.pox_constants.prepare_length.into(),
            burn_block_height,
        ) {
            1
        } else {
            OUTPUTS_PER_COMMIT
        };
        op_num_outputs
    }

    /// Given all of a snapshot's block ops, calculate how many burnchain tokens were sent to each
    /// PoX payout.  Note that this value is *per payout*:
    /// * in a reward phase, multiply this by OUTPUTS_PER_COMMIT to get the total amount of tokens
    /// sent across all miners.
    /// * in a prepare phase, where there is only one output, this value is the total amount of
    /// tokens sent across all miners.
    fn get_pox_payout_per_output(&self, block_ops: &[BlockstackOperationType]) -> u128 {
        let mut total = 0u128;
        for block_op in block_ops.iter() {
            if let BlockstackOperationType::LeaderBlockCommit(ref op) = block_op {
                // burn_fee = pox_fee * OUTPUTS_PER_COMMIT
                // we're finding sum(pox_fee)
                let num_outputs = self.get_num_pox_payouts(op.block_height);
                total += (op.burn_fee as u128) / (num_outputs as u128);
            }
        }

        total
    }

    /// Record fork information to the index and calculate the new fork index root hash.
    /// * sortdb::vrf::${VRF_PUBLIC_KEY} --> 0 or 1 (1 if available, 0 if consumed), for each VRF public key we process
    /// * sortdb::last_sortition --> $BURN_BLOCK_HASH, for each block that had a sortition
    /// * sortdb::sortition_block_hash::${STACKS_BLOCK_HASH} --> $BURN_BLOCK_HASH for each winning block sortition
    /// * sortdb::stacks::block::${STACKS_BLOCK_HASH} --> ${STACKS_BLOCK_HEIGHT} for each block that has been accepted so far
    /// * sortdb::stacks::block::max_arrival_index --> ${ARRIVAL_INDEX} to set the maximum arrival index processed in this fork
    /// * sortdb::pox_reward_set::${n} --> recipient Bitcoin address, to track the reward set as the permutation progresses
    ///
    /// `recipient_info` is used to pass information to this function about which reward set addresses were consumed
    ///   during this sortition. this object will be None in the following cases:
    ///    * The reward cycle had an anchor block, but it isn't known by this node.
    ///    * The reward cycle did not have anchor block
    ///    * The Stacking recipient set is empty (either because this reward cycle has already exhausted the set of addresses or because no one ever Stacked).
    ///
    /// NOTE: the resulting index root must be globally unique.  This is guaranteed because each
    /// burn block hash is unique, no matter what fork it's on (and this index uses burn block
    /// hashes as its index's block hash data).
    fn index_add_fork_info(
        &mut self,
        parent_snapshot: &mut BlockSnapshot,
        snapshot: &BlockSnapshot,
        block_ops: &[BlockstackOperationType],
        next_pox_info: Option<RewardCycleInfo>,
        recipient_info: Option<&RewardSetInfo>,
        initialize_bonus: Option<InitialMiningBonus>,
    ) -> Result<(TrieHash, (Vec<PoxAddress>, u128)), db_error> {
        if !snapshot.is_initial() {
            assert_eq!(
                snapshot.parent_burn_header_hash,
                parent_snapshot.burn_header_hash
            );
            assert_eq!(&parent_snapshot.sortition_id, &self.context.chain_tip);
        }

        // data we want to store
        let mut keys = vec![];
        let mut values = vec![];

        // record each new VRF key, and each consumed VRF key
        for block_op in block_ops.iter() {
            if let BlockstackOperationType::LeaderKeyRegister(ref data) = block_op {
                keys.push(db_keys::vrf_key_status(&data.public_key));
                values.push("1".to_string()); // the value is no longer used, but the key needs to exist to figure whether a key was registered
            }
        }

        // map burnchain header hashes to sortition ids
        keys.push(db_keys::sortition_id_for_bhh(&snapshot.burn_header_hash));
        values.push(snapshot.sortition_id.to_hex());

        // if this commit has a sortition, record its burn block hash and stacks block hash
        if snapshot.sortition {
            keys.push(db_keys::last_sortition().to_string());
            values.push(snapshot.burn_header_hash.to_hex());

            keys.push(db_keys::stacks_block_present(
                &snapshot.winning_stacks_block_hash,
            ));
            values.push(snapshot.sortition_id.to_hex());
        }

        if let Some(initialize_bonus) = initialize_bonus {
            debug!("Add initial mining bonus: {:?}", &initialize_bonus);
            // first sortition with a winner, set the initial mining bonus fields
            keys.push(db_keys::initial_mining_bonus_per_block().into());
            values.push(initialize_bonus.per_block.to_string());

            let total_reward_remaining = initialize_bonus
                .total_reward
                .saturating_sub(initialize_bonus.per_block);
            keys.push(db_keys::initial_mining_bonus_remaining().into());
            values.push(total_reward_remaining.to_string());
        } else if parent_snapshot.total_burn > 0 {
            // mining has started, check if there's still any remaining bonus that this
            //  block consumed, and then decrement
            let prior_bonus_remaining =
                self.get_initial_mining_bonus_remaining(&parent_snapshot.sortition_id)?;
            if prior_bonus_remaining > 0 {
                let mining_bonus_per_block = self
                    .get_initial_mining_bonus_per_block(&parent_snapshot.sortition_id)?
                    .expect(
                        "BUG: initial mining bonus amount written, but not the per block amount.",
                    );
                let bonus_remaining = prior_bonus_remaining.saturating_sub(mining_bonus_per_block);
                keys.push(db_keys::initial_mining_bonus_remaining().into());
                values.push(bonus_remaining.to_string());
            }
        }

        // if this is the start of a reward cycle, store the new PoX keys.
        // Get the PoX payouts while doing so.
        let pox_payout = self.get_pox_payout_per_output(block_ops);
        let mut pox_payout_addrs = if !snapshot.is_initial() {
            if let Some(reward_info) = next_pox_info {
                let mut pox_id = self.get_pox_id()?;
                let pox_payout_addrs;

                // update the PoX bit vector with whether or not
                //  this reward cycle is aware of its anchor (if one wasn't selected,
                //   mark this as "known")
                if reward_info.is_reward_info_known() {
                    pox_id.extend_with_present_block();
                } else {
                    pox_id.extend_with_not_present_block();
                }

                let mut cur_affirmation_map = self.get_sortition_affirmation_map()?;
                let mut selected_anchor_block = false;

                // if we have selected an anchor block (known or unknown), write that info
                if let Some((anchor_block, anchor_block_txid)) = reward_info.selected_anchor_block()
                {
                    selected_anchor_block = true;

                    keys.push(db_keys::pox_anchor_to_prepare_end(anchor_block));
                    values.push(parent_snapshot.sortition_id.to_hex());

                    keys.push(db_keys::pox_last_anchor().to_string());
                    values.push(anchor_block.to_hex());

                    keys.push(db_keys::pox_last_anchor_txid().to_string());
                    values.push(anchor_block_txid.to_hex());

                    keys.push(db_keys::pox_affirmation_map().to_string());
                    values.push(cur_affirmation_map.encode());

                    keys.push(db_keys::pox_last_selected_anchor().to_string());
                    values.push(anchor_block.to_hex());

                    keys.push(db_keys::pox_last_selected_anchor_txid().to_string());
                    values.push(anchor_block_txid.to_hex());

                    debug!(
                        "Known anchor block {} txid {} at reward cycle starting at burn height {}",
                        anchor_block, anchor_block_txid, snapshot.block_height
                    );
                } else {
                    keys.push(db_keys::pox_last_anchor().to_string());
                    values.push("".to_string());

                    keys.push(db_keys::pox_last_anchor_txid().to_string());
                    values.push("".to_string());

                    cur_affirmation_map.push(AffirmationMapEntry::Nothing);

                    debug!(
                        "No anchor block at reward cycle starting at burn height {}",
                        snapshot.block_height
                    );
                }

                let _reward_cycle = reward_info.reward_cycle;

                // if we've selected an anchor _and_ know of the anchor,
                //  write the reward set information
                if let Some(mut reward_set) = reward_info.known_selected_anchor_block_owned() {
                    // record payouts separately from the remaining addresses, since some of them
                    // could have just been consumed.
                    if reward_set.rewarded_addresses.len() > 0 {
                        // if we have a reward set, then we must also have produced a recipient
                        //   info for this block
                        let mut recipients_to_remove: Vec<_> = recipient_info
                            .unwrap()
                            .recipients
                            .iter()
                            .map(|(addr, ix)| (addr.clone(), *ix))
                            .collect();
                        recipients_to_remove.sort_unstable_by(|(_, a), (_, b)| b.cmp(a));
                        // remove from the reward set any consumed addresses in this first reward block
                        let mut addrs = vec![];
                        for (addr, ix) in recipients_to_remove.iter() {
                            addrs.push(addr.clone());
                            assert_eq!(reward_set.rewarded_addresses.remove(*ix as usize).to_burnchain_repr(), addr.to_burnchain_repr(),
                                       "BUG: Attempted to remove used address from reward set, but failed to do so safely");
                        }
                        pox_payout_addrs = addrs;
                    } else {
                        // no payouts
                        pox_payout_addrs = vec![];
                    }

                    keys.push(db_keys::pox_reward_set_size().to_string());
                    values.push(db_keys::reward_set_size_to_string(
                        reward_set.rewarded_addresses.len(),
                    ));

                    // NOTE: the pox_addr _must_ come from the reward set (i.e. from the PoX
                    // contract), since we _must_ know the hash modes for standard addresses.  This
                    // information cannot be learned from the burnchain alone.
                    for (ix, pox_addr) in reward_set.rewarded_addresses.iter().enumerate() {
                        keys.push(db_keys::pox_reward_set_entry(ix as u16));
                        values.push(pox_addr.to_db_string());
                    }
                    // if there are qualifying auto-unlocks, record them
                    if !reward_set.start_cycle_state.is_empty() {
                        let cycle_number = Burnchain::static_block_height_to_reward_cycle(
                            snapshot.block_height,
                            self.context.first_block_height,
                            self.context.pox_constants.reward_cycle_length.into(),
                        )
                        .expect("FATAL: PoX reward cycle started before first block height");

                        keys.push(db_keys::pox_reward_cycle_unlocks(cycle_number));
                        values.push(reward_set.start_cycle_state.serialize());
                    }

                    cur_affirmation_map.push(AffirmationMapEntry::PoxAnchorBlockPresent);
                } else {
                    // no anchor block; we're burning
                    keys.push(db_keys::pox_reward_set_size().to_string());
                    values.push(db_keys::reward_set_size_to_string(0));

                    if selected_anchor_block {
                        cur_affirmation_map.push(AffirmationMapEntry::PoxAnchorBlockAbsent);
                    }

                    pox_payout_addrs = vec![];
                }

                // in all cases, write the new PoX bit vector
                keys.push(db_keys::pox_identifier().to_string());
                values.push(pox_id.to_string());

                keys.push(db_keys::pox_affirmation_map().to_string());
                values.push(cur_affirmation_map.encode());

                if cfg!(test) {
                    // last reward cycle.
                    // NOTE: We keep this only for testing, since this is what the original (but
                    // unmigratable code) did, and we need to verify that the compatibility fix to
                    // SortitionDB::get_last_processed_reward_cycle() is semantically compatible
                    // with querying this key.
                    keys.push(db_keys::last_reward_cycle_key().to_string());
                    values.push(db_keys::last_reward_cycle_to_string(_reward_cycle));
                }

                pox_payout_addrs
            } else {
                // if this snapshot consumed some reward set entries AND
                //  this isn't the start of a new reward cycle,
                //   update the reward set
                if let Some(reward_info) = recipient_info {
                    let mut current_len = self.get_reward_set_size()?;
                    let payout_addrs: Vec<_> = reward_info
                        .recipients
                        .iter()
                        .map(|(addr, _)| addr.clone())
                        .collect();
                    let mut recipient_indexes: Vec<_> =
                        reward_info.recipients.iter().map(|(_, x)| *x).collect();
                    let mut remapped_entries = HashMap::new();
                    // sort in decrementing order
                    recipient_indexes.sort_unstable_by(|a, b| b.cmp(a));
                    for index in recipient_indexes.into_iter() {
                        // sanity check
                        if index >= current_len {
                            unreachable!(
                                "Supplied index should never be greater than recipient set size"
                            );
                        } else if index + 1 == current_len {
                            // selected index is the last element: no need to swap, just decrement len
                            current_len -= 1;
                        } else {
                            let replacement = current_len - 1; // if current_len were 0, we would already have panicked.
                            let replace_with = if let Some((_prior_ix, replace_with)) =
                                remapped_entries.remove_entry(&replacement)
                            {
                                // the entry to swap in was itself swapped, so let's use the new value instead
                                replace_with
                            } else {
                                self.get_reward_set_entry(replacement)?
                            };

                            // NOTE: we have to have a hash mode for the address -- i.e. we have to be
                            // able to conver it to a clarity tuple -- since this data must be available
                            // via `get-burn-block-info?`.
                            assert!(
                                replace_with.as_clarity_tuple().is_some(),
                                "FATAL: do not know hash mode for next PoX address"
                            );

                            // swap and decrement to remove from set
                            remapped_entries.insert(index, replace_with);
                            current_len -= 1;
                        }
                    }
                    // store the changes in the new trie
                    keys.push(db_keys::pox_reward_set_size().to_string());
                    values.push(db_keys::reward_set_size_to_string(current_len as usize));

                    for (recipient_index, replace_with) in remapped_entries.into_iter() {
                        keys.push(db_keys::pox_reward_set_entry(recipient_index));
                        values.push(replace_with.to_db_string());
                    }

                    // reward-phase PoX payout addresses
                    payout_addrs
                } else {
                    // in prepare phase (no recipient info), so no payouts
                    vec![]
                }
            }
        } else {
            // initial snapshot
            assert_eq!(next_pox_info, None);
            keys.push(db_keys::pox_identifier().to_string());
            values.push(PoxId::initial().to_string());
            keys.push(db_keys::pox_reward_set_size().to_string());
            values.push(db_keys::reward_set_size_to_string(0));
            keys.push(db_keys::pox_last_anchor().to_string());
            values.push("".to_string());
            keys.push(db_keys::pox_last_anchor_txid().to_string());
            values.push("".to_string());
            keys.push(db_keys::pox_last_selected_anchor().to_string());
            values.push("".to_string());
            keys.push(db_keys::pox_last_selected_anchor_txid().to_string());
            values.push("".to_string());

            if cfg!(test) {
                // NOTE: We keep this only for testing, since this is what the original (but
                // unmigratable code) did, and we need to verify that the compatibility fix to
                // SortitionDB::get_last_processed_reward_cycle() is semantically compatible
                // with querying this key.
                keys.push(db_keys::last_reward_cycle_key().to_string());
                values.push(db_keys::last_reward_cycle_to_string(0));
            }

            // no payouts
            vec![]
        };

        // store each indexed field
        let root_hash = if !self.context.dryrun {
            // commit to all newly-arrived blocks
            let (mut block_arrival_keys, mut block_arrival_values) =
                self.process_new_block_arrivals(parent_snapshot)?;
            keys.append(&mut block_arrival_keys);
            values.append(&mut block_arrival_values);

            self.put_indexed_all(
                &parent_snapshot.sortition_id,
                &snapshot.sortition_id,
                &keys,
                &values,
            )?
        } else {
            TrieHash([0x00; 32])
        };

        // pox payout addrs must include burn addresses
        let num_pox_payouts = self.get_num_pox_payouts(snapshot.block_height);
        while pox_payout_addrs.len() < num_pox_payouts {
            // NOTE: while this coerces mainnet, it's totally fine in practice because the address
            // version is not exposed to Clarity.  Clarity only sees a PoX-specific version and the
            // hash.
            pox_payout_addrs.push(PoxAddress::standard_burn_address(true));
        }

        self.context.chain_tip = snapshot.sortition_id.clone();
        Ok((root_hash, (pox_payout_addrs, pox_payout)))
    }

    /// Resolve ties between blocks at the same height.
    /// Hashes the given snapshot's sortition hash with the index block hash for each block
    /// (calculated from `new_block_arrivals`' consensus hash and block header hash), and chooses
    /// the block in `new_block_arrivals` whose resulting hash is lexographically the smallest.
    /// Returns the index into `new_block_arrivals` for the block whose hash is the smallest.
    fn break_canonical_stacks_tip_tie(
        tip: &BlockSnapshot,
        best_height: u64,
        new_block_arrivals: &[(ConsensusHash, BlockHeaderHash, u64)],
    ) -> Option<usize> {
        // if there's a tie, then randomly and deterministically pick one
        let mut tied = vec![];
        for (i, (consensus_hash, block_bhh, height)) in new_block_arrivals.iter().enumerate() {
            if best_height == *height {
                tied.push((StacksBlockId::new(consensus_hash, block_bhh), i));
            }
        }

        if tied.len() == 0 {
            return None;
        }
        if tied.len() == 1 {
            return Some(tied[0].1);
        }

        // break ties by hashing the index block hash with the snapshot's sortition hash, and
        // picking the lexicographically smallest one
        let mut hash_tied = vec![];
        let mut mapping = HashMap::new();
        for (block_id, arrival_idx) in tied.into_iter() {
            let mut buff = [0u8; 64];
            buff[0..32].copy_from_slice(&block_id.0);
            buff[32..64].copy_from_slice(&tip.sortition_hash.0);

            let hashed = Sha512Trunc256Sum::from_data(&buff);
            hash_tied.push(hashed.clone());
            mapping.insert(hashed, arrival_idx);
        }

        hash_tied.sort();
        let winner = hash_tied
            .first()
            .expect("FATAL: zero-length list of tied block IDs");

        let winner_index = *mapping
            .get(&winner)
            .expect("FATAL: winning block ID not mapped");

        Some(winner_index)
    }

    /// Find the new Stacks block arrivals as of the given tip `parent_tip`, and returns
    /// the highest Stacks chain tip and maximum arrival index.
    /// Used for both discovering the new arrivals and processing them with new snapshots.
    ///
    /// Returns Ok((
    ///     stacks tip consensus hash,
    ///     stacks tip block header hash,
    ///     stacks tip height,
    ///     max arrival index,
    ///     list of all blocks that have arrived since this parent_tip
    /// ))
    fn inner_find_new_block_arrivals(
        &mut self,
        parent_tip: &BlockSnapshot,
    ) -> Result<
        (
            ConsensusHash,
            BlockHeaderHash,
            u64,
            u64,
            Vec<(BlockHeaderHash, u64)>,
        ),
        db_error,
    > {
        let mut new_block_arrivals = vec![];

        let old_max_arrival_index = self
            .get_indexed(
                &parent_tip.sortition_id,
                &db_keys::stacks_block_max_arrival_index(),
            )?
            .unwrap_or("1".into())
            .parse::<u64>()
            .expect("BUG: max arrival index is not a u64");

        let max_arrival_index = SortitionDB::get_max_arrival_index(self.tx())?;

        // find all Stacks block hashes who arrived since this parent_tip was built.
        for ari in old_max_arrival_index..(max_arrival_index + 1) {
            test_debug!("Get block with arrival index {}", ari);
            let arrival_sn = match SortitionDB::get_snapshot_by_arrival_index(self.tx(), ari)? {
                Some(sn) => sn,
                None => {
                    continue;
                }
            };
            if !arrival_sn.pox_valid {
                continue;
            }

            // must be an ancestor of this tip, or must be this tip
            if let Some(sn) =
                self.get_block_snapshot(&arrival_sn.burn_header_hash, &parent_tip.sortition_id)?
            {
                if !sn.pox_valid || sn != arrival_sn {
                    continue;
                }

                debug!(
                    "New Stacks anchored block arrived: block {}/{} ({}) ari={} tip={}",
                    &sn.consensus_hash,
                    &sn.winning_stacks_block_hash,
                    sn.stacks_block_height,
                    ari,
                    &parent_tip.burn_header_hash
                );
                new_block_arrivals.push((
                    sn.consensus_hash,
                    sn.winning_stacks_block_hash,
                    sn.stacks_block_height,
                ));
            } else {
                // this block did not arrive on an ancestor block
                continue;
            }
        }

        let mut best_tip_block_bhh = parent_tip.canonical_stacks_tip_hash.clone();
        let mut best_tip_consensus_hash = parent_tip.canonical_stacks_tip_consensus_hash.clone();
        let mut best_tip_height = parent_tip.canonical_stacks_tip_height;
        let mut ret = vec![];

        debug!(
            "Current best tip is {}/{} (height {})",
            &best_tip_consensus_hash, &best_tip_block_bhh, best_tip_height
        );

        for (consensus_hash, block_bhh, height) in new_block_arrivals.iter() {
            ret.push((block_bhh.clone(), *height));

            // genesis blocks are incomparable -- it doesn't matter which one was "first."
            // everyone else must be higher than the highest known tip to supersede it.
            if *height > best_tip_height || (*height == 0 && best_tip_height == 0) {
                debug!(
                    "At tip {}: {}/{} (height {}) is superceded by {}/{} (height {})",
                    &parent_tip.burn_header_hash,
                    &best_tip_consensus_hash,
                    &best_tip_block_bhh,
                    best_tip_height,
                    consensus_hash,
                    block_bhh,
                    *height
                );

                best_tip_block_bhh = block_bhh.clone();
                best_tip_consensus_hash = consensus_hash.clone();
                best_tip_height = *height;
            }
        }

        // if there's a tie, then randomly and deterministically pick one
        let winning_index_opt = SortitionHandleTx::break_canonical_stacks_tip_tie(
            parent_tip,
            best_tip_height,
            &new_block_arrivals,
        );
        if let Some(winning_index) = winning_index_opt {
            best_tip_consensus_hash = new_block_arrivals[winning_index].0;
            best_tip_block_bhh = new_block_arrivals[winning_index].1;
        }

        debug!(
            "Max arrival for child of {} is {} (hash {} height {})",
            &best_tip_consensus_hash, &max_arrival_index, &best_tip_block_bhh, best_tip_height
        );

        Ok((
            best_tip_consensus_hash,
            best_tip_block_bhh,
            best_tip_height,
            max_arrival_index,
            ret,
        ))
    }

    /// Find the new Stacks block arrivals as of the given tip `tip`, and return the highest chain
    /// tip discovered.
    ///
    /// Used in conjunction with update_new_block_arrivals().
    ///
    /// Returns Ok((
    ///     stacks tip consensus hash,
    ///     stacks tip block header hash,
    ///     stacks tip height,
    /// ))
    fn find_new_block_arrivals(
        &mut self,
        tip: &BlockSnapshot,
    ) -> Result<(ConsensusHash, BlockHeaderHash, u64), db_error> {
        self.inner_find_new_block_arrivals(tip)
            .map(|(ch, bhh, height, _, _)| (ch, bhh, height))
    }

    /// Update the given tip's canonical Stacks block pointer.
    /// Does so on all sortitions of the same height as tip.
    /// Only used in Stacks 2.x
    fn update_new_block_arrivals(
        &mut self,
        tip: &BlockSnapshot,
        best_chh: ConsensusHash,
        best_bhh: BlockHeaderHash,
        best_height: u64,
    ) -> Result<(), db_error> {
        let args: &[&dyn ToSql] = &[
            &best_chh,
            &best_bhh,
            &u64_to_sql(best_height)?,
            &u64_to_sql(tip.block_height)?,
        ];

        debug!(
            "Canonical Stacks tip at ({},{}) is {}/{} (height {})",
            &tip.block_height, &tip.burn_header_hash, &best_chh, &best_bhh, best_height
        );
        self.execute("UPDATE snapshots SET canonical_stacks_tip_consensus_hash = ?1, canonical_stacks_tip_hash = ?2, canonical_stacks_tip_height = ?3
                    WHERE block_height = ?4", args)
            .map_err(db_error::SqliteError)?;
        Ok(())
    }

    /// Find all stacks blocks that were processed since parent_tip had been processed, and generate MARF
    /// key/value pairs for the subset that arrived on ancestor blocks of the parent.  Update the
    /// given parent chain tip to have the correct memoized canonical chain tip present in the fork
    /// it represents.
    fn process_new_block_arrivals(
        &mut self,
        parent_tip: &mut BlockSnapshot,
    ) -> Result<(Vec<String>, Vec<String>), db_error> {
        let mut keys = vec![];
        let mut values = vec![];

        let (
            best_tip_consensus_hash,
            best_tip_block_bhh,
            best_tip_height,
            max_arrival_index,
            new_arrivals,
        ) = self.inner_find_new_block_arrivals(parent_tip)?;

        // generate MARF key/value pairs for new arrivals
        for (block_bhh, height) in new_arrivals.into_iter() {
            keys.push(db_keys::stacks_block_index(&block_bhh));
            values.push(db_keys::stacks_block_index_value(height));
        }

        // update parent tip
        parent_tip.canonical_stacks_tip_consensus_hash = best_tip_consensus_hash;
        parent_tip.canonical_stacks_tip_hash = best_tip_block_bhh;
        parent_tip.canonical_stacks_tip_height = best_tip_height;

        // generate MARF key/value pairs for highest arrival
        keys.push(db_keys::stacks_block_max_arrival_index());
        values.push(db_keys::stacks_block_max_arrival_index_value(
            max_arrival_index,
        ));

        Ok((keys, values))
    }
}

impl ChainstateDB for SortitionDB {
    fn backup(_backup_path: &str) -> Result<(), db_error> {
        return Err(db_error::NotImplemented);
    }
}

#[cfg(test)]
pub mod tests {
    use std::sync::mpsc::sync_channel;
    use std::thread;

    use rusqlite::NO_PARAMS;
    use stacks_common::address::AddressHashMode;
    use stacks_common::types::chainstate::{BlockHeaderHash, StacksAddress, VRFSeed};
    use stacks_common::util::get_epoch_time_secs;
    use stacks_common::util::hash::{hex_bytes, Hash160};
    use stacks_common::util::vrf::*;

    use super::*;
    use crate::burnchains::affirmation::AffirmationMap;
    use crate::burnchains::bitcoin::address::BitcoinAddress;
    use crate::burnchains::bitcoin::keys::BitcoinPublicKey;
    use crate::burnchains::bitcoin::BitcoinNetworkType;
    use crate::burnchains::tests::affirmation::{make_reward_cycle, make_simple_key_register};
    use crate::burnchains::*;
    use crate::chainstate::burn::operations::leader_block_commit::BURN_BLOCK_MINED_AT_MODULUS;
    use crate::chainstate::burn::operations::{
        BlockstackOperationType, LeaderBlockCommitOp, LeaderKeyRegisterOp,
    };
    use crate::chainstate::burn::ConsensusHash;
    use crate::chainstate::stacks::index::TrieHashExtension;
    use crate::chainstate::stacks::StacksPublicKey;
    use crate::core::{StacksEpochExtension, *};
    use crate::util_lib::db::Error as db_error;

    impl<'a> SortitionHandleConn<'a> {
        /// At one point in the development lifecycle, this code depended on a MARF key/value
        /// pair to map the sortition tip to the last-processed reward cycle number.  This data would
        /// not have been present in epoch 2.4 chainstate and earlier, but would have been present in
        /// epoch 2.5 and later, since at the time it was expected that all nodes would perform a
        /// genesis sync when booting into epoch 2.5.  However, that requirement changed at the last
        /// minute, so this code was reworked to avoid the need for the MARF key.  But to ensure that
        /// this method is semantically consistent with the old code (which the Nakamoto chains
        /// coordinator depends on), this code will test that the new reward cycle calculation matches
        /// the old reward cycle calculation.
        #[cfg(test)]
        pub fn legacy_get_last_processed_reward_cycle(&self) -> Result<u64, db_error> {
            // verify that this is semantically compatible with the older behavior, which shipped
            // for epoch 2.5 but needed to be removed at the last minute in order to support a
            // migration path from 2.4 chainstate to 2.5/3.0 chainstate.
            let encoded_rc = self
                .get_indexed(&self.context.chain_tip, &db_keys::last_reward_cycle_key())?
                .expect("FATAL: no last-processed reward cycle");

            let expected_rc = db_keys::last_reward_cycle_from_string(&encoded_rc);
            Ok(expected_rc)
        }
    }

    impl<'a> SortitionHandleTx<'a> {
        /// Update the canonical Stacks tip (testing only)
        pub fn test_update_canonical_stacks_tip(
            &mut self,
            sort_id: &SortitionId,
            consensus_hash: &ConsensusHash,
            stacks_block_hash: &BlockHeaderHash,
            stacks_block_height: u64,
        ) -> Result<(), db_error> {
            self.update_canonical_stacks_tip(
                sort_id,
                consensus_hash,
                stacks_block_hash,
                stacks_block_height,
            )
        }
    }

    impl SortitionDB {
        /// Open a burn database at random tmp dir (used for testing)
        pub fn connect_test(
            first_block_height: u64,
            first_burn_hash: &BurnchainHeaderHash,
        ) -> Result<SortitionDB, db_error> {
            use crate::core::StacksEpochExtension;
            SortitionDB::connect_test_with_epochs(
                first_block_height,
                first_burn_hash,
                StacksEpoch::unit_test(StacksEpochId::Epoch20, first_block_height),
            )
        }

        /// Open a burn database at random tmp dir (used for testing)
        /// But, take a particular epoch configuration
        pub fn connect_test_with_epochs(
            first_block_height: u64,
            first_burn_hash: &BurnchainHeaderHash,
            epochs: Vec<StacksEpoch>,
        ) -> Result<SortitionDB, db_error> {
            let mut rng = rand::thread_rng();
            let mut buf = [0u8; 32];
            rng.fill_bytes(&mut buf);
            let db_path_dir = format!(
                "/tmp/stacks-node-tests/unit-tests-sortdb/db-{}",
                to_hex(&buf)
            );

            SortitionDB::connect(
                &db_path_dir,
                first_block_height,
                first_burn_hash,
                get_epoch_time_secs(),
                &epochs,
                PoxConstants::test_default(),
                None,
                true,
            )
        }

        pub fn connect_v1(
            path: &str,
            first_block_height: u64,
            first_burn_hash: &BurnchainHeaderHash,
            first_burn_header_timestamp: u64,
            readwrite: bool,
        ) -> Result<SortitionDB, db_error> {
            let create_flag = match fs::metadata(path) {
                Err(e) => {
                    if e.kind() == ErrorKind::NotFound {
                        // need to create
                        if readwrite {
                            true
                        } else {
                            return Err(db_error::NoDBError);
                        }
                    } else {
                        return Err(db_error::IOError(e));
                    }
                }
                Ok(_md) => false,
            };

            let index_path = db_mkdirs(path)?;
            debug!(
                "Connect/Open {} sortdb '{}' as '{}'",
                if create_flag { "(create)" } else { "" },
                index_path,
                if readwrite { "readwrite" } else { "readonly" }
            );

            let marf = SortitionDB::open_index(&index_path)?;

            let mut db = SortitionDB {
                path: path.to_string(),
                marf,
                readwrite,
                dryrun: false,
                first_block_height,
                first_burn_header_hash: first_burn_hash.clone(),
                pox_constants: PoxConstants::test_default(),
            };

            if create_flag {
                // instantiate!
                db.instantiate_v1(
                    first_block_height,
                    first_burn_hash,
                    first_burn_header_timestamp,
                )?;
            } else {
                // validate -- must contain the given first block and first block hash
                let snapshot = SortitionDB::get_first_block_snapshot(db.conn())?;
                if !snapshot.is_initial()
                    || snapshot.block_height != first_block_height
                    || snapshot.burn_header_hash != *first_burn_hash
                {
                    error!("Invalid genesis snapshot: sn.is_initial = {}, sn.block_height = {}, sn.burn_hash = {}, expect.block_height = {}, expect.burn_hash = {}",
                           snapshot.is_initial(), snapshot.block_height, &snapshot.burn_header_hash, first_block_height, first_burn_hash);
                    return Err(db_error::Corruption);
                }
            }

            Ok(db)
        }

        fn instantiate_v1(
            &mut self,
            first_block_height: u64,
            first_burn_header_hash: &BurnchainHeaderHash,
            first_burn_header_timestamp: u64,
        ) -> Result<(), db_error> {
            debug!("Instantiate SortDB");

            sql_pragma(self.conn(), "journal_mode", &"WAL")?;
            sql_pragma(self.conn(), "foreign_keys", &true)?;

            let mut db_tx = SortitionHandleTx::begin(self, &SortitionId::sentinel())?;

            // create first (sentinel) snapshot
            debug!("Make first snapshot");
            let mut first_snapshot = BlockSnapshot::initial(
                first_block_height,
                first_burn_header_hash,
                first_burn_header_timestamp,
            );

            assert!(first_snapshot.parent_burn_header_hash != first_snapshot.burn_header_hash);
            assert_eq!(
                first_snapshot.parent_burn_header_hash,
                BurnchainHeaderHash::sentinel()
            );

            for row_text in SORTITION_DB_INITIAL_SCHEMA {
                db_tx.execute_batch(row_text)?;
            }

            db_tx.execute(
                "INSERT OR REPLACE INTO db_config (version) VALUES (?1)",
                &[&"1"],
            )?;

            db_tx.instantiate_index()?;

            let mut first_sn = first_snapshot.clone();
            first_sn.sortition_id = SortitionId::sentinel();
            let (index_root, pox_payout) = db_tx.index_add_fork_info(
                &mut first_sn,
                &first_snapshot,
                &vec![],
                None,
                None,
                None,
            )?;
            first_snapshot.index_root = index_root;

            // manually insert the first block snapshot in instantiate_v1 testing code, because
            //  SCHEMA_8 adds a new column
            let pox_payouts_json = serde_json::to_string(&pox_payout)
                .expect("FATAL: could not encode `total_pox_payouts` as JSON");

            let args = rusqlite::params![
                &u64_to_sql(first_snapshot.block_height)?,
                &first_snapshot.burn_header_hash,
                &u64_to_sql(first_snapshot.burn_header_timestamp)?,
                &first_snapshot.parent_burn_header_hash,
                &first_snapshot.consensus_hash,
                &first_snapshot.ops_hash,
                &first_snapshot.total_burn.to_string(),
                &first_snapshot.sortition,
                &first_snapshot.sortition_hash,
                &first_snapshot.winning_block_txid,
                &first_snapshot.winning_stacks_block_hash,
                &first_snapshot.index_root,
                &u64_to_sql(first_snapshot.num_sortitions)?,
                &first_snapshot.stacks_block_accepted,
                &u64_to_sql(first_snapshot.stacks_block_height)?,
                &u64_to_sql(first_snapshot.arrival_index)?,
                &u64_to_sql(first_snapshot.canonical_stacks_tip_height)?,
                &first_snapshot.canonical_stacks_tip_hash,
                &first_snapshot.canonical_stacks_tip_consensus_hash,
                &first_snapshot.sortition_id,
                &first_snapshot.parent_sortition_id,
                &first_snapshot.pox_valid,
                &first_snapshot.accumulated_coinbase_ustx.to_string(),
                &pox_payouts_json,
            ];

            db_tx.execute("INSERT INTO snapshots \
                          (block_height, burn_header_hash, burn_header_timestamp, parent_burn_header_hash, consensus_hash, ops_hash, total_burn, sortition, sortition_hash, winning_block_txid, winning_stacks_block_hash, index_root, num_sortitions, \
                          stacks_block_accepted, stacks_block_height, arrival_index, canonical_stacks_tip_height, canonical_stacks_tip_hash, canonical_stacks_tip_consensus_hash, sortition_id, parent_sortition_id, pox_valid, accumulated_coinbase_ustx, \
                          pox_payouts) \
                          VALUES (?1, ?2, ?3, ?4, ?5, ?6, ?7, ?8, ?9, ?10, ?11, ?12, ?13, ?14, ?15, ?16, ?17, ?18, ?19, ?20, ?21, ?22, ?23, ?24)", args)?;

            db_tx.store_transition_ops(
                &first_snapshot.sortition_id,
                &BurnchainStateTransition::noop(),
            )?;

            db_tx.commit()?;
            Ok(())
        }

        pub fn test_get_next_block_recipients(
            &mut self,
            burnchain: &Burnchain,
            next_pox_info: Option<&RewardCycleInfo>,
        ) -> Result<Option<RewardSetInfo>, BurnchainError> {
            let parent_snapshot = SortitionDB::get_canonical_burn_chain_tip(self.conn())?;
            self.get_next_block_recipients(burnchain, &parent_snapshot, next_pox_info)
        }

        pub fn set_canonical_stacks_chain_tip(
            conn: &Connection,
            ch: &ConsensusHash,
            bhh: &BlockHeaderHash,
            height: u64,
        ) -> Result<(), db_error> {
            let tip = SortitionDB::get_canonical_burn_chain_tip(conn)?;
            let args: &[&dyn ToSql] = &[ch, bhh, &u64_to_sql(height)?, &tip.sortition_id];
            conn.execute("UPDATE snapshots SET canonical_stacks_tip_consensus_hash = ?1, canonical_stacks_tip_hash = ?2, canonical_stacks_tip_height = ?3
                        WHERE sortition_id = ?4", args)
                .map_err(db_error::SqliteError)?;
            Ok(())
        }

        /// Given the last_tenure_id (e.g. in a block-commit in Nakamoto), find its sortition in the
        /// given sortition fork.
        pub fn get_block_snapshot_for_winning_nakamoto_tenure(
            ic: &SortitionDBConn,
            tip: &SortitionId,
            last_tenure_id: &StacksBlockId,
        ) -> Result<Option<BlockSnapshot>, db_error> {
            let block_hash = BlockHeaderHash(last_tenure_id.0.clone());
            Self::get_block_snapshot_for_winning_stacks_block(ic, tip, &block_hash)
        }

        /// Get a blockstack burnchain operation by txid
        pub fn get_burnchain_transaction(
            conn: &Connection,
            txid: &Txid,
        ) -> Result<Option<BlockstackOperationType>, db_error> {
            // leader key?
            let leader_key_sql = "SELECT * FROM leader_keys WHERE txid = ?1 LIMIT 1";
            let args = [&txid];

            let leader_key_res = query_row_panic(conn, &leader_key_sql, &args, || {
                "Multiple leader keys with same txid".to_string()
            })?;
            if let Some(leader_key) = leader_key_res {
                return Ok(Some(BlockstackOperationType::LeaderKeyRegister(leader_key)));
            }

            // block commit?
            let block_commit_sql = "SELECT * FROM block_commits WHERE txid = ?1 LIMIT 1";

            let block_commit_res = query_row_panic(conn, &block_commit_sql, &args, || {
                "Multiple block commits with same txid".to_string()
            })?;
            if let Some(block_commit) = block_commit_res {
                return Ok(Some(BlockstackOperationType::LeaderBlockCommit(
                    block_commit,
                )));
            }

            Ok(None)
        }

        /// Load up all stacks chain tips, in ascending order by block height.  Great for testing!
        pub fn get_all_stacks_chain_tips(
            &self,
        ) -> Result<Vec<(SortitionId, ConsensusHash, BlockHeaderHash, u64)>, db_error> {
            let sql = "SELECT * FROM stacks_chain_tips ORDER BY block_height ASC";
            let mut stmt = self.conn().prepare(sql)?;
            let mut qry = stmt.query(NO_PARAMS)?;
            let mut ret = vec![];
            while let Some(row) = qry.next()? {
                let sort_id: SortitionId = row.get("sortition_id")?;
                let consensus_hash: ConsensusHash = row.get("consensus_hash")?;
                let block_hash: BlockHeaderHash = row.get("block_hash")?;
                let block_height_i64: i64 = row.get("block_height")?;
                let block_height =
                    u64::try_from(block_height_i64).map_err(|_| db_error::ParseError)?;
                ret.push((sort_id, consensus_hash, block_hash, block_height));
            }
            Ok(ret)
        }

        /// Get the last block-commit from a given sender
        pub fn get_last_block_commit_by_sender(
            conn: &DBConn,
            sender: &BurnchainSigner,
        ) -> Result<Option<LeaderBlockCommitOp>, db_error> {
            let apparent_sender_str =
                serde_json::to_string(sender).map_err(|e| db_error::SerializationError(e))?;
            let sql = "SELECT * FROM block_commits WHERE apparent_sender = ?1 ORDER BY block_height DESC LIMIT 1";
            let args = rusqlite::params![&apparent_sender_str];
            query_row(conn, sql, args)
        }
    }

    #[test]
    fn test_instantiate() {
        let first_burn_hash = BurnchainHeaderHash::from_hex(
            "0000000000000000000000000000000000000000000000000000000000000000",
        )
        .unwrap();
        let _db = SortitionDB::connect_test(123, &first_burn_hash).unwrap();
    }

    #[test]
    fn test_v1_to_v2_migration() {
        let mut rng = rand::thread_rng();
        let mut buf = [0u8; 32];
        rng.fill_bytes(&mut buf);
        let db_path_dir = format!(
            "/tmp/stacks-node-tests/unit-tests-sortdb/db-{}",
            to_hex(&buf)
        );

        let first_block_height = 123;
        let first_burn_hash = BurnchainHeaderHash::from_hex(
            "0000000000000000000000000000000000000000000000000000000000000000",
        )
        .unwrap();

        // create a v1 sortition DB
        let db = SortitionDB::connect_v1(
            &db_path_dir,
            first_block_height,
            &first_burn_hash,
            get_epoch_time_secs(),
            true,
        )
        .unwrap();
        let res = SortitionDB::get_stacks_epoch(db.conn(), first_block_height);
        assert!(res.is_err());
        assert!(format!("{:?}", res).contains("no such table: epochs"));

        assert!(SortitionDB::open(&db_path_dir, true, PoxConstants::test_default()).is_err());

        // create a v2 sortition DB at the same path as the v1 DB.
        // the schema migration should be successfully applied, and the epochs table should exist.
        let db = SortitionDB::connect(
            &db_path_dir,
            first_block_height,
            &first_burn_hash,
            get_epoch_time_secs(),
            &StacksEpoch::unit_test_2_05(first_block_height),
            PoxConstants::test_default(),
            None,
            true,
        )
        .unwrap();
        // assert that an epoch is returned
        SortitionDB::get_stacks_epoch(db.conn(), first_block_height)
            .expect("Database should not error querying epochs")
            .expect("Database should have an epoch entry");

        assert!(SortitionDB::open(&db_path_dir, true, PoxConstants::test_default()).is_ok());
    }

    #[test]
    fn test_tx_begin_end() {
        let first_burn_hash = BurnchainHeaderHash::from_hex(
            "0000000000000000000000000000000000000000000000000000000000000000",
        )
        .unwrap();
        let mut db = SortitionDB::connect_test(123, &first_burn_hash).unwrap();
        let tx = db.tx_begin().unwrap();
        tx.commit().unwrap();
    }

    pub fn test_append_snapshot_with_winner(
        db: &mut SortitionDB,
        next_hash: BurnchainHeaderHash,
        block_ops: &Vec<BlockstackOperationType>,
        parent_sn: Option<BlockSnapshot>,
        winning_block_commit: Option<LeaderBlockCommitOp>,
    ) -> BlockSnapshot {
        let mut sn = match parent_sn {
            Some(sn) => sn,
            None => SortitionDB::get_canonical_burn_chain_tip(db.conn()).unwrap(),
        };

        let mut tx = SortitionHandleTx::begin(db, &sn.sortition_id).unwrap();

        let sn_parent = sn.clone();
        sn.parent_burn_header_hash = sn.burn_header_hash.clone();
        sn.parent_sortition_id = sn.sortition_id.clone();
        sn.burn_header_hash = next_hash;
        sn.block_height += 1;
        sn.num_sortitions += 1;
        sn.sortition_id = SortitionId::stubbed(&sn.burn_header_hash);
        sn.consensus_hash = ConsensusHash(Hash160::from_data(&sn.consensus_hash.0).0);

        if let Some(cmt) = winning_block_commit {
            sn.sortition = true;
            sn.winning_stacks_block_hash = cmt.block_header_hash;
            sn.winning_block_txid = cmt.txid;
        }

        let index_root = tx
            .append_chain_tip_snapshot(&sn_parent, &sn, block_ops, &vec![], None, None, None)
            .unwrap();
        sn.index_root = index_root;

        tx.commit().unwrap();

        sn
    }

    pub fn test_append_snapshot(
        db: &mut SortitionDB,
        next_hash: BurnchainHeaderHash,
        block_ops: &Vec<BlockstackOperationType>,
    ) -> BlockSnapshot {
        test_append_snapshot_with_winner(db, next_hash, block_ops, None, None)
    }

    #[test]
    fn test_insert_leader_key() {
        let block_height = 123;
        let vtxindex = 456;
        let first_burn_hash = BurnchainHeaderHash::from_hex(
            "0000000000000000000000000000000000000000000000000000000000000000",
        )
        .unwrap();

        let leader_key = LeaderKeyRegisterOp {
            consensus_hash: ConsensusHash::from_bytes(
                &hex_bytes("2222222222222222222222222222222222222222").unwrap(),
            )
            .unwrap(),
            public_key: VRFPublicKey::from_bytes(
                &hex_bytes("a366b51292bef4edd64063d9145c617fec373bceb0758e98cd72becd84d54c7a")
                    .unwrap(),
            )
            .unwrap(),
            memo: vec![01, 02, 03, 04, 05],

            txid: Txid::from_bytes_be(
                &hex_bytes("1bfa831b5fc56c858198acb8e77e5863c1e9d8ac26d49ddb914e24d8d4083562")
                    .unwrap(),
            )
            .unwrap(),
            vtxindex: vtxindex,
            block_height: block_height + 1,
            burn_header_hash: BurnchainHeaderHash([0x01; 32]),
        };

        let mut db = SortitionDB::connect_test(block_height, &first_burn_hash).unwrap();

        let snapshot = test_append_snapshot(
            &mut db,
            BurnchainHeaderHash([0x01; 32]),
            &vec![BlockstackOperationType::LeaderKeyRegister(
                leader_key.clone(),
            )],
        );

        {
            let ic = db.index_conn();
            let leader_key_opt = SortitionDB::get_leader_key_at(
                &ic,
                block_height + 1,
                vtxindex,
                &snapshot.sortition_id,
            )
            .unwrap();
            assert!(leader_key_opt.is_some());
            assert_eq!(leader_key_opt.unwrap(), leader_key);
        }

        let new_snapshot = test_append_snapshot(&mut db, BurnchainHeaderHash([0x02; 32]), &vec![]);

        {
            let ic = db.index_conn();
            let leader_key_opt = SortitionDB::get_leader_key_at(
                &ic,
                block_height + 1,
                vtxindex,
                &new_snapshot.sortition_id,
            )
            .unwrap();
            assert!(leader_key_opt.is_some());
            assert_eq!(leader_key_opt.unwrap(), leader_key);

            let leader_key_none = SortitionDB::get_leader_key_at(
                &ic,
                block_height + 1,
                vtxindex + 1,
                &new_snapshot.sortition_id,
            )
            .unwrap();
            assert!(leader_key_none.is_none());
        }
    }

    #[test]
    fn test_insert_block_commit() {
        let block_height = 123;
        let vtxindex = 456;
        let first_burn_hash = BurnchainHeaderHash::from_hex(
            "0000000000000000000000000000000000000000000000000000000000000000",
        )
        .unwrap();

        let leader_key = LeaderKeyRegisterOp {
            consensus_hash: ConsensusHash::from_bytes(
                &hex_bytes("2222222222222222222222222222222222222222").unwrap(),
            )
            .unwrap(),
            public_key: VRFPublicKey::from_bytes(
                &hex_bytes("a366b51292bef4edd64063d9145c617fec373bceb0758e98cd72becd84d54c7a")
                    .unwrap(),
            )
            .unwrap(),
            memo: vec![01, 02, 03, 04, 05],

            txid: Txid::from_bytes_be(
                &hex_bytes("1bfa831b5fc56c858198acb8e77e5863c1e9d8ac26d49ddb914e24d8d4083562")
                    .unwrap(),
            )
            .unwrap(),
            vtxindex: vtxindex,
            block_height: block_height + 1,
            burn_header_hash: BurnchainHeaderHash([0x01; 32]),
        };

        let block_commit = LeaderBlockCommitOp {
            sunset_burn: 0,
            block_header_hash: BlockHeaderHash::from_bytes(
                &hex_bytes("2222222222222222222222222222222222222222222222222222222222222222")
                    .unwrap(),
            )
            .unwrap(),
            new_seed: VRFSeed::from_bytes(
                &hex_bytes("3333333333333333333333333333333333333333333333333333333333333333")
                    .unwrap(),
            )
            .unwrap(),
            parent_block_ptr: 0x43424140,
            parent_vtxindex: 0x5150,
            key_block_ptr: (block_height + 1) as u32,
            key_vtxindex: vtxindex as u16,
            memo: vec![0x80],

            commit_outs: vec![],
            burn_fee: 12345,
            input: (Txid([0; 32]), 0),
            apparent_sender: BurnchainSigner::mock_parts(
                AddressHashMode::SerializeP2PKH,
                1,
                vec![StacksPublicKey::from_hex(
                    "02d8015134d9db8178ac93acbc43170a2f20febba5087a5b0437058765ad5133d0",
                )
                .unwrap()],
            ),

            txid: Txid::from_bytes_be(
                &hex_bytes("3c07a0a93360bc85047bbaadd49e30c8af770f73a37e10fec400174d2e5f27cf")
                    .unwrap(),
            )
            .unwrap(),
            vtxindex: vtxindex,
            block_height: block_height + 2,
            burn_parent_modulus: ((block_height + 1) % BURN_BLOCK_MINED_AT_MODULUS) as u8,
            burn_header_hash: BurnchainHeaderHash([0x03; 32]),
        };

        let mut db = SortitionDB::connect_test(block_height, &first_burn_hash).unwrap();

        let snapshot = test_append_snapshot(
            &mut db,
            BurnchainHeaderHash([0x01; 32]),
            &vec![BlockstackOperationType::LeaderKeyRegister(
                leader_key.clone(),
            )],
        );

        // test get_consumed_leader_keys()
        {
            let mut ic = SortitionHandleTx::begin(&mut db, &snapshot.sortition_id).unwrap();
            let keys = ic
                .get_consumed_leader_keys(&snapshot, &vec![block_commit.clone()])
                .unwrap();
            assert_eq!(keys, vec![leader_key.clone()]);
        }

        let snapshot_consumed = test_append_snapshot(
            &mut db,
            BurnchainHeaderHash([0x03; 32]),
            &vec![BlockstackOperationType::LeaderBlockCommit(
                block_commit.clone(),
            )],
        );

        {
            let res_block_commits =
                SortitionDB::get_block_commits_by_block(db.conn(), &snapshot_consumed.sortition_id)
                    .unwrap();
            assert_eq!(res_block_commits.len(), 1);
            assert_eq!(res_block_commits[0], block_commit);
        }

        // advance and get parent
        let empty_snapshot =
            test_append_snapshot(&mut db, BurnchainHeaderHash([0x05; 32]), &vec![]);

        // test get_block_commit_parent()
        {
            let ic = db.index_conn();
            let parent = SortitionDB::get_block_commit_parent(
                &ic,
                block_height + 2,
                block_commit.vtxindex,
                &empty_snapshot.sortition_id,
            )
            .unwrap();
            assert!(parent.is_some());
            assert_eq!(parent.unwrap(), block_commit);

            let parent = SortitionDB::get_block_commit_parent(
                &ic,
                block_height + 3,
                block_commit.vtxindex,
                &empty_snapshot.sortition_id,
            )
            .unwrap();
            assert!(parent.is_none());

            let parent = SortitionDB::get_block_commit_parent(
                &ic,
                block_height + 2,
                block_commit.vtxindex + 1,
                &empty_snapshot.sortition_id,
            )
            .unwrap();
            assert!(parent.is_none());
        }

        // test get_block_commit()
        {
            let handle = db.index_handle(&empty_snapshot.sortition_id);
            let commit = handle
                .get_block_commit_by_txid(&snapshot_consumed.sortition_id, &block_commit.txid)
                .unwrap();
            assert!(commit.is_some());
            assert_eq!(commit.unwrap(), block_commit);

            let bad_txid = Txid::from_bytes_be(
                &hex_bytes("4c07a0a93360bc85047bbaadd49e30c8af770f73a37e10fec400174d2e5f27cf")
                    .unwrap(),
            )
            .unwrap();
            let commit = handle
                .get_block_commit_by_txid(&snapshot_consumed.sortition_id, &bad_txid)
                .unwrap();
            assert!(commit.is_none());
        }

        // sortition ID is memoized, or absent
        {
            assert_eq!(
                SortitionDB::get_block_commit_parent_sortition_id(
                    db.conn(),
                    &block_commit.txid,
                    &snapshot_consumed.sortition_id
                )
                .unwrap(),
                Some(SortitionId([0x00; 32]))
            );
        }

        // test get_consumed_leader_keys() (should be doable at any subsequent index root)
        {
            let mut ic = SortitionHandleTx::begin(&mut db, &snapshot.sortition_id).unwrap();
            let keys = ic
                .get_consumed_leader_keys(&empty_snapshot, &vec![block_commit.clone()])
                .unwrap();
            assert_eq!(keys, vec![leader_key.clone()]);
        }

        // make a fork between the leader key and block commit, and verify that the key is
        // unconsumed
        let fork_snapshot = {
            let mut sn = SortitionDB::get_block_snapshot(db.conn(), &snapshot.sortition_id)
                .unwrap()
                .unwrap();
            let next_hash = BurnchainHeaderHash([0x13; 32]);
            let mut tx = SortitionHandleTx::begin(&mut db, &sn.sortition_id).unwrap();

            let sn_parent = sn.clone();
            sn.parent_burn_header_hash = sn.burn_header_hash.clone();
            sn.sortition_id = SortitionId(next_hash.0.clone());
            sn.parent_sortition_id = sn_parent.sortition_id.clone();
            sn.burn_header_hash = next_hash;
            sn.block_height += 1;
            sn.num_sortitions += 1;
            sn.consensus_hash = ConsensusHash([0x23; 20]);

            let index_root = tx
                .append_chain_tip_snapshot(&sn_parent, &sn, &vec![], &vec![], None, None, None)
                .unwrap();
            sn.index_root = index_root;

            tx.commit().unwrap();

            sn
        };

        // test get_consumed_leader_keys() and is_leader_key_consumed() against this new fork
        {
            let mut ic = SortitionHandleTx::begin(&mut db, &snapshot.sortition_id).unwrap();
            let keys = ic
                .get_consumed_leader_keys(&fork_snapshot, &vec![block_commit.clone()])
                .unwrap();
            assert_eq!(keys, vec![leader_key.clone()]);
        }
    }

    #[test]
    fn has_VRF_public_key() {
        let public_key = VRFPublicKey::from_bytes(
            &hex_bytes("a366b51292bef4edd64063d9145c617fec373bceb0758e98cd72becd84d54c7a").unwrap(),
        )
        .unwrap();
        let block_height = 123;
        let vtxindex = 456;
        let first_burn_hash = BurnchainHeaderHash::from_hex(
            "0000000000000000000000000000000000000000000000000000000000000000",
        )
        .unwrap();

        let leader_key = LeaderKeyRegisterOp {
            consensus_hash: ConsensusHash::from_bytes(
                &hex_bytes("2222222222222222222222222222222222222222").unwrap(),
            )
            .unwrap(),
            public_key: public_key.clone(),
            memo: vec![01, 02, 03, 04, 05],

            txid: Txid::from_bytes_be(
                &hex_bytes("1bfa831b5fc56c858198acb8e77e5863c1e9d8ac26d49ddb914e24d8d4083562")
                    .unwrap(),
            )
            .unwrap(),
            vtxindex: vtxindex,
            block_height: block_height + 2,
            burn_header_hash: BurnchainHeaderHash([0x03; 32]),
        };

        let mut db = SortitionDB::connect_test(block_height, &first_burn_hash).unwrap();

        let no_key_snapshot =
            test_append_snapshot(&mut db, BurnchainHeaderHash([0x01; 32]), &vec![]);

        let has_key_before = {
            let mut ic = SortitionHandleTx::begin(&mut db, &no_key_snapshot.sortition_id).unwrap();
            ic.has_VRF_public_key(&public_key).unwrap()
        };

        assert!(!has_key_before);

        let key_snapshot = test_append_snapshot(
            &mut db,
            BurnchainHeaderHash([0x03; 32]),
            &vec![BlockstackOperationType::LeaderKeyRegister(
                leader_key.clone(),
            )],
        );

        let has_key_after = {
            let mut ic = SortitionHandleTx::begin(&mut db, &key_snapshot.sortition_id).unwrap();
            ic.has_VRF_public_key(&public_key).unwrap()
        };

        assert!(has_key_after);
    }

    #[test]
    fn is_fresh_consensus_hash() {
        let consensus_hash_lifetime = 24;
        let first_burn_hash = BurnchainHeaderHash::from_hex(
            "10000000000000000000000000000000000000000000000000000000000000ff",
        )
        .unwrap();
        let mut db = SortitionDB::connect_test(0, &first_burn_hash).unwrap();
        {
            let mut last_snapshot = SortitionDB::get_first_block_snapshot(db.conn()).unwrap();
            for i in 0..255 {
                let sortition_id = SortitionId([
                    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
                    0, 0, 0, 0, 0, i as u8,
                ]);
                let parent_sortition_id = if i == 0 {
                    last_snapshot.sortition_id.clone()
                } else {
                    SortitionId([
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        i - 1 as u8,
                    ])
                };

                let mut tx = SortitionHandleTx::begin(&mut db, &parent_sortition_id).unwrap();
                let snapshot_row = BlockSnapshot {
                    accumulated_coinbase_ustx: 0,
                    pox_valid: true,
                    block_height: i as u64 + 1,
                    burn_header_timestamp: get_epoch_time_secs(),
                    burn_header_hash: BurnchainHeaderHash::from_bytes(&[
                        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
                        0, 0, 0, 0, 0, 0, i as u8,
                    ])
                    .unwrap(),
                    sortition_id,
                    parent_sortition_id,
                    parent_burn_header_hash: BurnchainHeaderHash::from_bytes(&[
                        (if i == 0 { 0x10 } else { 0 }) as u8,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        (if i == 0 { 0xff } else { i - 1 }) as u8,
                    ])
                    .unwrap(),
                    consensus_hash: ConsensusHash::from_bytes(&[
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        (i + 1) as u8,
                    ])
                    .unwrap(),
                    ops_hash: OpsHash::from_bytes(&[
                        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
                        0, 0, 0, 0, 0, 0, i as u8,
                    ])
                    .unwrap(),
                    total_burn: i as u64,
                    sortition: true,
                    sortition_hash: SortitionHash::initial(),
                    winning_block_txid: Txid::from_hex(
                        "0000000000000000000000000000000000000000000000000000000000000000",
                    )
                    .unwrap(),
                    winning_stacks_block_hash: BlockHeaderHash::from_hex(
                        "0000000000000000000000000000000000000000000000000000000000000000",
                    )
                    .unwrap(),
                    index_root: TrieHash::from_empty_data(),
                    num_sortitions: i as u64 + 1,
                    stacks_block_accepted: false,
                    stacks_block_height: 0,
                    arrival_index: 0,
                    canonical_stacks_tip_height: 0,
                    canonical_stacks_tip_hash: BlockHeaderHash([0u8; 32]),
                    canonical_stacks_tip_consensus_hash: ConsensusHash([0u8; 20]),
                    miner_pk_hash: None,
                };
                let index_root = tx
                    .append_chain_tip_snapshot(
                        &last_snapshot,
                        &snapshot_row,
                        &vec![],
                        &vec![],
                        None,
                        None,
                        None,
                    )
                    .unwrap();
                last_snapshot = snapshot_row;
                last_snapshot.index_root = index_root;
                tx.commit().unwrap();
            }
        }

        let tip = SortitionDB::get_canonical_burn_chain_tip(db.conn()).unwrap();

        let ch_fresh = ConsensusHash::from_bytes(&[
            0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 255,
        ])
        .unwrap();
        let ch_oldest_fresh = ConsensusHash::from_bytes(&[
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            (255 - consensus_hash_lifetime) as u8,
        ])
        .unwrap();
        let ch_newest_stale = ConsensusHash::from_bytes(&[
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            (255 - consensus_hash_lifetime - 1) as u8,
        ])
        .unwrap();
        let ch_missing = ConsensusHash::from_bytes(&[
            0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 255,
        ])
        .unwrap();

        let mut ic = SortitionHandleTx::begin(&mut db, &tip.sortition_id).unwrap();
        let fresh_check = ic
            .is_fresh_consensus_hash(consensus_hash_lifetime, &ch_fresh)
            .unwrap();

        assert!(fresh_check);

        let oldest_fresh_check = ic
            .is_fresh_consensus_hash(consensus_hash_lifetime, &ch_oldest_fresh)
            .unwrap();

        assert!(oldest_fresh_check);

        let newest_stale_check = ic
            .is_fresh_consensus_hash(consensus_hash_lifetime, &ch_newest_stale)
            .unwrap();

        assert!(!newest_stale_check);

        let missing_check = ic
            .is_fresh_consensus_hash(consensus_hash_lifetime, &ch_missing)
            .unwrap();

        assert!(!missing_check);
    }

    #[test]
    fn get_consensus_at() {
        let first_burn_hash = BurnchainHeaderHash::from_hex(
            "10000000000000000000000000000000000000000000000000000000000000ff",
        )
        .unwrap();
        let mut db = SortitionDB::connect_test(0, &first_burn_hash).unwrap();
        {
            let mut last_snapshot = SortitionDB::get_first_block_snapshot(db.conn()).unwrap();
            for i in 0..256u64 {
                let sortition_id = SortitionId([
                    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
                    0, 0, 0, 0, 0, i as u8,
                ]);
                let parent_sortition_id = if i == 0 {
                    last_snapshot.sortition_id.clone()
                } else {
                    SortitionId([
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        (i - 1) as u8,
                    ])
                };

                let mut tx = SortitionHandleTx::begin(&mut db, &parent_sortition_id).unwrap();
                let snapshot_row = BlockSnapshot {
                    accumulated_coinbase_ustx: 0,
                    pox_valid: true,
                    block_height: i as u64 + 1,
                    burn_header_timestamp: get_epoch_time_secs(),
                    burn_header_hash: BurnchainHeaderHash::from_bytes(&[
                        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
                        0, 0, 0, 0, 0, 0, i as u8,
                    ])
                    .unwrap(),
                    sortition_id,
                    parent_sortition_id,
                    parent_burn_header_hash: BurnchainHeaderHash::from_bytes(&[
                        (if i == 0 { 0x10 } else { 0 }) as u8,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        (if i == 0 { 0xff } else { i - 1 }) as u8,
                    ])
                    .unwrap(),
                    consensus_hash: ConsensusHash::from_bytes(&[
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        ((i + 1) / 256) as u8,
                        (i + 1) as u8,
                    ])
                    .unwrap(),
                    ops_hash: OpsHash::from_bytes(&[
                        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
                        0, 0, 0, 0, 0, 0, i as u8,
                    ])
                    .unwrap(),
                    total_burn: i as u64,
                    sortition: true,
                    sortition_hash: SortitionHash::initial(),
                    winning_block_txid: Txid::from_hex(
                        "0000000000000000000000000000000000000000000000000000000000000000",
                    )
                    .unwrap(),
                    winning_stacks_block_hash: BlockHeaderHash::from_hex(
                        "0000000000000000000000000000000000000000000000000000000000000000",
                    )
                    .unwrap(),
                    index_root: TrieHash::from_empty_data(),
                    num_sortitions: i as u64 + 1,
                    stacks_block_accepted: false,
                    stacks_block_height: 0,
                    arrival_index: 0,
                    canonical_stacks_tip_height: 0,
                    canonical_stacks_tip_hash: BlockHeaderHash([0u8; 32]),
                    canonical_stacks_tip_consensus_hash: ConsensusHash([0u8; 20]),
                    miner_pk_hash: None,
                };
                let index_root = tx
                    .append_chain_tip_snapshot(
                        &last_snapshot,
                        &snapshot_row,
                        &vec![],
                        &vec![],
                        None,
                        None,
                        None,
                    )
                    .unwrap();
                last_snapshot = snapshot_row;
                last_snapshot.index_root = index_root;
                // should succeed within the tx
                let ch = tx.get_consensus_at(i as u64 + 1).unwrap().unwrap();
                assert_eq!(ch, last_snapshot.consensus_hash);

                tx.commit().unwrap();
            }
        }

        let tip = SortitionDB::get_canonical_burn_chain_tip(db.conn()).unwrap();

        for i in 0..256 {
            // should succeed within the conn
            let ic = db.index_handle(&tip.sortition_id);
            let expected_ch = ConsensusHash::from_bytes(&[
                0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, i as u8,
            ])
            .unwrap();
            let ch = ic.get_consensus_at(i).unwrap().unwrap();
            assert_eq!(ch, expected_ch);
        }
    }

    #[test]
    fn get_block_burn_amount() {
        let block_height = 123;
        let vtxindex = 456;
        let first_burn_hash = BurnchainHeaderHash::from_hex(
            "0000000000000000000000000000000000000000000000000000000000000000",
        )
        .unwrap();

        let leader_key = LeaderKeyRegisterOp {
            consensus_hash: ConsensusHash::from_bytes(
                &hex_bytes("2222222222222222222222222222222222222222").unwrap(),
            )
            .unwrap(),
            public_key: VRFPublicKey::from_bytes(
                &hex_bytes("a366b51292bef4edd64063d9145c617fec373bceb0758e98cd72becd84d54c7a")
                    .unwrap(),
            )
            .unwrap(),
            memo: vec![01, 02, 03, 04, 05],

            txid: Txid::from_bytes_be(
                &hex_bytes("1bfa831b5fc56c858198acb8e77e5863c1e9d8ac26d49ddb914e24d8d4083562")
                    .unwrap(),
            )
            .unwrap(),
            vtxindex: vtxindex,
            block_height: block_height + 1,
            burn_header_hash: BurnchainHeaderHash([0x01; 32]),
        };

        let block_commit = LeaderBlockCommitOp {
            sunset_burn: 0,
            block_header_hash: BlockHeaderHash::from_bytes(
                &hex_bytes("2222222222222222222222222222222222222222222222222222222222222222")
                    .unwrap(),
            )
            .unwrap(),
            new_seed: VRFSeed::from_bytes(
                &hex_bytes("3333333333333333333333333333333333333333333333333333333333333333")
                    .unwrap(),
            )
            .unwrap(),
            parent_block_ptr: 0x43424140,
            parent_vtxindex: 0x4342,
            key_block_ptr: (block_height + 1) as u32,
            key_vtxindex: vtxindex as u16,
            memo: vec![0x80],
            commit_outs: vec![],

            burn_fee: 12345,
            input: (Txid([0; 32]), 0),
            apparent_sender: BurnchainSigner::mock_parts(
                AddressHashMode::SerializeP2PKH,
                1,
                vec![StacksPublicKey::from_hex(
                    "02d8015134d9db8178ac93acbc43170a2f20febba5087a5b0437058765ad5133d0",
                )
                .unwrap()],
            ),

            txid: Txid::from_bytes_be(
                &hex_bytes("3c07a0a93360bc85047bbaadd49e30c8af770f73a37e10fec400174d2e5f27cf")
                    .unwrap(),
            )
            .unwrap(),
            vtxindex: vtxindex,
            block_height: block_height + 2,
            burn_parent_modulus: ((block_height + 1) % BURN_BLOCK_MINED_AT_MODULUS) as u8,
            burn_header_hash: BurnchainHeaderHash([0x03; 32]),
        };

        let mut db = SortitionDB::connect_test(block_height, &first_burn_hash).unwrap();

        let key_snapshot = test_append_snapshot(
            &mut db,
            BurnchainHeaderHash([0x01; 32]),
            &vec![BlockstackOperationType::LeaderKeyRegister(
                leader_key.clone(),
            )],
        );

        let commit_snapshot = test_append_snapshot(
            &mut db,
            BurnchainHeaderHash([0x03; 32]),
            &vec![BlockstackOperationType::LeaderBlockCommit(
                block_commit.clone(),
            )],
        );

        {
            let burn_amt = SortitionDB::get_block_burn_amount(db.conn(), &commit_snapshot).unwrap();
            assert_eq!(burn_amt, block_commit.burn_fee);

            let no_burn_amt = SortitionDB::get_block_burn_amount(db.conn(), &key_snapshot).unwrap();
            assert_eq!(no_burn_amt, 0);
        }
    }

    #[test]
    fn get_last_snapshot_with_sortition() {
        let block_height = 123;
        let total_burn_sortition = 100;
        let total_burn_no_sortition = 200;
        let first_burn_hash = BurnchainHeaderHash::from_hex(
            "0000000000000000000000000000000000000000000000000000000000000000",
        )
        .unwrap();

        let mut first_snapshot = BlockSnapshot {
            accumulated_coinbase_ustx: 0,
            pox_valid: true,
            block_height: block_height - 2,
            burn_header_timestamp: get_epoch_time_secs(),
            burn_header_hash: first_burn_hash.clone(),
            sortition_id: SortitionId(first_burn_hash.0.clone()),
            parent_sortition_id: SortitionId(first_burn_hash.0.clone()),
            parent_burn_header_hash: BurnchainHeaderHash([0xff; 32]),
            consensus_hash: ConsensusHash::from_hex("0000000000000000000000000000000000000000")
                .unwrap(),
            ops_hash: OpsHash::from_hex(
                "0000000000000000000000000000000000000000000000000000000000000000",
            )
            .unwrap(),
            total_burn: 0,
            sortition: true,
            sortition_hash: SortitionHash::initial(),
            winning_block_txid: Txid::from_hex(
                "0000000000000000000000000000000000000000000000000000000000000000",
            )
            .unwrap(),
            winning_stacks_block_hash: BlockHeaderHash::from_hex(
                "0000000000000000000000000000000000000000000000000000000000000000",
            )
            .unwrap(),
            index_root: TrieHash([0u8; 32]),
            num_sortitions: 0,
            stacks_block_accepted: false,
            stacks_block_height: 0,
            arrival_index: 0,
            canonical_stacks_tip_height: 0,
            canonical_stacks_tip_hash: BlockHeaderHash([0u8; 32]),
            canonical_stacks_tip_consensus_hash: ConsensusHash([0u8; 20]),
            miner_pk_hash: None,
        };

        let mut snapshot_with_sortition = BlockSnapshot {
            accumulated_coinbase_ustx: 0,
            pox_valid: true,
            block_height: block_height,
            burn_header_timestamp: get_epoch_time_secs(),
            burn_header_hash: BurnchainHeaderHash::from_bytes(&[
                0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
                0, 0, 0, 2,
            ])
            .unwrap(),
            sortition_id: SortitionId([
                0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
                0, 0, 0, 2,
            ]),
            parent_sortition_id: SortitionId([
                0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
                0, 0, 0, 1,
            ]),
            parent_burn_header_hash: BurnchainHeaderHash::from_bytes(&[
                0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
                0, 0, 0, 1,
            ])
            .unwrap(),
            consensus_hash: ConsensusHash::from_bytes(&[
                0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,
            ])
            .unwrap(),
            ops_hash: OpsHash::from_bytes(&[
                0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
                0, 0, 0, 1,
            ])
            .unwrap(),
            total_burn: total_burn_sortition,
            sortition: true,
            sortition_hash: SortitionHash::initial(),
            winning_block_txid: Txid::from_hex(
                "0000000000000000000000000000000000000000000000000000000000000001",
            )
            .unwrap(),
            winning_stacks_block_hash: BlockHeaderHash::from_hex(
                "0000000000000000000000000000000000000000000000000000000000000001",
            )
            .unwrap(),
            index_root: TrieHash([1u8; 32]),
            num_sortitions: 1,
            stacks_block_accepted: false,
            stacks_block_height: 0,
            arrival_index: 0,
            canonical_stacks_tip_height: 0,
            canonical_stacks_tip_hash: BlockHeaderHash([0u8; 32]),
            canonical_stacks_tip_consensus_hash: ConsensusHash([0u8; 20]),
            miner_pk_hash: None,
        };

        let snapshot_without_sortition = BlockSnapshot {
            accumulated_coinbase_ustx: 0,
            pox_valid: true,
            block_height: block_height - 1,
            burn_header_timestamp: get_epoch_time_secs(),
            burn_header_hash: BurnchainHeaderHash::from_bytes(&[
                0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
                0, 0, 0, 1,
            ])
            .unwrap(),
            sortition_id: SortitionId([
                0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
                0, 0, 0, 1,
            ]),
            parent_sortition_id: SortitionId([
                0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
                0, 0, 0, 0,
            ]),
            parent_burn_header_hash: BurnchainHeaderHash::from_bytes(&[
                0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
                0, 0, 0, 0,
            ])
            .unwrap(),
            consensus_hash: ConsensusHash::from_bytes(&[
                0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2,
            ])
            .unwrap(),
            ops_hash: OpsHash::from_bytes(&[
                0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
                0, 0, 0, 2,
            ])
            .unwrap(),
            total_burn: total_burn_no_sortition,
            sortition: false,
            sortition_hash: SortitionHash::initial(),
            winning_block_txid: Txid::from_hex(
                "0000000000000000000000000000000000000000000000000000000000000002",
            )
            .unwrap(),
            winning_stacks_block_hash: BlockHeaderHash::from_hex(
                "0000000000000000000000000000000000000000000000000000000000000002",
            )
            .unwrap(),
            index_root: TrieHash([2u8; 32]),
            num_sortitions: 0,
            stacks_block_accepted: false,
            stacks_block_height: 0,
            arrival_index: 0,
            canonical_stacks_tip_height: 0,
            canonical_stacks_tip_hash: BlockHeaderHash([0u8; 32]),
            canonical_stacks_tip_consensus_hash: ConsensusHash([0u8; 20]),
            miner_pk_hash: None,
        };

        let mut db = SortitionDB::connect_test(block_height - 2, &first_burn_hash).unwrap();

        let chain_tip = SortitionDB::get_canonical_burn_chain_tip(db.conn()).unwrap();

        let initial_snapshot = {
            let ic = db.index_handle(&chain_tip.sortition_id);
            ic.get_last_snapshot_with_sortition(block_height - 2)
                .unwrap()
        };

        first_snapshot.index_root = initial_snapshot.index_root.clone();
        first_snapshot.burn_header_timestamp = initial_snapshot.burn_header_timestamp;
        assert_eq!(initial_snapshot, first_snapshot);

        {
            let chain_tip = SortitionDB::get_canonical_burn_chain_tip(db.conn()).unwrap();
            let mut tx = SortitionHandleTx::begin(&mut db, &chain_tip.sortition_id).unwrap();

            tx.append_chain_tip_snapshot(
                &chain_tip,
                &snapshot_without_sortition,
                &vec![],
                &vec![],
                None,
                None,
                None,
            )
            .unwrap();
            tx.commit().unwrap();
        }

        let chain_tip = SortitionDB::get_canonical_burn_chain_tip(db.conn()).unwrap();

        let mut next_snapshot = {
            let ic = db.index_handle(&chain_tip.sortition_id);
            ic.get_last_snapshot_with_sortition(block_height - 1)
                .unwrap()
        };

        next_snapshot.index_root = initial_snapshot.index_root.clone();
        next_snapshot.burn_header_timestamp = initial_snapshot.burn_header_timestamp;
        assert_eq!(initial_snapshot, next_snapshot);

        {
            let chain_tip = SortitionDB::get_canonical_burn_chain_tip(db.conn()).unwrap();
            let mut tx = SortitionHandleTx::begin(&mut db, &chain_tip.sortition_id).unwrap();

            tx.append_chain_tip_snapshot(
                &chain_tip,
                &snapshot_with_sortition,
                &vec![],
                &vec![],
                None,
                None,
                None,
            )
            .unwrap();
            tx.commit().unwrap();
        }

        let chain_tip = SortitionDB::get_canonical_burn_chain_tip(db.conn()).unwrap();

        let next_snapshot_2 = {
            let ic = db.index_handle(&chain_tip.sortition_id);
            ic.get_last_snapshot_with_sortition(block_height).unwrap()
        };

        snapshot_with_sortition.index_root = next_snapshot_2.index_root.clone();
        snapshot_with_sortition.burn_header_timestamp = next_snapshot_2.burn_header_timestamp;
        assert_eq!(snapshot_with_sortition, next_snapshot_2);
    }

    /// Verify that the snapshots in a fork are well-formed -- i.e. the block heights are
    /// sequential and the parent block hash of the ith block is equal to the block hash of the
    /// (i-1)th block.
    fn verify_fork_integrity(db: &mut SortitionDB, tip: &SortitionId) {
        let mut child = SortitionDB::get_block_snapshot(db.conn(), tip)
            .unwrap()
            .unwrap();

        let initial = SortitionDB::get_first_block_snapshot(db.conn()).unwrap();

        test_debug!(
            "Verify from {},hash={},parent={} back to {},hash={},parent={}",
            child.block_height,
            child.burn_header_hash,
            child.parent_burn_header_hash,
            initial.block_height,
            initial.burn_header_hash,
            initial.parent_burn_header_hash
        );

        while child.block_height > initial.block_height {
            let parent = {
                let ic = db.index_conn();
                SortitionDB::get_ancestor_snapshot(&ic, child.block_height - 1, &child.sortition_id)
                    .unwrap()
                    .unwrap()
            };

            test_debug!(
                "Verify {} == {} - 1 and hash={},parent_hash={} == parent={}",
                parent.block_height,
                child.block_height,
                child.burn_header_hash,
                parent.burn_header_hash,
                child.parent_burn_header_hash
            );

            assert_eq!(parent.block_height, child.block_height - 1);
            assert_eq!(parent.burn_header_hash, child.parent_burn_header_hash);

            child = parent.clone();
        }

        assert_eq!(child, initial);
    }

    #[test]
    fn test_chain_reorg() {
        // Create a set of forks that looks like this:
        // 0-1-2-3-4-5-6-7-8-9 (fork 0)
        //  \
        //   1-2-3-4-5-6-7-8-9 (fork 1)
        //    \
        //     2-3-4-5-6-7-8-9 (fork 2)
        //      \
        //       3-4-5-6-7-8-9 (fork 3)
        //
        //    ...etc...
        //
        // Then, append a block to fork 9, and confirm that it switches places with fork 0.
        // Append 2 blocks to fork 8, and confirm that it switches places with fork 0.
        // Append 3 blocks to fork 7, and confirm that it switches places with fork 0.
        // ... etc.
        //
        let first_burn_hash = BurnchainHeaderHash([0x00; 32]);
        let first_block_height = 100;

        let mut db = SortitionDB::connect_test(first_block_height, &first_burn_hash).unwrap();

        // make an initial fork
        let mut last_snapshot = SortitionDB::get_first_block_snapshot(db.conn()).unwrap();

        for i in 0..10 {
            let mut next_snapshot = last_snapshot.clone();

            next_snapshot.block_height += 1;
            next_snapshot.num_sortitions += 1;
            next_snapshot.parent_burn_header_hash = next_snapshot.burn_header_hash.clone();
            next_snapshot.burn_header_hash = BurnchainHeaderHash([
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                i + 1,
            ]);
            next_snapshot.sortition_id = SortitionId([
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                i + 1,
            ]);
            next_snapshot.parent_sortition_id = last_snapshot.sortition_id.clone();
            next_snapshot.consensus_hash = ConsensusHash([
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                i + 1,
            ]);

            let mut tx = SortitionHandleTx::begin(&mut db, &last_snapshot.sortition_id).unwrap();
            tx.append_chain_tip_snapshot(
                &last_snapshot,
                &next_snapshot,
                &vec![],
                &vec![],
                None,
                None,
                None,
            )
            .unwrap();
            tx.commit().unwrap();

            last_snapshot = next_snapshot.clone();
        }

        test_debug!("----- make forks -----");

        // make other forks
        for i in 0..9 {
            let parent_block_hash = if i == 0 {
                [0u8; 32]
            } else {
                let mut tmp = [
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    (i + 1) as u8,
                ];
                tmp[i - 1] = 1;
                tmp
            };

            let parent_block = SortitionId(parent_block_hash);
            test_debug!(
                "----- build fork off of parent {} (i = {}) -----",
                &parent_block,
                i
            );

            let mut last_snapshot = SortitionDB::get_block_snapshot(db.conn(), &parent_block)
                .unwrap()
                .unwrap();

            let initial_block_height = last_snapshot.block_height;
            let initial_num_sortitions = last_snapshot.num_sortitions;

            let mut next_snapshot = last_snapshot.clone();

            for j in (i + 1)..10 {
                let mut block_hash = [
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    (j + 1) as u8,
                ];
                block_hash[i] = (j - i) as u8;

                next_snapshot.block_height = initial_block_height + (j - i) as u64;
                next_snapshot.num_sortitions = initial_num_sortitions + (j - i) as u64;
                next_snapshot.parent_burn_header_hash = next_snapshot.burn_header_hash.clone();
                next_snapshot.sortition_id = SortitionId(block_hash.clone());
                next_snapshot.parent_sortition_id = last_snapshot.sortition_id.clone();
                next_snapshot.burn_header_hash = BurnchainHeaderHash(block_hash);
                next_snapshot.consensus_hash = ConsensusHash([
                    1,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    j as u8,
                    (i + 1) as u8,
                ]);

                let mut tx =
                    SortitionHandleTx::begin(&mut db, &last_snapshot.sortition_id).unwrap();
                let next_index_root = tx
                    .append_chain_tip_snapshot(
                        &last_snapshot,
                        &next_snapshot,
                        &vec![],
                        &vec![],
                        None,
                        None,
                        None,
                    )
                    .unwrap();
                tx.commit().unwrap();

                next_snapshot.index_root = next_index_root;
                last_snapshot = next_snapshot.clone();
            }

            test_debug!(
                "----- made fork {} (i = {}) -----",
                &next_snapshot.burn_header_hash,
                i
            );
        }

        test_debug!("----- grow forks -----");

        let mut all_chain_tips = vec![];

        // grow each fork so it overtakes the currently-canonical fork
        for i in 0..9 {
            let mut last_block_hash = [
                0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
                0, 0, 0, 10,
            ];
            last_block_hash[i] = (9 - i) as u8;
            let last_block = SortitionId(last_block_hash);

            test_debug!("----- grow fork {} (i = {}) -----", &last_block, i);

            let mut last_snapshot = SortitionDB::get_block_snapshot(db.conn(), &last_block)
                .unwrap()
                .unwrap();

            let initial_block_height = last_snapshot.block_height;
            let mut next_snapshot = last_snapshot.clone();

            // grow the fork up to the length of the previous fork
            for j in 0..((i + 1) as u64) {
                next_snapshot = last_snapshot.clone();

                let mut next_block_hash_vec = last_snapshot.burn_header_hash.as_bytes().to_vec();
                next_block_hash_vec[0] += 1;
                let mut next_block_hash = [0u8; 32];
                next_block_hash.copy_from_slice(&next_block_hash_vec[..]);

                next_snapshot.block_height = last_snapshot.block_height + 1;
                next_snapshot.num_sortitions = last_snapshot.num_sortitions + 1;
                next_snapshot.parent_burn_header_hash = last_snapshot.burn_header_hash.clone();
                next_snapshot.sortition_id = SortitionId(next_block_hash.clone());
                next_snapshot.parent_sortition_id = last_snapshot.sortition_id.clone();
                next_snapshot.burn_header_hash = BurnchainHeaderHash(next_block_hash);
                next_snapshot.consensus_hash = ConsensusHash([
                    2,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    j as u8,
                    (i + 1) as u8,
                ]);

                let next_index_root = {
                    let mut tx =
                        SortitionHandleTx::begin(&mut db, &last_snapshot.sortition_id).unwrap();
                    let next_index_root = tx
                        .append_chain_tip_snapshot(
                            &last_snapshot,
                            &next_snapshot,
                            &vec![],
                            &vec![],
                            None,
                            None,
                            None,
                        )
                        .unwrap();
                    tx.commit().unwrap();
                    next_index_root
                };

                last_snapshot =
                    SortitionDB::get_block_snapshot(db.conn(), &next_snapshot.sortition_id)
                        .unwrap()
                        .unwrap();
            }

            // make the fork exceed the canonical chain tip
            next_snapshot = last_snapshot.clone();

            let mut next_block_hash_vec = last_snapshot.burn_header_hash.as_bytes().to_vec();
            next_block_hash_vec[0] = 0xff;
            let mut next_block_hash = [0u8; 32];
            next_block_hash.copy_from_slice(&next_block_hash_vec[..]);

            next_snapshot.block_height += 1;
            next_snapshot.num_sortitions += 1;
            next_snapshot.parent_burn_header_hash = next_snapshot.burn_header_hash.clone();
            next_snapshot.sortition_id = SortitionId(next_block_hash.clone());
            next_snapshot.parent_sortition_id = last_snapshot.sortition_id.clone();
            next_snapshot.burn_header_hash = BurnchainHeaderHash(next_block_hash);
            next_snapshot.consensus_hash =
                ConsensusHash(Hash160::from_data(&next_snapshot.consensus_hash.0).0);

            let next_index_root = {
                let mut tx =
                    SortitionHandleTx::begin(&mut db, &last_snapshot.sortition_id).unwrap();
                let next_index_root = tx
                    .append_chain_tip_snapshot(
                        &last_snapshot,
                        &next_snapshot,
                        &vec![],
                        &vec![],
                        None,
                        None,
                        None,
                    )
                    .unwrap();
                tx.commit().unwrap();
                next_index_root
            };

            next_snapshot.index_root = next_index_root;

            let mut expected_tip = next_snapshot.clone();
            expected_tip.index_root = next_index_root;

            let canonical_tip = SortitionDB::get_canonical_burn_chain_tip(db.conn()).unwrap();
            assert_eq!(canonical_tip, expected_tip);

            verify_fork_integrity(&mut db, &canonical_tip.sortition_id);
            all_chain_tips.push(canonical_tip.sortition_id.clone());
        }

        for tip_header_hash in all_chain_tips.iter() {
            verify_fork_integrity(&mut db, tip_header_hash);
        }
    }

    #[test]
    fn test_get_stacks_header_hashes() {
        let first_burn_hash = BurnchainHeaderHash::from_hex(
            "10000000000000000000000000000000000000000000000000000000000000ff",
        )
        .unwrap();
        let mut db = SortitionDB::connect_test(0, &first_burn_hash).unwrap();
        {
            let mut last_snapshot = SortitionDB::get_first_block_snapshot(db.conn()).unwrap();
            let mut total_burn = 0;
            let mut total_sortitions = 0;
            for i in 0..256 {
                let snapshot_row = if i % 3 == 0 {
                    BlockSnapshot {
                        accumulated_coinbase_ustx: 0,
                        pox_valid: true,
                        block_height: i + 1,
                        burn_header_timestamp: get_epoch_time_secs(),
                        burn_header_hash: BurnchainHeaderHash::from_bytes(&[
                            0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
                            0, 0, 0, 0, 0, 0, 0, i as u8,
                        ])
                        .unwrap(),
                        sortition_id: SortitionId([
                            0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
                            0, 0, 0, 0, 0, 0, 0, i as u8,
                        ]),
                        parent_sortition_id: last_snapshot.sortition_id.clone(),
                        parent_burn_header_hash: BurnchainHeaderHash::from_bytes(&[
                            (if i == 0 { 0x10 } else { 0 }) as u8,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            (if i == 0 { 0xff } else { i - 1 }) as u8,
                        ])
                        .unwrap(),
                        consensus_hash: ConsensusHash::from_bytes(&[
                            1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, i as u8,
                        ])
                        .unwrap(),
                        ops_hash: OpsHash::from_bytes(&[
                            0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
                            0, 0, 0, 0, 0, 0, 0, i as u8,
                        ])
                        .unwrap(),
                        total_burn: total_burn,
                        sortition: false,
                        sortition_hash: SortitionHash([(i as u8); 32]),
                        winning_block_txid: Txid([(i as u8); 32]),
                        winning_stacks_block_hash: BlockHeaderHash([0u8; 32]),
                        index_root: TrieHash::from_empty_data(),
                        num_sortitions: total_sortitions,
                        stacks_block_accepted: false,
                        stacks_block_height: 0,
                        arrival_index: 0,
                        canonical_stacks_tip_height: 0,
                        canonical_stacks_tip_hash: BlockHeaderHash([0u8; 32]),
                        canonical_stacks_tip_consensus_hash: ConsensusHash([0u8; 20]),
                        miner_pk_hash: None,
                    }
                } else {
                    total_burn += 1;
                    total_sortitions += 1;
                    BlockSnapshot {
                        accumulated_coinbase_ustx: 0,
                        pox_valid: true,
                        block_height: i + 1,
                        burn_header_timestamp: get_epoch_time_secs(),
                        burn_header_hash: BurnchainHeaderHash::from_bytes(&[
                            0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
                            0, 0, 0, 0, 0, 0, 0, i as u8,
                        ])
                        .unwrap(),
                        sortition_id: SortitionId([
                            0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
                            0, 0, 0, 0, 0, 0, 0, i as u8,
                        ]),
                        parent_sortition_id: last_snapshot.sortition_id.clone(),
                        parent_burn_header_hash: BurnchainHeaderHash::from_bytes(&[
                            (if i == 0 { 0x10 } else { 0 }) as u8,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            (if i == 0 { 0xff } else { i - 1 }) as u8,
                        ])
                        .unwrap(),
                        consensus_hash: ConsensusHash::from_bytes(&[
                            1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, i as u8,
                        ])
                        .unwrap(),
                        ops_hash: OpsHash::from_bytes(&[
                            0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
                            0, 0, 0, 0, 0, 0, 0, i as u8,
                        ])
                        .unwrap(),
                        total_burn: total_burn,
                        sortition: true,
                        sortition_hash: SortitionHash([(i as u8); 32]),
                        winning_block_txid: Txid([(i as u8); 32]),
                        winning_stacks_block_hash: BlockHeaderHash([(i as u8); 32]),
                        index_root: TrieHash::from_empty_data(),
                        num_sortitions: total_sortitions,
                        stacks_block_accepted: false,
                        stacks_block_height: 0,
                        arrival_index: 0,
                        canonical_stacks_tip_height: 0,
                        canonical_stacks_tip_hash: BlockHeaderHash([0u8; 32]),
                        canonical_stacks_tip_consensus_hash: ConsensusHash([0u8; 20]),
                        miner_pk_hash: None,
                    }
                };

                // NOTE: we don't care about VRF keys or block commits here

                let mut tx =
                    SortitionHandleTx::begin(&mut db, &last_snapshot.sortition_id).unwrap();

                let index_root = tx
                    .append_chain_tip_snapshot(
                        &last_snapshot,
                        &snapshot_row,
                        &vec![],
                        &vec![],
                        None,
                        None,
                        None,
                    )
                    .unwrap();
                last_snapshot = snapshot_row;
                last_snapshot.index_root = index_root;

                // should succeed within the tx
                let ch = tx
                    .get_consensus_at(i + 1)
                    .unwrap()
                    .unwrap_or(ConsensusHash::empty());
                assert_eq!(ch, last_snapshot.consensus_hash);

                tx.commit().unwrap();
            }
        }

        let canonical_tip = SortitionDB::get_canonical_burn_chain_tip(db.conn()).unwrap();
        let mut cache = BlockHeaderCache::new();

        {
            let ic = db.index_conn();
            let hashes = ic
                .get_stacks_header_hashes(256, &canonical_tip.consensus_hash, &cache)
                .unwrap();
            SortitionDB::merge_block_header_cache(&mut cache, &hashes);

            assert_eq!(hashes.len(), 256);
            for i in 0..256 {
                let (ref consensus_hash, ref block_hash_opt) = &hashes[i];
                if i % 3 == 0 {
                    assert!(block_hash_opt.is_none());
                } else {
                    assert!(block_hash_opt.is_some());
                    let block_hash = block_hash_opt.unwrap();
                    assert_eq!(block_hash, BlockHeaderHash([(i as u8); 32]));
                }
                assert_eq!(
                    *consensus_hash,
                    ConsensusHash::from_bytes(&[
                        1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, i as u8
                    ])
                    .unwrap()
                );

                if i > 0 {
                    assert!(cache.contains_key(consensus_hash));
                    assert_eq!(cache.get(consensus_hash).unwrap().0, *block_hash_opt);
                }
            }
        }

        {
            let ic = db.index_conn();
            let hashes = ic
                .get_stacks_header_hashes(
                    256,
                    &canonical_tip.consensus_hash,
                    &mut BlockHeaderCache::new(),
                )
                .unwrap();
            SortitionDB::merge_block_header_cache(&mut cache, &hashes);

            let cached_hashes = ic
                .get_stacks_header_hashes(256, &canonical_tip.consensus_hash, &cache)
                .unwrap();

            assert_eq!(hashes.len(), 256);
            assert_eq!(cached_hashes.len(), 256);
            for i in 0..256 {
                assert_eq!(cached_hashes[i], hashes[i]);
                let (ref consensus_hash, ref block_hash_opt) = &hashes[i];
                if i % 3 == 0 {
                    assert!(block_hash_opt.is_none());
                } else {
                    assert!(block_hash_opt.is_some());
                    let block_hash = block_hash_opt.unwrap();
                    assert_eq!(block_hash, BlockHeaderHash([(i as u8); 32]));
                }
                assert_eq!(
                    *consensus_hash,
                    ConsensusHash::from_bytes(&[
                        1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, i as u8
                    ])
                    .unwrap()
                );

                if i > 0 {
                    assert!(cache.contains_key(consensus_hash));
                    assert_eq!(cache.get(consensus_hash).unwrap().0, *block_hash_opt);
                }
            }
        }

        {
            let ic = db.index_conn();
            let hashes = ic
                .get_stacks_header_hashes(
                    192,
                    &canonical_tip.consensus_hash,
                    &mut BlockHeaderCache::new(),
                )
                .unwrap();
            SortitionDB::merge_block_header_cache(&mut cache, &hashes);

            let cached_hashes = ic
                .get_stacks_header_hashes(192, &canonical_tip.consensus_hash, &cache)
                .unwrap();

            assert_eq!(hashes.len(), 192);
            assert_eq!(cached_hashes.len(), 192);
            for i in 64..256 {
                assert_eq!(cached_hashes[i - 64], hashes[i - 64]);
                let (ref consensus_hash, ref block_hash_opt) = &hashes[i - 64];
                if i % 3 == 0 {
                    assert!(block_hash_opt.is_none());
                } else {
                    assert!(block_hash_opt.is_some());
                    let block_hash = block_hash_opt.unwrap();
                    assert_eq!(block_hash, BlockHeaderHash([(i as u8); 32]));
                }
                assert_eq!(
                    *consensus_hash,
                    ConsensusHash::from_bytes(&[
                        1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, i as u8
                    ])
                    .unwrap()
                );

                assert!(cache.contains_key(consensus_hash));
                assert_eq!(cache.get(consensus_hash).unwrap().0, *block_hash_opt);
            }
        }

        {
            let ic = db.index_conn();
            let hashes = ic
                .get_stacks_header_hashes(
                    257,
                    &canonical_tip.consensus_hash,
                    &mut BlockHeaderCache::new(),
                )
                .unwrap();
            SortitionDB::merge_block_header_cache(&mut cache, &hashes);

            let cached_hashes = ic
                .get_stacks_header_hashes(257, &canonical_tip.consensus_hash, &cache)
                .unwrap();

            assert_eq!(hashes.len(), 256);
            assert_eq!(cached_hashes.len(), 256);
            for i in 0..256 {
                assert_eq!(cached_hashes[i], hashes[i]);
                let (ref consensus_hash, ref block_hash_opt) = &hashes[i];
                if i % 3 == 0 {
                    assert!(block_hash_opt.is_none());
                } else {
                    assert!(block_hash_opt.is_some());
                    let block_hash = block_hash_opt.unwrap();
                    assert_eq!(block_hash, BlockHeaderHash([(i as u8); 32]));
                }
                assert_eq!(
                    *consensus_hash,
                    ConsensusHash::from_bytes(&[
                        1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, i as u8
                    ])
                    .unwrap()
                );

                if i > 0 {
                    assert!(cache.contains_key(consensus_hash));
                    assert_eq!(cache.get(consensus_hash).unwrap().0, *block_hash_opt);
                }
            }
        }

        {
            let ic = db.index_conn();
            let err = ic
                .get_stacks_header_hashes(256, &ConsensusHash([0x03; 20]), &BlockHeaderCache::new())
                .unwrap_err();
            match err {
                db_error::NotFoundError => {}
                _ => {
                    eprintln!("Got wrong error: {:?}", &err);
                    assert!(false);
                    unreachable!();
                }
            }

            let err = ic
                .get_stacks_header_hashes(256, &ConsensusHash([0x03; 20]), &cache)
                .unwrap_err();
            match err {
                db_error::NotFoundError => {}
                _ => {
                    eprintln!("Got wrong error: {:?}", &err);
                    assert!(false);
                    unreachable!();
                }
            }
        }
    }

    pub fn make_fork_run(
        db: &mut SortitionDB,
        start_snapshot: &BlockSnapshot,
        length: u64,
        bit_pattern: u8,
    ) -> Vec<BlockSnapshot> {
        let mut last_snapshot = start_snapshot.clone();
        let mut new_snapshots = vec![];
        for i in last_snapshot.block_height..(last_snapshot.block_height + length) {
            let snapshot = BlockSnapshot {
                accumulated_coinbase_ustx: 0,
                pox_valid: true,
                block_height: last_snapshot.block_height + 1,
                burn_header_timestamp: get_epoch_time_secs(),
                burn_header_hash: BurnchainHeaderHash([(i as u8) | bit_pattern; 32]),
                sortition_id: SortitionId([(i as u8) | bit_pattern; 32]),
                parent_sortition_id: last_snapshot.sortition_id.clone(),
                parent_burn_header_hash: last_snapshot.burn_header_hash.clone(),
                consensus_hash: ConsensusHash([((i + 1) as u8) | bit_pattern; 20]),
                ops_hash: OpsHash([(i as u8) | bit_pattern; 32]),
                total_burn: 0,
                sortition: true,
                sortition_hash: SortitionHash([(i as u8) | bit_pattern; 32]),
                winning_block_txid: Txid([(i as u8) | bit_pattern; 32]),
                winning_stacks_block_hash: BlockHeaderHash([(i as u8) | bit_pattern; 32]),
                index_root: TrieHash([0u8; 32]),
                num_sortitions: last_snapshot.num_sortitions + 1,
                stacks_block_accepted: false,
                stacks_block_height: 0,
                arrival_index: 0,
                canonical_stacks_tip_height: last_snapshot.canonical_stacks_tip_height,
                canonical_stacks_tip_hash: last_snapshot.canonical_stacks_tip_hash,
                canonical_stacks_tip_consensus_hash: last_snapshot
                    .canonical_stacks_tip_consensus_hash,
                miner_pk_hash: None,
            };
            new_snapshots.push(snapshot.clone());
            {
                let mut tx = SortitionHandleTx::begin(db, &last_snapshot.sortition_id).unwrap();
                let _index_root = tx
                    .append_chain_tip_snapshot(
                        &last_snapshot,
                        &snapshot,
                        &vec![],
                        &vec![],
                        None,
                        None,
                        None,
                    )
                    .unwrap();
                tx.commit().unwrap();
            }
            last_snapshot = SortitionDB::get_block_snapshot(db.conn(), &snapshot.sortition_id)
                .unwrap()
                .unwrap();
        }
        new_snapshots
    }

    #[test]
    fn test_set_stacks_block_accepted() {
        let first_burn_hash = BurnchainHeaderHash::from_hex(
            "10000000000000000000000000000000000000000000000000000000000000ff",
        )
        .unwrap();
        let mut db = SortitionDB::connect_test(0, &first_burn_hash).unwrap();

        let mut last_snapshot = SortitionDB::get_first_block_snapshot(db.conn()).unwrap();

        // seed a single fork
        make_fork_run(&mut db, &last_snapshot, 5, 0);

        // set some blocks as processed
        for i in 0..5 {
            let consensus_hash = ConsensusHash([(i + 1) as u8; 20]);

            let stacks_block_hash = BlockHeaderHash([i as u8; 32]);
            let height = i;

            {
                let mut tx = db.tx_begin_at_tip();

                debug!(
                    "test: set_stacks_block_accepted {}/{} height {}",
                    &consensus_hash, &stacks_block_hash, height
                );
                tx.set_stacks_block_accepted(&consensus_hash, &stacks_block_hash, height)
                    .unwrap();
                tx.commit().unwrap();
            }

            // chain tip is memoized to the current burn chain tip
            let (block_consensus_hash, block_bhh) =
                SortitionDB::get_canonical_stacks_chain_tip_hash(db.conn()).unwrap();
            assert_eq!(block_consensus_hash, consensus_hash);
            assert_eq!(block_bhh, stacks_block_hash);
        }

        last_snapshot = SortitionDB::get_block_snapshot(db.conn(), &SortitionId([0x04; 32]))
            .unwrap()
            .unwrap();

        // before materializing new arrivals to the MARF, we should still have the canonical tip
        assert_eq!(last_snapshot.canonical_stacks_tip_height, 4);
        assert_eq!(
            last_snapshot.canonical_stacks_tip_consensus_hash,
            ConsensusHash([0x05; 20])
        );
        assert_eq!(
            last_snapshot.canonical_stacks_tip_hash,
            BlockHeaderHash([0x04; 32])
        );

        // materialize all block arrivals in the MARF
        make_fork_run(&mut db, &last_snapshot, 1, 0);

        // verify that all Stacks block in this fork can be looked up from this chain tip
        last_snapshot = SortitionDB::get_canonical_burn_chain_tip(db.conn()).unwrap();
        {
            let ic = db.index_conn();
            for i in 0..5 {
                let parent_stacks_block_hash = BlockHeaderHash([i as u8; 32]);
                let parent_key = db_keys::stacks_block_index(&parent_stacks_block_hash);

                test_debug!(
                    "Look up '{}' off of {}",
                    &parent_key,
                    &last_snapshot.burn_header_hash
                );
                let value_opt = ic
                    .get_indexed(&last_snapshot.sortition_id, &parent_key)
                    .unwrap();
                assert!(value_opt.is_some());
                assert_eq!(value_opt.unwrap(), format!("{}", i));
            }
        }

        // make a burn fork off of the 5th block
        last_snapshot = SortitionDB::get_canonical_burn_chain_tip(db.conn()).unwrap();
        make_fork_run(&mut db, &last_snapshot, 5, 0x80);

        // chain tip is _still_ memoized to the last materialized chain tip
        last_snapshot = SortitionDB::get_canonical_burn_chain_tip(db.conn()).unwrap();
        assert_eq!(
            last_snapshot.burn_header_hash,
            BurnchainHeaderHash([0x8a; 32])
        );
        assert_eq!(last_snapshot.canonical_stacks_tip_height, 4);
        assert_eq!(
            last_snapshot.canonical_stacks_tip_hash,
            BlockHeaderHash([0x04; 32])
        );
        assert_eq!(
            last_snapshot.canonical_stacks_tip_consensus_hash,
            ConsensusHash([0x05; 20])
        );

        // accept blocks 5 and 7 in one fork, and 6, 8, 9 in another.
        // Stacks fork 1,2,3,4,5,7 will be the longest fork.
        // Stacks fork 1,2,3,4 will overtake it when blocks 6,8,9 are processed.
        for (i, height) in [7].iter().zip([6].iter()) {
            let consensus_hash = ConsensusHash([((i + 1) | 0x80) as u8; 20]);
            let stacks_block_hash = BlockHeaderHash([(i | 0x80) as u8; 32]);

            {
                let mut tx = db.tx_begin_at_tip();
                tx.set_stacks_block_accepted(&consensus_hash, &stacks_block_hash, *height)
                    .unwrap();
                tx.commit().unwrap();
            }

            // chain tip is memoized to the current burn chain tip, since it's the longest stacks fork
            let (block_consensus_hash, block_bhh) =
                SortitionDB::get_canonical_stacks_chain_tip_hash(db.conn()).unwrap();
            assert_eq!(block_consensus_hash, consensus_hash);
            assert_eq!(block_bhh, stacks_block_hash);
        }

        // chain tip is _still_ memoized to the last materialized chain tip (i.e. stacks block 7)
        last_snapshot = SortitionDB::get_canonical_burn_chain_tip(db.conn()).unwrap();
        assert_eq!(
            last_snapshot.burn_header_hash,
            BurnchainHeaderHash([0x8a; 32])
        );
        assert_eq!(
            last_snapshot.canonical_stacks_tip_consensus_hash,
            ConsensusHash([0x88; 20])
        );
        assert_eq!(
            last_snapshot.canonical_stacks_tip_hash,
            BlockHeaderHash([0x87; 32])
        );
        assert_eq!(last_snapshot.canonical_stacks_tip_height, 6);

        // when the blocks for burn blocks 6 and 8 arrive, the canonical fork is still at stacks
        // block 7.  The two stacks forks will be:
        // * 1,2,3,4,5,7
        // * 1,2,3,4,6,8
        for (i, height) in [6, 8].iter().zip([5, 6].iter()) {
            let consensus_hash = ConsensusHash([((i + 1) | 0x80) as u8; 20]);
            let stacks_block_hash = BlockHeaderHash([(i | 0x80) as u8; 32]);

            {
                let mut tx = db.tx_begin_at_tip();
                tx.set_stacks_block_accepted(&consensus_hash, &stacks_block_hash, *height)
                    .unwrap();
                tx.commit().unwrap();
            }

            // chain tip is memoized to the current burn chain tip, since it's the longest stacks fork.
            // BUT! the tie-breaking logic will cause the canonical fork to *flip*
            let (block_consensus_hash, block_bhh) =
                SortitionDB::get_canonical_stacks_chain_tip_hash(db.conn()).unwrap();

            if *i != 8 {
                assert_eq!(
                    block_consensus_hash,
                    last_snapshot.canonical_stacks_tip_consensus_hash
                );
                assert_eq!(block_bhh, last_snapshot.canonical_stacks_tip_hash);
            } else {
                // flip!
                let new_last_snapshot =
                    SortitionDB::get_canonical_burn_chain_tip(db.conn()).unwrap();
                assert_eq!(
                    block_consensus_hash,
                    new_last_snapshot.canonical_stacks_tip_consensus_hash
                );
                assert_eq!(block_bhh, new_last_snapshot.canonical_stacks_tip_hash);
                assert_ne!(
                    new_last_snapshot.canonical_stacks_tip_consensus_hash,
                    last_snapshot.canonical_stacks_tip_consensus_hash
                );
                assert_ne!(
                    new_last_snapshot.canonical_stacks_tip_hash,
                    last_snapshot.canonical_stacks_tip_hash
                );
            }
        }

        // when the block for burn block 9 arrives, the canonical stacks fork will be
        // 1,2,3,4,6,8,9.  It overtakes 1,2,3,4,5,7
        for (i, height) in [9].iter().zip([7].iter()) {
            let consensus_hash = ConsensusHash([((i + 1) | 0x80) as u8; 20]);
            let stacks_block_hash = BlockHeaderHash([(i | 0x80) as u8; 32]);

            {
                let mut tx = db.tx_begin_at_tip();
                tx.set_stacks_block_accepted(&consensus_hash, &stacks_block_hash, *height)
                    .unwrap();
                tx.commit().unwrap();
            }

            // we've overtaken the longest fork with a different longest fork on this burn chain fork
            let (block_consensus_hash, block_bhh) =
                SortitionDB::get_canonical_stacks_chain_tip_hash(db.conn()).unwrap();
            assert_eq!(block_consensus_hash, consensus_hash);
            assert_eq!(block_bhh, stacks_block_hash);
        }

        // canonical stacks chain tip is now stacks block 9
        last_snapshot = SortitionDB::get_canonical_burn_chain_tip(db.conn()).unwrap();
        assert_eq!(
            last_snapshot.burn_header_hash,
            BurnchainHeaderHash([0x8a; 32])
        );
        assert_eq!(
            last_snapshot.canonical_stacks_tip_consensus_hash,
            ConsensusHash([0x8a; 20])
        );
        assert_eq!(
            last_snapshot.canonical_stacks_tip_hash,
            BlockHeaderHash([0x89; 32])
        );
        assert_eq!(last_snapshot.canonical_stacks_tip_height, 7);

        // fork the burn chain at 0x4, producing a longer burnchain fork.  There are now two
        // burnchain forks, where the first one has two stacks forks:
        // stx:      1,    2,    3,    4,          6,          8,    9
        // stx:      1,    2,    3,    4,    5,          7,
        // burn:  0x01, 0x02, 0x03, 0x04, 0x85, 0x86, 0x87, 0x88, 0x89, 0x8a
        //
        // stx:      1,    2,    3,    4
        // burn:  0x01, 0x02, 0x03, 0x04, 0x45, 0x46, 0x47, 0x48, 0x49, 0x4a, 0x4b
        last_snapshot = SortitionDB::get_block_snapshot(db.conn(), &SortitionId([0x04; 32]))
            .unwrap()
            .unwrap();
        make_fork_run(&mut db, &last_snapshot, 7, 0x40);

        // canonical stacks chain tip is now stacks block 4, since the burn chain fork ending on
        // 0x4b has overtaken the burn chain fork ending on 0x8a
        last_snapshot = SortitionDB::get_canonical_burn_chain_tip(db.conn()).unwrap();
        assert_eq!(
            last_snapshot.burn_header_hash,
            BurnchainHeaderHash([0x4b; 32])
        );
        assert_eq!(
            last_snapshot.canonical_stacks_tip_consensus_hash,
            ConsensusHash([0x05; 20])
        );
        assert_eq!(
            last_snapshot.canonical_stacks_tip_hash,
            BlockHeaderHash([0x04; 32])
        );
        assert_eq!(last_snapshot.canonical_stacks_tip_height, 4);

        // set the stacks block at 0x4b as accepted as the 5th block
        {
            let mut tx = db.tx_begin_at_tip();
            tx.set_stacks_block_accepted(
                &ConsensusHash([0x4c; 20]),
                &BlockHeaderHash([0x4b; 32]),
                5,
            )
            .unwrap();
            tx.commit().unwrap();
        }

        last_snapshot = SortitionDB::get_canonical_burn_chain_tip(db.conn()).unwrap();
        assert_eq!(
            last_snapshot.burn_header_hash,
            BurnchainHeaderHash([0x4b; 32])
        );
        assert_eq!(
            last_snapshot.canonical_stacks_tip_consensus_hash,
            ConsensusHash([0x4c; 20])
        );
        assert_eq!(
            last_snapshot.canonical_stacks_tip_hash,
            BlockHeaderHash([0x4b; 32])
        );
        assert_eq!(last_snapshot.canonical_stacks_tip_height, 5);

        // fork the burn chain at 0x48, producing a shorter burnchain fork.  There are now three
        // burnchain forks:
        // stx:      1,    2,    3,    4,          6,          8,    9
        // stx:      1,    2,    3,    4,    5,          7,
        // burn:  0x01, 0x02, 0x03, 0x04, 0x85, 0x86, 0x87, 0x88, 0x89, 0x8a
        //
        // stx:      1,    2,    3,    4,                                        5
        // burn:  0x01, 0x02, 0x03, 0x04, 0x45, 0x46, 0x47, 0x48, 0x49, 0x4a, 0x4b
        //
        // stx:      1,    2,    3,    4,
        // burn:  0x01, 0x02, 0x03, 0x04, 0x45, 0x46, 0x47, 0x48, 0x29, 0x2a
        last_snapshot = SortitionDB::get_block_snapshot(db.conn(), &SortitionId([0x48; 32]))
            .unwrap()
            .unwrap();
        make_fork_run(&mut db, &last_snapshot, 2, 0x20);

        last_snapshot = SortitionDB::get_block_snapshot(db.conn(), &SortitionId([0x2a; 32]))
            .unwrap()
            .unwrap();
        assert_eq!(
            last_snapshot.burn_header_hash,
            BurnchainHeaderHash([0x2a; 32])
        );
        assert_eq!(
            last_snapshot.canonical_stacks_tip_consensus_hash,
            ConsensusHash([0x05; 20])
        );
        assert_eq!(
            last_snapshot.canonical_stacks_tip_hash,
            BlockHeaderHash([0x04; 32])
        );
        assert_eq!(last_snapshot.canonical_stacks_tip_height, 4);

        // doesn't affect canonical chain tip
        last_snapshot = SortitionDB::get_canonical_burn_chain_tip(db.conn()).unwrap();
        assert_eq!(
            last_snapshot.burn_header_hash,
            BurnchainHeaderHash([0x4b; 32])
        );
        assert_eq!(
            last_snapshot.canonical_stacks_tip_consensus_hash,
            ConsensusHash([0x4c; 20])
        );
        assert_eq!(
            last_snapshot.canonical_stacks_tip_hash,
            BlockHeaderHash([0x4b; 32])
        );
        assert_eq!(last_snapshot.canonical_stacks_tip_height, 5);

        // set the stacks block at 0x29 and 0x2a as accepted as the 5th and 6th blocks
        {
            let mut tx = db.tx_handle_begin(&SortitionId([0x2a; 32])).unwrap();
            tx.set_stacks_block_accepted(
                &ConsensusHash([0x2a; 20]),
                &BlockHeaderHash([0x29; 32]),
                5,
            )
            .unwrap();
            tx.set_stacks_block_accepted(
                &ConsensusHash([0x2b; 20]),
                &BlockHeaderHash([0x2a; 32]),
                6,
            )
            .unwrap();
            tx.commit().unwrap();
        }

        // new state of the world:
        // burnchain forks:
        // stx:      1,    2,    3,    4,          6,          8,    9
        // stx:      1,    2,    3,    4,    5,          7,
        // burn:  0x01, 0x02, 0x03, 0x04, 0x85, 0x86, 0x87, 0x88, 0x89, 0x8a
        //
        // stx:      1,    2,    3,    4,                                        5
        // burn:  0x01, 0x02, 0x03, 0x04, 0x45, 0x46, 0x47, 0x48, 0x49, 0x4a, 0x4b
        //
        // stx:      1,    2,    3,    4,                            5,    6
        // burn:  0x01, 0x02, 0x03, 0x04, 0x45, 0x46, 0x47, 0x48, 0x29, 0x2a

        // canonical stacks chain off of non-canonical burn chain fork 0x2a should have been updated
        last_snapshot = SortitionDB::get_block_snapshot(db.conn(), &SortitionId([0x2a; 32]))
            .unwrap()
            .unwrap();
        assert_eq!(
            last_snapshot.burn_header_hash,
            BurnchainHeaderHash([0x2a; 32])
        );
        assert_eq!(
            last_snapshot.canonical_stacks_tip_consensus_hash,
            ConsensusHash([0x2b; 20])
        );
        assert_eq!(
            last_snapshot.canonical_stacks_tip_hash,
            BlockHeaderHash([0x2a; 32])
        );
        assert_eq!(last_snapshot.canonical_stacks_tip_height, 6);

        // insertion on the non-canonical tip doesn't affect canonical chain tip
        last_snapshot = SortitionDB::get_canonical_burn_chain_tip(db.conn()).unwrap();
        assert_eq!(
            last_snapshot.burn_header_hash,
            BurnchainHeaderHash([0x4b; 32])
        );
        assert_eq!(
            last_snapshot.canonical_stacks_tip_consensus_hash,
            ConsensusHash([0x4c; 20])
        );
        assert_eq!(
            last_snapshot.canonical_stacks_tip_hash,
            BlockHeaderHash([0x4b; 32])
        );
        assert_eq!(last_snapshot.canonical_stacks_tip_height, 5);

        // insert stacks blocks #6, #7, #8, #9 off of the burn chain tip starting at 0x4b (i.e. the
        // canonical burn chain tip), on blocks 0x45, 0x46, and 0x47
        {
            let mut tx = db.tx_begin_at_tip();
            tx.set_stacks_block_accepted(
                &ConsensusHash([0x46; 20]),
                &BlockHeaderHash([0x45; 32]),
                5,
            )
            .unwrap();
            tx.set_stacks_block_accepted(
                &ConsensusHash([0x47; 20]),
                &BlockHeaderHash([0x46; 32]),
                6,
            )
            .unwrap();
            tx.set_stacks_block_accepted(
                &ConsensusHash([0x48; 20]),
                &BlockHeaderHash([0x47; 32]),
                7,
            )
            .unwrap();
            tx.set_stacks_block_accepted(
                &ConsensusHash([0x49; 20]),
                &BlockHeaderHash([0x48; 32]),
                8,
            )
            .unwrap();
            tx.commit().unwrap();
        }

        // new state of the world:
        // burnchain forks:
        // stx:      1,    2,    3,    4,          6,          8,    9
        // stx:      1,    2,    3,    4,    5,          7,
        // burn:  0x01, 0x02, 0x03, 0x04, 0x85, 0x86, 0x87, 0x88, 0x89, 0x8a
        //
        // stx:      1,    2,    3,    4,    6,    7,    8,   9
        // stx:      1,    2,    3,    4,                                        5
        // burn:  0x01, 0x02, 0x03, 0x04, 0x45, 0x46, 0x47, 0x48, 0x49, 0x4a, 0x4b
        //
        // stx:      1,    2,    3,    4,                            5,    6
        // burn:  0x01, 0x02, 0x03, 0x04, 0x45, 0x46, 0x47, 0x48, 0x29, 0x2a

        // new stacks tip is the 9th block added on burn chain tipped by 0x4b
        last_snapshot = SortitionDB::get_canonical_burn_chain_tip(db.conn()).unwrap();
        assert_eq!(
            last_snapshot.burn_header_hash,
            BurnchainHeaderHash([0x4b; 32])
        );
        assert_eq!(
            last_snapshot.canonical_stacks_tip_consensus_hash,
            ConsensusHash([0x49; 20])
        );
        assert_eq!(
            last_snapshot.canonical_stacks_tip_hash,
            BlockHeaderHash([0x48; 32])
        );
        assert_eq!(last_snapshot.canonical_stacks_tip_height, 8);

        // LIMITATION: the burn chain tipped at 0x2a will _not_ be updated, since it is not the
        // canonical burn chain tip.
        last_snapshot = SortitionDB::get_block_snapshot(db.conn(), &SortitionId([0x2a; 32]))
            .unwrap()
            .unwrap();
        assert_eq!(
            last_snapshot.burn_header_hash,
            BurnchainHeaderHash([0x2a; 32])
        );
        assert_eq!(
            last_snapshot.canonical_stacks_tip_consensus_hash,
            ConsensusHash([0x2b; 20])
        );
        assert_eq!(
            last_snapshot.canonical_stacks_tip_hash,
            BlockHeaderHash([0x2a; 32])
        );
        assert_eq!(last_snapshot.canonical_stacks_tip_height, 6);

        // BUT, when the burn chain tipped by 0x2a overtakes the one tipped by 0x4b, then all blocks
        // will show up.
        make_fork_run(&mut db, &last_snapshot, 2, 0x20);

        // new state of the world:
        // burnchain forks:
        // stx:      1,    2,    3,    4,          6,          8,    9
        // stx:      1,    2,    3,    4,    5,          7,
        // burn:  0x01, 0x02, 0x03, 0x04, 0x85, 0x86, 0x87, 0x88, 0x89, 0x8a
        //
        // stx:      1,    2,    3,    4,    6,    7,    8,    9
        // stx:      1,    2,    3,    4,                                        5
        // burn:  0x01, 0x02, 0x03, 0x04, 0x45, 0x46, 0x47, 0x48, 0x49, 0x4a, 0x4b
        //
        // stx:      1,    2,    3,    4,    7,    8,    9,   10
        // stx:      1,    2,    3,    4,                            5,    6
        // burn:  0x01, 0x02, 0x03, 0x04, 0x45, 0x46, 0x47, 0x48, 0x29, 0x2a, 0x2b, 0x2c

        last_snapshot = SortitionDB::get_canonical_burn_chain_tip(db.conn()).unwrap();
        assert_eq!(
            last_snapshot.burn_header_hash,
            BurnchainHeaderHash([0x2c; 32])
        );
        assert_eq!(
            last_snapshot.canonical_stacks_tip_consensus_hash,
            ConsensusHash([0x49; 20])
        );
        assert_eq!(
            last_snapshot.canonical_stacks_tip_hash,
            BlockHeaderHash([0x48; 32])
        );
        assert_eq!(last_snapshot.canonical_stacks_tip_height, 8);
    }

    /// Verify that the highest Stacks pointer written remains so, even if blocks from lower
    /// heights arrive. Verify that the pointer changes even if no new sortitions are added.
    #[test]
    fn test_stacks_block_accepted_out_of_order() {
        let first_burn_hash = BurnchainHeaderHash::from_hex(
            "10000000000000000000000000000000000000000000000000000000000000ff",
        )
        .unwrap();
        let mut db = SortitionDB::connect_test(0, &first_burn_hash).unwrap();

        let mut last_snapshot = SortitionDB::get_first_block_snapshot(db.conn()).unwrap();

        // seed a single fork
        make_fork_run(&mut db, &last_snapshot, 5, 0);

        // set some blocks as processed
        for i in (0..5).rev() {
            let consensus_hash = ConsensusHash([(i + 1) as u8; 20]);
            let stacks_block_hash = BlockHeaderHash([i as u8; 32]);
            let height = i;

            {
                let mut tx = db.tx_begin_at_tip();

                debug!(
                    "test: set_stacks_block_accepted {}/{} height {}",
                    &consensus_hash, &stacks_block_hash, height
                );
                tx.set_stacks_block_accepted(&consensus_hash, &stacks_block_hash, height)
                    .unwrap();
                tx.commit().unwrap();
            }

            // chain tip is memoized to the current burn chain tip
            let (block_consensus_hash, block_bhh) =
                SortitionDB::get_canonical_stacks_chain_tip_hash(db.conn()).unwrap();
            assert_eq!(block_consensus_hash, ConsensusHash([0x05; 20]));
            assert_eq!(block_bhh, BlockHeaderHash([0x04; 32]));
        }

        last_snapshot = SortitionDB::get_block_snapshot(db.conn(), &SortitionId([0x04; 32]))
            .unwrap()
            .unwrap();

        // before materializing new arrivals to the MARF, we should still have the canonical tip
        assert_eq!(last_snapshot.canonical_stacks_tip_height, 4);
        assert_eq!(
            last_snapshot.canonical_stacks_tip_consensus_hash,
            ConsensusHash([0x05; 20])
        );
        assert_eq!(
            last_snapshot.canonical_stacks_tip_hash,
            BlockHeaderHash([0x04; 32])
        );
    }

    #[test]
    fn test_stacks_tip_tiebreaker() {
        let snapshot = BlockSnapshot {
            accumulated_coinbase_ustx: 0,
            pox_valid: true,
            block_height: 123,
            burn_header_timestamp: get_epoch_time_secs(),
            burn_header_hash: BurnchainHeaderHash([0x01; 32]),
            sortition_id: SortitionId([0x02; 32]),
            parent_sortition_id: SortitionId([0x01; 32]),
            parent_burn_header_hash: BurnchainHeaderHash([0xff; 32]),
            consensus_hash: ConsensusHash([0x03; 20]),
            ops_hash: OpsHash([0x04; 32]),
            total_burn: 0,
            sortition: true,
            sortition_hash: SortitionHash([0x05; 32]),
            winning_block_txid: Txid([0x06; 32]),
            winning_stacks_block_hash: BlockHeaderHash([0x07; 32]),
            index_root: TrieHash([0x08; 32]),
            num_sortitions: 3,
            stacks_block_accepted: false,
            stacks_block_height: 0,
            arrival_index: 0,
            canonical_stacks_tip_height: 0,
            canonical_stacks_tip_hash: BlockHeaderHash([0x09; 32]),
            canonical_stacks_tip_consensus_hash: ConsensusHash([0x0a; 20]),
            miner_pk_hash: None,
        };

        let best_height = 123;
        let new_block_arrivals = vec![
            (ConsensusHash([0x01; 20]), BlockHeaderHash([0x02; 32]), 123),
            (ConsensusHash([0x03; 20]), BlockHeaderHash([0x04; 32]), 123),
            (ConsensusHash([0x07; 20]), BlockHeaderHash([0x08; 32]), 122),
            (ConsensusHash([0x05; 20]), BlockHeaderHash([0x06; 32]), 123),
        ];

        assert_eq!(
            SortitionHandleTx::break_canonical_stacks_tip_tie(&snapshot, 121, &new_block_arrivals),
            None
        );
        assert_eq!(
            SortitionHandleTx::break_canonical_stacks_tip_tie(&snapshot, 122, &new_block_arrivals),
            Some(2)
        );
        assert_eq!(
            SortitionHandleTx::break_canonical_stacks_tip_tie(&snapshot, 123, &new_block_arrivals),
            Some(0)
        );
    }

    #[test]
    fn test_epoch_switch_205() {
        let mut rng = rand::thread_rng();
        let mut buf = [0u8; 32];
        rng.fill_bytes(&mut buf);
        let db_path_dir = format!(
            "/tmp/stacks-node-tests/unit-tests-sortdb/db-{}",
            to_hex(&buf)
        );

        let mut db = SortitionDB::connect(
            &db_path_dir,
            3,
            &BurnchainHeaderHash([0u8; 32]),
            0,
            &vec![
                StacksEpoch {
                    epoch_id: StacksEpochId::Epoch10,
                    start_height: 0,
                    end_height: 8,
                    block_limit: ExecutionCost::max_value(),
                    network_epoch: PEER_VERSION_EPOCH_1_0,
                },
                StacksEpoch {
                    epoch_id: StacksEpochId::Epoch20,
                    start_height: 8,
                    end_height: 12,
                    block_limit: ExecutionCost::max_value(),
                    network_epoch: PEER_VERSION_EPOCH_2_0,
                },
                StacksEpoch {
                    epoch_id: StacksEpochId::Epoch2_05,
                    start_height: 12,
                    end_height: STACKS_EPOCH_MAX,
                    block_limit: ExecutionCost::max_value(),
                    network_epoch: PEER_VERSION_EPOCH_2_05,
                },
            ],
            PoxConstants::test_default(),
            None,
            true,
        )
        .unwrap();

        let mut cur_snapshot = SortitionDB::get_canonical_burn_chain_tip(db.conn()).unwrap();
        // In this loop, we will advance the height, and check if the stacks epoch id is advancing as expected.
        for i in 0..20 {
            debug!("Get epoch for block height {}", cur_snapshot.block_height);
            let cur_epoch = SortitionDB::get_stacks_epoch(db.conn(), cur_snapshot.block_height)
                .unwrap()
                .unwrap();

            if cur_snapshot.block_height < 8 {
                assert_eq!(cur_epoch.epoch_id, StacksEpochId::Epoch10);
            } else if cur_snapshot.block_height < 12 {
                assert_eq!(cur_epoch.epoch_id, StacksEpochId::Epoch20);
            } else {
                assert_eq!(cur_epoch.epoch_id, StacksEpochId::Epoch2_05);
            }

            cur_snapshot =
                test_append_snapshot(&mut db, BurnchainHeaderHash([((i + 1) as u8); 32]), &vec![]);
        }
    }

    #[test]
    fn test_epoch_switch_21() {
        let mut rng = rand::thread_rng();
        let mut buf = [0u8; 32];
        rng.fill_bytes(&mut buf);
        let db_path_dir = format!("/tmp/test-blockstack-sortdb-{}", to_hex(&buf));

        let mut db = SortitionDB::connect(
            &db_path_dir,
            3,
            &BurnchainHeaderHash([0u8; 32]),
            0,
            &vec![
                StacksEpoch {
                    epoch_id: StacksEpochId::Epoch10,
                    start_height: 0,
                    end_height: 8,
                    block_limit: ExecutionCost::max_value(),
                    network_epoch: PEER_VERSION_EPOCH_1_0,
                },
                StacksEpoch {
                    epoch_id: StacksEpochId::Epoch20,
                    start_height: 8,
                    end_height: 12,
                    block_limit: ExecutionCost::max_value(),
                    network_epoch: PEER_VERSION_EPOCH_2_0,
                },
                StacksEpoch {
                    epoch_id: StacksEpochId::Epoch2_05,
                    start_height: 12,
                    end_height: 14,
                    block_limit: ExecutionCost::max_value(),
                    network_epoch: PEER_VERSION_EPOCH_2_05,
                },
                StacksEpoch {
                    epoch_id: StacksEpochId::Epoch21,
                    start_height: 14,
                    end_height: STACKS_EPOCH_MAX,
                    block_limit: ExecutionCost::max_value(),
                    network_epoch: PEER_VERSION_EPOCH_2_05,
                },
            ],
            PoxConstants::test_default(),
            None,
            true,
        )
        .unwrap();

        let mut cur_snapshot = SortitionDB::get_canonical_burn_chain_tip(db.conn()).unwrap();
        for i in 0..20 {
            debug!("Get epoch for block height {}", cur_snapshot.block_height);
            let cur_epoch = SortitionDB::get_stacks_epoch(db.conn(), cur_snapshot.block_height)
                .unwrap()
                .unwrap();

            if cur_snapshot.block_height < 8 {
                assert_eq!(cur_epoch.epoch_id, StacksEpochId::Epoch10);
            } else if cur_snapshot.block_height < 12 {
                assert_eq!(cur_epoch.epoch_id, StacksEpochId::Epoch20);
            } else if cur_snapshot.block_height < 14 {
                assert_eq!(cur_epoch.epoch_id, StacksEpochId::Epoch2_05);
            } else {
                assert_eq!(cur_epoch.epoch_id, StacksEpochId::Epoch21);
            }

            cur_snapshot =
                test_append_snapshot(&mut db, BurnchainHeaderHash([((i + 1) as u8); 32]), &vec![]);
        }
    }

    #[test]
    #[should_panic]
    fn test_bad_epochs_discontinuous() {
        let mut rng = rand::thread_rng();
        let mut buf = [0u8; 32];
        rng.fill_bytes(&mut buf);
        let db_path_dir = format!(
            "/tmp/stacks-node-tests/unit-tests-sortdb/db-{}",
            to_hex(&buf)
        );

        let db = SortitionDB::connect(
            &db_path_dir,
            3,
            &BurnchainHeaderHash([0u8; 32]),
            0,
            &vec![
                StacksEpoch {
                    epoch_id: StacksEpochId::Epoch10,
                    start_height: 0,
                    end_height: 8,
                    block_limit: ExecutionCost::max_value(),
                    network_epoch: PEER_VERSION_EPOCH_1_0,
                },
                StacksEpoch {
                    epoch_id: StacksEpochId::Epoch20,
                    start_height: 9,
                    end_height: 12,
                    block_limit: ExecutionCost::max_value(),
                    network_epoch: PEER_VERSION_EPOCH_2_0,
                }, // discontinuity
                StacksEpoch {
                    epoch_id: StacksEpochId::Epoch2_05,
                    start_height: 12,
                    end_height: STACKS_EPOCH_MAX,
                    block_limit: ExecutionCost::max_value(),
                    network_epoch: PEER_VERSION_EPOCH_2_05,
                },
            ],
            PoxConstants::test_default(),
            None,
            true,
        )
        .unwrap();
    }

    #[test]
    #[should_panic]
    fn test_bad_epochs_overlapping() {
        let mut rng = rand::thread_rng();
        let mut buf = [0u8; 32];
        rng.fill_bytes(&mut buf);
        let db_path_dir = format!(
            "/tmp/stacks-node-tests/unit-tests-sortdb/db-{}",
            to_hex(&buf)
        );

        let db = SortitionDB::connect(
            &db_path_dir,
            3,
            &BurnchainHeaderHash([0u8; 32]),
            0,
            &vec![
                StacksEpoch {
                    epoch_id: StacksEpochId::Epoch10,
                    start_height: 0,
                    end_height: 8,
                    block_limit: ExecutionCost::max_value(),
                    network_epoch: PEER_VERSION_EPOCH_1_0,
                },
                StacksEpoch {
                    epoch_id: StacksEpochId::Epoch20,
                    start_height: 7,
                    end_height: 12,
                    block_limit: ExecutionCost::max_value(),
                    network_epoch: PEER_VERSION_EPOCH_2_0,
                }, // overlap
                StacksEpoch {
                    epoch_id: StacksEpochId::Epoch2_05,
                    start_height: 12,
                    end_height: STACKS_EPOCH_MAX,
                    block_limit: ExecutionCost::max_value(),
                    network_epoch: PEER_VERSION_EPOCH_2_05,
                },
            ],
            PoxConstants::test_default(),
            None,
            true,
        )
        .unwrap();
    }

    #[test]
    #[should_panic]
    fn test_bad_epochs_missing_past() {
        let mut rng = rand::thread_rng();
        let mut buf = [0u8; 32];
        rng.fill_bytes(&mut buf);
        let db_path_dir = format!(
            "/tmp/stacks-node-tests/unit-tests-sortdb/db-{}",
            to_hex(&buf)
        );

        let db = SortitionDB::connect(
            &db_path_dir,
            3,
            &BurnchainHeaderHash([0u8; 32]),
            0,
            &vec![
                StacksEpoch {
                    epoch_id: StacksEpochId::Epoch10,
                    start_height: 1,
                    end_height: 8,
                    block_limit: ExecutionCost::max_value(),
                    network_epoch: PEER_VERSION_EPOCH_1_0,
                }, // should start at 0
                StacksEpoch {
                    epoch_id: StacksEpochId::Epoch20,
                    start_height: 8,
                    end_height: 12,
                    block_limit: ExecutionCost::max_value(),
                    network_epoch: PEER_VERSION_EPOCH_2_0,
                },
                StacksEpoch {
                    epoch_id: StacksEpochId::Epoch2_05,
                    start_height: 12,
                    end_height: STACKS_EPOCH_MAX,
                    block_limit: ExecutionCost::max_value(),
                    network_epoch: PEER_VERSION_EPOCH_2_05,
                },
            ],
            PoxConstants::test_default(),
            None,
            true,
        )
        .unwrap();
    }

    #[test]
    #[should_panic]
    fn test_bad_epochs_missing_future() {
        let mut rng = rand::thread_rng();
        let mut buf = [0u8; 32];
        rng.fill_bytes(&mut buf);
        let db_path_dir = format!(
            "/tmp/stacks-node-tests/unit-tests-sortdb/db-{}",
            to_hex(&buf)
        );

        let db = SortitionDB::connect(
            &db_path_dir,
            3,
            &BurnchainHeaderHash([0u8; 32]),
            0,
            &vec![
                StacksEpoch {
                    epoch_id: StacksEpochId::Epoch10,
                    start_height: 0,
                    end_height: 8,
                    block_limit: ExecutionCost::max_value(),
                    network_epoch: PEER_VERSION_EPOCH_1_0,
                },
                StacksEpoch {
                    epoch_id: StacksEpochId::Epoch20,
                    start_height: 8,
                    end_height: 12,
                    block_limit: ExecutionCost::max_value(),
                    network_epoch: PEER_VERSION_EPOCH_2_0,
                },
                StacksEpoch {
                    epoch_id: StacksEpochId::Epoch2_05,
                    start_height: 12,
                    end_height: 20,
                    block_limit: ExecutionCost::max_value(),
                    network_epoch: PEER_VERSION_EPOCH_2_05,
                }, // missing future
            ],
            PoxConstants::test_default(),
            None,
            true,
        )
        .unwrap();
    }

    #[test]
    #[should_panic]
    fn test_bad_epochs_invalid() {
        let mut rng = rand::thread_rng();
        let mut buf = [0u8; 32];
        rng.fill_bytes(&mut buf);
        let db_path_dir = format!(
            "/tmp/stacks-node-tests/unit-tests-sortdb/db-{}",
            to_hex(&buf)
        );

        let db = SortitionDB::connect(
            &db_path_dir,
            3,
            &BurnchainHeaderHash([0u8; 32]),
            0,
            &vec![
                StacksEpoch {
                    epoch_id: StacksEpochId::Epoch10,
                    start_height: 0,
                    end_height: 8,
                    block_limit: ExecutionCost::max_value(),
                    network_epoch: PEER_VERSION_EPOCH_1_0,
                },
                StacksEpoch {
                    epoch_id: StacksEpochId::Epoch20,
                    start_height: 8,
                    end_height: 7,
                    block_limit: ExecutionCost::max_value(),
                    network_epoch: PEER_VERSION_EPOCH_2_0,
                }, // invalid range
                StacksEpoch {
                    epoch_id: StacksEpochId::Epoch2_05,
                    start_height: 8,
                    end_height: STACKS_EPOCH_MAX,
                    block_limit: ExecutionCost::max_value(),
                    network_epoch: PEER_VERSION_EPOCH_2_05,
                },
            ],
            PoxConstants::test_default(),
            None,
            true,
        )
        .unwrap();
    }

    #[test]
    fn test_descended_from() {
        let block_height = 123;
        let vtxindex = 456;
        let first_burn_hash = BurnchainHeaderHash::from_hex(
            "0000000000000000000000000000000000000000000000000000000000000000",
        )
        .unwrap();

        let leader_key = LeaderKeyRegisterOp {
            consensus_hash: ConsensusHash::from_bytes(
                &hex_bytes("2222222222222222222222222222222222222222").unwrap(),
            )
            .unwrap(),
            public_key: VRFPublicKey::from_bytes(
                &hex_bytes("a366b51292bef4edd64063d9145c617fec373bceb0758e98cd72becd84d54c7a")
                    .unwrap(),
            )
            .unwrap(),
            memo: vec![01, 02, 03, 04, 05],

            txid: Txid::from_bytes_be(
                &hex_bytes("1bfa831b5fc56c858198acb8e77e5863c1e9d8ac26d49ddb914e24d8d4083562")
                    .unwrap(),
            )
            .unwrap(),
            vtxindex: vtxindex,
            block_height: block_height + 1,
            burn_header_hash: BurnchainHeaderHash([0x01; 32]),
        };

        let genesis_block_commit = LeaderBlockCommitOp {
            sunset_burn: 0,
            block_header_hash: BlockHeaderHash::from_bytes(
                &hex_bytes("2222222222222222222222222222222222222222222222222222222222222221")
                    .unwrap(),
            )
            .unwrap(),
            new_seed: VRFSeed::from_bytes(
                &hex_bytes("3333333333333333333333333333333333333333333333333333333333333333")
                    .unwrap(),
            )
            .unwrap(),
            // genesis
            parent_block_ptr: 0,
            parent_vtxindex: 0,
            key_block_ptr: (block_height + 1) as u32,
            key_vtxindex: vtxindex as u16,
            memo: vec![0x80],
            commit_outs: vec![],

            burn_fee: 12345,
            input: (Txid([0; 32]), 0),
            apparent_sender: BurnchainSigner::mock_parts(
                AddressHashMode::SerializeP2PKH,
                1,
                vec![StacksPublicKey::from_hex(
                    "02d8015134d9db8178ac93acbc43170a2f20febba5087a5b0437058765ad5133d0",
                )
                .unwrap()],
            ),

            txid: Txid::from_bytes_be(
                &hex_bytes("dec0489b200c05e3611c174a203da75bea86eb16d254afdec9d93a7d50623426")
                    .unwrap(),
            )
            .unwrap(),
            vtxindex: 1,
            block_height: block_height + 2,
            burn_parent_modulus: ((block_height + 1) % BURN_BLOCK_MINED_AT_MODULUS) as u8,
            burn_header_hash: BurnchainHeaderHash([0x03; 32]),
        };

        // descends from genesis
        let block_commit_1 = LeaderBlockCommitOp {
            sunset_burn: 0,
            block_header_hash: BlockHeaderHash::from_bytes(
                &hex_bytes("2222222222222222222222222222222222222222222222222222222222222222")
                    .unwrap(),
            )
            .unwrap(),
            new_seed: VRFSeed::from_bytes(
                &hex_bytes("3333333333333333333333333333333333333333333333333333333333333333")
                    .unwrap(),
            )
            .unwrap(),
            parent_block_ptr: genesis_block_commit.block_height as u32,
            parent_vtxindex: genesis_block_commit.vtxindex as u16,
            key_block_ptr: (block_height + 1) as u32,
            key_vtxindex: vtxindex as u16,
            memo: vec![0x80],
            commit_outs: vec![],

            burn_fee: 12345,
            input: (Txid([0; 32]), 0),
            apparent_sender: BurnchainSigner::mock_parts(
                AddressHashMode::SerializeP2PKH,
                1,
                vec![StacksPublicKey::from_hex(
                    "02d8015134d9db8178ac93acbc43170a2f20febba5087a5b0437058765ad5133d0",
                )
                .unwrap()],
            ),

            txid: Txid::from_bytes_be(
                &hex_bytes("c25b21f8c8d55f52cf67e1e7604ca243438df7753a06bea085e10a9957ce0f8e")
                    .unwrap(),
            )
            .unwrap(),
            vtxindex: 1,
            block_height: block_height + 3,
            burn_parent_modulus: ((block_height + 2) % BURN_BLOCK_MINED_AT_MODULUS) as u8,
            burn_header_hash: BurnchainHeaderHash([0x04; 32]),
        };

        // descends from block_commit_1
        let block_commit_1_1 = LeaderBlockCommitOp {
            sunset_burn: 0,
            block_header_hash: BlockHeaderHash::from_bytes(
                &hex_bytes("2222222222222222222222222222222222222222222222222222222222222224")
                    .unwrap(),
            )
            .unwrap(),
            new_seed: VRFSeed::from_bytes(
                &hex_bytes("3333333333333333333333333333333333333333333333333333333333333333")
                    .unwrap(),
            )
            .unwrap(),
            parent_block_ptr: block_commit_1.block_height as u32,
            parent_vtxindex: block_commit_1.vtxindex as u16,
            key_block_ptr: (block_height + 1) as u32,
            key_vtxindex: vtxindex as u16,
            memo: vec![0x80],
            commit_outs: vec![],

            burn_fee: 12345,
            input: (Txid([0; 32]), 0),
            apparent_sender: BurnchainSigner::mock_parts(
                AddressHashMode::SerializeP2PKH,
                1,
                vec![StacksPublicKey::from_hex(
                    "02d8015134d9db8178ac93acbc43170a2f20febba5087a5b0437058765ad5133d0",
                )
                .unwrap()],
            ),

            txid: Txid::from_bytes_be(
                &hex_bytes("a55f4f6afff0ba597a22a5d90bea2cd61b078518dbdf67f77588e3c0effb5c0f")
                    .unwrap(),
            )
            .unwrap(),
            vtxindex: 1,
            block_height: block_height + 4,
            burn_parent_modulus: ((block_height + 3) % BURN_BLOCK_MINED_AT_MODULUS) as u8,
            burn_header_hash: BurnchainHeaderHash([0x05; 32]),
        };

        // descends from genesis_block_commit
        let block_commit_2 = LeaderBlockCommitOp {
            sunset_burn: 0,
            block_header_hash: BlockHeaderHash::from_bytes(
                &hex_bytes("2222222222222222222222222222222222222222222222222222222222222223")
                    .unwrap(),
            )
            .unwrap(),
            new_seed: VRFSeed::from_bytes(
                &hex_bytes("3333333333333333333333333333333333333333333333333333333333333333")
                    .unwrap(),
            )
            .unwrap(),
            parent_block_ptr: genesis_block_commit.block_height as u32,
            parent_vtxindex: genesis_block_commit.vtxindex as u16,
            key_block_ptr: (block_height + 1) as u32,
            key_vtxindex: vtxindex as u16,
            memo: vec![0x80],
            commit_outs: vec![],

            burn_fee: 1,
            input: (Txid([0; 32]), 0),
            apparent_sender: BurnchainSigner::mock_parts(
                AddressHashMode::SerializeP2PKH,
                1,
                vec![StacksPublicKey::from_hex(
                    "02d8015134d9db8178ac93acbc43170a2f20febba5087a5b0437058765ad5133d0",
                )
                .unwrap()],
            ),

            txid: Txid::from_bytes_be(
                &hex_bytes("53bfa82f97ef65f0239ded2b4ed93cab1f9d72f9454ac5eb4d7d0f79ad9e0127")
                    .unwrap(),
            )
            .unwrap(),
            vtxindex: 2,
            block_height: block_height + 5,
            burn_parent_modulus: ((block_height + 4) % BURN_BLOCK_MINED_AT_MODULUS) as u8,
            burn_header_hash: BurnchainHeaderHash([0x06; 32]),
        };

        let mut db = SortitionDB::connect_test(block_height, &first_burn_hash).unwrap();

        let key_snapshot = test_append_snapshot(
            &mut db,
            BurnchainHeaderHash([0x01; 32]),
            &vec![BlockstackOperationType::LeaderKeyRegister(
                leader_key.clone(),
            )],
        );

        let genesis_commit_snapshot = test_append_snapshot_with_winner(
            &mut db,
            BurnchainHeaderHash([0x03; 32]),
            &vec![BlockstackOperationType::LeaderBlockCommit(
                genesis_block_commit.clone(),
            )],
            None,
            Some(genesis_block_commit.clone()),
        );

        let first_block_commit_snapshot = test_append_snapshot_with_winner(
            &mut db,
            BurnchainHeaderHash([0x04; 32]),
            &vec![BlockstackOperationType::LeaderBlockCommit(
                block_commit_1.clone(),
            )],
            None,
            Some(block_commit_1.clone()),
        );

        let second_block_commit_snapshot = test_append_snapshot_with_winner(
            &mut db,
            BurnchainHeaderHash([0x05; 32]),
            &vec![BlockstackOperationType::LeaderBlockCommit(
                block_commit_1_1.clone(),
            )],
            None,
            Some(block_commit_1_1.clone()),
        );

        let third_block_commit_snapshot = test_append_snapshot_with_winner(
            &mut db,
            BurnchainHeaderHash([0x06; 32]),
            &vec![BlockstackOperationType::LeaderBlockCommit(
                block_commit_2.clone(),
            )],
            None,
            Some(block_commit_2.clone()),
        );

        assert_eq!(
            genesis_commit_snapshot.winning_stacks_block_hash,
            genesis_block_commit.block_header_hash
        );
        assert_eq!(
            first_block_commit_snapshot.winning_stacks_block_hash,
            block_commit_1.block_header_hash
        );
        assert_eq!(
            second_block_commit_snapshot.winning_stacks_block_hash,
            block_commit_1_1.block_header_hash
        );
        assert_eq!(
            third_block_commit_snapshot.winning_stacks_block_hash,
            block_commit_2.block_header_hash
        );

        assert_eq!(
            SortitionDB::get_block_commit_parent_sortition_id(
                db.conn(),
                &block_commit_1.txid,
                &first_block_commit_snapshot.sortition_id
            )
            .unwrap(),
            Some(genesis_commit_snapshot.sortition_id.clone())
        );
        assert_eq!(
            SortitionDB::get_block_commit_parent_sortition_id(
                db.conn(),
                &block_commit_1_1.txid,
                &second_block_commit_snapshot.sortition_id
            )
            .unwrap(),
            Some(first_block_commit_snapshot.sortition_id.clone())
        );
        assert_eq!(
            SortitionDB::get_block_commit_parent_sortition_id(
                db.conn(),
                &block_commit_2.txid,
                &third_block_commit_snapshot.sortition_id
            )
            .unwrap(),
            Some(genesis_commit_snapshot.sortition_id.clone())
        );

        assert_eq!(
            SortitionDB::get_block_commit_parent_sortition_id(
                db.conn(),
                &block_commit_2.txid,
                &first_block_commit_snapshot.sortition_id
            )
            .unwrap(),
            None
        );

        for i in 0..2 {
            // do this battery of tests twice -- once with the block commit parent descendancy
            // information, and once without.
            if i == 0 {
                debug!("Test descended_from with block_commit_parents");
            } else {
                debug!("Test descended_from without block_commit_parents");
            }
            {
                let mut db_tx =
                    SortitionHandleTx::begin(&mut db, &third_block_commit_snapshot.sortition_id)
                        .unwrap();
                assert!(db_tx
                    .descended_from(
                        block_commit_1.block_height,
                        &block_commit_1.block_header_hash
                    )
                    .unwrap());
                assert!(db_tx
                    .descended_from(
                        block_commit_1.block_height,
                        &genesis_block_commit.block_header_hash
                    )
                    .unwrap());
                assert!(db_tx
                    .descended_from(
                        block_commit_2.block_height,
                        &genesis_block_commit.block_header_hash
                    )
                    .unwrap());

                assert!(!db_tx
                    .descended_from(
                        block_commit_2.block_height,
                        &block_commit_1.block_header_hash
                    )
                    .unwrap());

                // not possible, since block_commit_1 predates block_commit_2
                assert!(!db_tx
                    .descended_from(
                        block_commit_1.block_height,
                        &block_commit_2.block_header_hash
                    )
                    .unwrap());
            }
            {
                let mut db_tx =
                    SortitionHandleTx::begin(&mut db, &third_block_commit_snapshot.sortition_id)
                        .unwrap();
                assert!(db_tx
                    .descended_from(
                        block_commit_1_1.block_height,
                        &block_commit_1.block_header_hash
                    )
                    .unwrap());
                assert!(db_tx
                    .descended_from(
                        block_commit_1.block_height,
                        &genesis_block_commit.block_header_hash
                    )
                    .unwrap());

                // transitively...
                assert!(db_tx
                    .descended_from(
                        block_commit_1_1.block_height,
                        &genesis_block_commit.block_header_hash
                    )
                    .unwrap());
            }

            // drop descendancy information
            {
                let db_tx = db.tx_begin().unwrap();
                db_tx
                    .execute("DELETE FROM block_commit_parents", NO_PARAMS)
                    .unwrap();
                db_tx.commit().unwrap();
            }
        }
    }

    #[test]
    fn test_get_ancestor_burnchain_header_hashes() {
        let block_height = 100;
        let first_burn_hash = BurnchainHeaderHash([0x00; 32]);
        let mut db = SortitionDB::connect_test(block_height, &first_burn_hash).unwrap();
        for i in 1..11 {
            test_append_snapshot(&mut db, BurnchainHeaderHash([i as u8; 32]), &vec![]);
        }

        // typical
        let ancestors = SortitionDB::get_ancestor_burnchain_header_hashes(
            db.conn(),
            &BurnchainHeaderHash([0x09; 32]),
            6,
        )
        .unwrap();
        assert_eq!(
            ancestors,
            vec![
                BurnchainHeaderHash([0x09; 32]),
                BurnchainHeaderHash([0x08; 32]),
                BurnchainHeaderHash([0x07; 32]),
                BurnchainHeaderHash([0x06; 32]),
                BurnchainHeaderHash([0x05; 32]),
                BurnchainHeaderHash([0x04; 32]),
                BurnchainHeaderHash([0x03; 32])
            ]
        );

        // edge case -- get too many
        let ancestors = SortitionDB::get_ancestor_burnchain_header_hashes(
            db.conn(),
            &BurnchainHeaderHash([0x09; 32]),
            20,
        )
        .unwrap();
        assert_eq!(
            ancestors,
            vec![
                BurnchainHeaderHash([0x09; 32]),
                BurnchainHeaderHash([0x08; 32]),
                BurnchainHeaderHash([0x07; 32]),
                BurnchainHeaderHash([0x06; 32]),
                BurnchainHeaderHash([0x05; 32]),
                BurnchainHeaderHash([0x04; 32]),
                BurnchainHeaderHash([0x03; 32]),
                BurnchainHeaderHash([0x02; 32]),
                BurnchainHeaderHash([0x01; 32]),
                BurnchainHeaderHash([0x00; 32]),
                BurnchainHeaderHash([0xff; 32]),
            ]
        );

        // edge case -- get none
        let ancestors = SortitionDB::get_ancestor_burnchain_header_hashes(
            db.conn(),
            &BurnchainHeaderHash([0x09; 32]),
            0,
        )
        .unwrap();
        assert_eq!(ancestors, vec![BurnchainHeaderHash([0x09; 32])]);

        // edge case -- get one that doesn't exist
        let ancestors = SortitionDB::get_ancestor_burnchain_header_hashes(
            db.conn(),
            &BurnchainHeaderHash([0xfe; 32]),
            0,
        )
        .unwrap();
        assert_eq!(ancestors, vec![BurnchainHeaderHash([0xfe; 32])]);
    }

    #[test]
    fn test_get_set_ast_rules() {
        let block_height = 123;
        let first_burn_hash = BurnchainHeaderHash::from_hex(
            "0000000000000000000000000000000000000000000000000000000000000000",
        )
        .unwrap();
        let mut db = SortitionDB::connect_test(block_height, &first_burn_hash).unwrap();

        assert_eq!(
            SortitionDB::get_ast_rules(db.conn(), 0).unwrap(),
            ASTRules::Typical
        );
        assert_eq!(
            SortitionDB::get_ast_rules(db.conn(), 1).unwrap(),
            ASTRules::Typical
        );
        assert_eq!(
            SortitionDB::get_ast_rules(db.conn(), AST_RULES_PRECHECK_SIZE - 1).unwrap(),
            ASTRules::Typical
        );
        assert_eq!(
            SortitionDB::get_ast_rules(db.conn(), AST_RULES_PRECHECK_SIZE).unwrap(),
            ASTRules::PrecheckSize
        );
        assert_eq!(
            SortitionDB::get_ast_rules(db.conn(), AST_RULES_PRECHECK_SIZE + 1).unwrap(),
            ASTRules::PrecheckSize
        );

        {
            let mut tx = db.tx_begin().unwrap();
            SortitionDB::override_ast_rule_height(&mut tx, ASTRules::PrecheckSize, 1).unwrap();
            tx.commit().unwrap();
        }

        assert_eq!(
            SortitionDB::get_ast_rules(db.conn(), 0).unwrap(),
            ASTRules::Typical
        );
        assert_eq!(
            SortitionDB::get_ast_rules(db.conn(), 1).unwrap(),
            ASTRules::PrecheckSize
        );
        assert_eq!(
            SortitionDB::get_ast_rules(db.conn(), 2).unwrap(),
            ASTRules::PrecheckSize
        );
    }

    #[test]
    fn test_get_chosen_pox_anchor() {
        let path_root = "/tmp/test_get_chosen_pox_anchor";
        if fs::metadata(path_root).is_ok() {
            fs::remove_dir_all(path_root).unwrap();
        }

        fs::create_dir_all(path_root).unwrap();

        let pox_consts = PoxConstants::new(
            10,
            3,
            3,
            25,
            5,
            u64::MAX,
            u64::MAX,
            u32::MAX,
            u32::MAX,
            u32::MAX,
            u32::MAX,
        );

        let mut burnchain = Burnchain::regtest(path_root);
        burnchain.pox_constants = pox_consts.clone();

        let mut burnchain_db =
            BurnchainDB::connect(&burnchain.get_burnchaindb_path(), &burnchain, true).unwrap();
        let first_block_header = burnchain_db.get_canonical_chain_tip().unwrap();
        let first_block_height = first_block_header.block_height;

        let mut headers = vec![first_block_header.clone()];
        let key_register = make_simple_key_register(&first_block_header.block_hash, 0, 1);

        let (next_headers, commits) = make_reward_cycle(
            &mut burnchain_db,
            &burnchain,
            &key_register,
            &mut headers,
            vec![None, None],
        );

        assert!(headers.len() > commits.len());

        let mut db = SortitionDB::connect_test_with_epochs(
            first_block_height,
            &first_block_header.block_hash,
            StacksEpoch::all(0, 0, 0),
        )
        .unwrap();

        // make snapshot for each block-commit.
        // make the first run of commits always win.
        for (i, commit_set) in commits.iter().enumerate() {
            let commit_ops: Vec<BlockstackOperationType> = commit_set
                .iter()
                .filter_map(|op| {
                    op.as_ref()
                        .map(|op| BlockstackOperationType::LeaderBlockCommit(op.clone()))
                })
                .collect();
            let winner = if commit_set.len() > 0 {
                commit_set[0].clone()
            } else {
                None
            };
            let burn_header_hash = headers[i + 1].block_hash.clone();
            let burn_block_height = headers[i + 1].block_height;

            Burnchain::process_affirmation_maps(
                &burnchain,
                &mut burnchain_db,
                &headers,
                burn_block_height,
            )
            .unwrap();
            test_append_snapshot_with_winner(&mut db, burn_header_hash, &commit_ops, None, winner);
        }

        let tip = SortitionDB::get_canonical_burn_chain_tip(db.conn()).unwrap();
        {
            let ic = db.index_handle(&tip.sortition_id);
            let anchor_2_05 = ic
                .get_chosen_pox_anchor(None, &tip.burn_header_hash, &pox_consts)
                .unwrap()
                .unwrap();
            let anchor_2_1 = ic
                .get_chosen_pox_anchor(
                    Some(burnchain_db.conn()),
                    &tip.burn_header_hash,
                    &pox_consts,
                )
                .unwrap()
                .unwrap();

            let ic = db.index_conn();
            let expected_anchor_ch = SortitionDB::get_ancestor_snapshot(&ic, 7, &tip.sortition_id)
                .unwrap()
                .unwrap()
                .consensus_hash;
            assert_eq!(
                anchor_2_05,
                (
                    expected_anchor_ch.clone(),
                    commits[6][0].as_ref().unwrap().block_header_hash.clone(),
                    commits[6][0].as_ref().unwrap().txid.clone(),
                )
            );
            assert_eq!(
                anchor_2_1,
                (
                    expected_anchor_ch,
                    commits[6][1].as_ref().unwrap().block_header_hash.clone(),
                    commits[6][1].as_ref().unwrap().txid.clone(),
                )
            );
        }
    }

    #[test]
    fn test_load_store_burnchain_ops() {
        let block_height = 123;
        let first_burn_hash = BurnchainHeaderHash::from_hex(
            "0000000000000000000000000000000000000000000000000000000000000000",
        )
        .unwrap();
        let fork_burn_hash = BurnchainHeaderHash::from_hex(
            "0000000000000000000000000000000000000000000000000000000000000001",
        )
        .unwrap();
        let mut db = SortitionDB::connect_test(block_height, &first_burn_hash).unwrap();
        let vote_pubkey = StacksPublicKey::from_hex(
            "02d8015134d9db8178ac93acbc43170a2f20febba5087a5b0437058765ad5133d0",
        )
        .unwrap();
        let vote_key: StacksPublicKeyBuffer = vote_pubkey.to_bytes_compressed().as_slice().into();

        let good_ops = vec![
            BlockstackOperationType::TransferStx(TransferStxOp {
                sender: StacksAddress::new(1, Hash160([1u8; 20])),
                recipient: StacksAddress::new(2, Hash160([2u8; 20])),
                transfered_ustx: 123,
                memo: vec![0x00, 0x01, 0x02, 0x03, 0x04],

                txid: Txid([0x01; 32]),
                vtxindex: 1,
                block_height,
                burn_header_hash: first_burn_hash.clone(),
            }),
            BlockstackOperationType::StackStx(StackStxOp {
                sender: StacksAddress::new(3, Hash160([3u8; 20])),
                reward_addr: PoxAddress::Standard(StacksAddress::new(4, Hash160([4u8; 20])), None),
                stacked_ustx: 456,
                num_cycles: 6,
                signer_key: Some(StacksPublicKeyBuffer([0x02; 33])),
                max_amount: Some(u128::MAX),
                auth_id: Some(0u32),

                txid: Txid([0x02; 32]),
                vtxindex: 2,
                block_height,
                burn_header_hash: first_burn_hash.clone(),
            }),
            BlockstackOperationType::DelegateStx(DelegateStxOp {
                sender: StacksAddress::new(6, Hash160([6u8; 20])),
                delegate_to: StacksAddress::new(7, Hash160([7u8; 20])),
                reward_addr: Some((
                    123,
                    PoxAddress::Standard(
                        StacksAddress::new(8, Hash160([8u8; 20])),
                        Some(AddressHashMode::SerializeP2PKH),
                    ),
                )),
                delegated_ustx: 789,
                until_burn_height: Some(1000),

                txid: Txid([0x04; 32]),
                vtxindex: 3,
                block_height,
                burn_header_hash: first_burn_hash.clone(),
            }),
            BlockstackOperationType::VoteForAggregateKey(VoteForAggregateKeyOp {
                sender: StacksAddress::new(6, Hash160([6u8; 20])),
                aggregate_key: vote_key,
                signer_key: vote_key,
                round: 1,
                reward_cycle: 2,
                signer_index: 3,

                txid: Txid([0x05; 32]),
                vtxindex: 4,
                block_height,
                burn_header_hash: first_burn_hash.clone(),
            }),
        ];

        let mut tx = db.tx_begin_at_tip();
        for op in good_ops.iter() {
            tx.store_burnchain_transaction(op, &SortitionId::stubbed(&first_burn_hash))
                .unwrap();
        }
        tx.commit().unwrap();

        let ops = SortitionDB::get_transfer_stx_ops(db.conn(), &first_burn_hash).unwrap();
        assert_eq!(ops.len(), 1);
        assert_eq!(
            BlockstackOperationType::TransferStx(ops[0].clone()),
            good_ops[0]
        );

        let ops = SortitionDB::get_stack_stx_ops(db.conn(), &first_burn_hash).unwrap();
        assert_eq!(ops.len(), 1);
        assert_eq!(
            BlockstackOperationType::StackStx(ops[0].clone()),
            good_ops[1]
        );

        let ops = SortitionDB::get_delegate_stx_ops(db.conn(), &first_burn_hash).unwrap();
        assert_eq!(ops.len(), 1);
        assert_eq!(
            BlockstackOperationType::DelegateStx(ops[0].clone()),
            good_ops[2]
        );

        let ops = SortitionDB::get_vote_for_aggregate_key_ops(db.conn(), &first_burn_hash).unwrap();
        assert_eq!(ops.len(), 1);
        assert_eq!(
            BlockstackOperationType::VoteForAggregateKey(ops[0].clone()),
            good_ops[3]
        );

        // if the same ops get mined in a different burnchain block, they will still be available
        let good_ops_2 = vec![
            BlockstackOperationType::TransferStx(TransferStxOp {
                sender: StacksAddress::new(1, Hash160([1u8; 20])),
                recipient: StacksAddress::new(2, Hash160([2u8; 20])),
                transfered_ustx: 123,
                memo: vec![0x00, 0x01, 0x02, 0x03, 0x04],

                txid: Txid([0x01; 32]),
                vtxindex: 1,
                block_height,
                burn_header_hash: fork_burn_hash.clone(),
            }),
            BlockstackOperationType::StackStx(StackStxOp {
                sender: StacksAddress::new(3, Hash160([3u8; 20])),
                reward_addr: PoxAddress::Standard(StacksAddress::new(4, Hash160([4u8; 20])), None),
                stacked_ustx: 456,
                num_cycles: 6,
                signer_key: None,
                max_amount: None,
                auth_id: None,

                txid: Txid([0x02; 32]),
                vtxindex: 2,
                block_height,
                burn_header_hash: fork_burn_hash.clone(),
            }),
            BlockstackOperationType::DelegateStx(DelegateStxOp {
                sender: StacksAddress::new(6, Hash160([6u8; 20])),
                delegate_to: StacksAddress::new(7, Hash160([7u8; 20])),
                reward_addr: Some((
                    123,
                    PoxAddress::Standard(StacksAddress::new(8, Hash160([8u8; 20])), None),
                )),
                delegated_ustx: 789,
                until_burn_height: Some(1000),

                txid: Txid([0x04; 32]),
                vtxindex: 3,
                block_height,
                burn_header_hash: fork_burn_hash.clone(),
            }),
            BlockstackOperationType::VoteForAggregateKey(VoteForAggregateKeyOp {
                sender: StacksAddress::new(6, Hash160([6u8; 20])),
                aggregate_key: StacksPublicKeyBuffer([0x01; 33]),
                signer_key: StacksPublicKeyBuffer([0x02; 33]),
                round: 1,
                reward_cycle: 2,
                signer_index: 3,

                txid: Txid([0x05; 32]),
                vtxindex: 4,
                block_height,
                burn_header_hash: fork_burn_hash.clone(),
            }),
        ];

        let mut tx = db.tx_begin_at_tip();
        for op in good_ops_2.iter() {
            tx.store_burnchain_transaction(op, &SortitionId::stubbed(&fork_burn_hash))
                .unwrap();
        }
        tx.commit().unwrap();

        // old ones are still there
        let ops = SortitionDB::get_transfer_stx_ops(db.conn(), &first_burn_hash).unwrap();
        assert_eq!(ops.len(), 1);
        assert_eq!(
            BlockstackOperationType::TransferStx(ops[0].clone()),
            good_ops[0]
        );

        let ops = SortitionDB::get_stack_stx_ops(db.conn(), &first_burn_hash).unwrap();
        assert_eq!(ops.len(), 1);
        assert_eq!(
            BlockstackOperationType::StackStx(ops[0].clone()),
            good_ops[1]
        );

        let ops = SortitionDB::get_delegate_stx_ops(db.conn(), &first_burn_hash).unwrap();
        assert_eq!(ops.len(), 1);
        assert_eq!(
            BlockstackOperationType::DelegateStx(ops[0].clone()),
            good_ops[2]
        );

        let ops = SortitionDB::get_vote_for_aggregate_key_ops(db.conn(), &first_burn_hash).unwrap();
        assert_eq!(ops.len(), 1);
        assert_eq!(
            BlockstackOperationType::VoteForAggregateKey(ops[0].clone()),
            good_ops[3]
        );

        // and so are the new ones
        let ops = SortitionDB::get_transfer_stx_ops(db.conn(), &fork_burn_hash).unwrap();
        assert_eq!(ops.len(), 1);
        assert_eq!(
            BlockstackOperationType::TransferStx(ops[0].clone()),
            good_ops_2[0]
        );

        let ops = SortitionDB::get_stack_stx_ops(db.conn(), &fork_burn_hash).unwrap();
        assert_eq!(ops.len(), 1);
        assert_eq!(
            BlockstackOperationType::StackStx(ops[0].clone()),
            good_ops_2[1]
        );

        let ops = SortitionDB::get_delegate_stx_ops(db.conn(), &fork_burn_hash).unwrap();
        assert_eq!(ops.len(), 1);
        assert_eq!(
            BlockstackOperationType::DelegateStx(ops[0].clone()),
            good_ops_2[2]
        );

        let ops = SortitionDB::get_vote_for_aggregate_key_ops(db.conn(), &fork_burn_hash).unwrap();
        assert_eq!(ops.len(), 1);
        assert_eq!(
            BlockstackOperationType::VoteForAggregateKey(ops[0].clone()),
            good_ops_2[3]
        );
    }

    #[test]
    fn test_validate_and_replace_epochs() {
        use crate::core::STACKS_EPOCHS_MAINNET;

        let path_root = "/tmp/test_validate_and_replace_epochs";
        if fs::metadata(path_root).is_ok() {
            fs::remove_dir_all(path_root).unwrap();
        }

        fs::create_dir_all(path_root).unwrap();

        let mut bad_epochs = STACKS_EPOCHS_MAINNET.to_vec();
        let idx = bad_epochs.len() - 2;
        bad_epochs[idx].end_height += 1;
        bad_epochs[idx + 1].start_height += 1;

        let sortdb = SortitionDB::connect(
            &format!("{}/sortdb.sqlite", &path_root),
            0,
            &BurnchainHeaderHash([0x00; 32]),
            0,
            &bad_epochs,
            PoxConstants::mainnet_default(),
            None,
            true,
        )
        .unwrap();

        let db_epochs = SortitionDB::get_stacks_epochs(sortdb.conn()).unwrap();
        assert_eq!(db_epochs, bad_epochs);

        let fixed_sortdb = SortitionDB::connect(
            &format!("{}/sortdb.sqlite", &path_root),
            0,
            &BurnchainHeaderHash([0x00; 32]),
            0,
            &STACKS_EPOCHS_MAINNET.to_vec(),
            PoxConstants::mainnet_default(),
            None,
            true,
        )
        .unwrap();

        let db_epochs = SortitionDB::get_stacks_epochs(sortdb.conn()).unwrap();
        assert_eq!(db_epochs, STACKS_EPOCHS_MAINNET.to_vec());
    }
}
